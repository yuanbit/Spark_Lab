{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment-06\n",
    "### Amirreza Fosoul and Bithiah Yuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import split\n",
    "import pyspark.sql.functions as f\n",
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import concat, col, lit, size\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import IntegerType\n",
    "import random\n",
    "spark = SparkSession.builder.appName('ex6').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unexplode a column to an array of given datatype\n",
    "def unExplode(df, groupByColName, collectColName, colType):\n",
    "    types = {'string': StringType(), 'integer': IntegerType()}\n",
    "    df_collected = df.groupby(groupByColName).agg(f.concat_ws(\", \", f.collect_list(df[collectColName])).alias(collectColName))\n",
    "    result = df_collected.withColumn(collectColName, split(col(collectColName), \",\\s*\").cast(ArrayType(types[colType])).alias(collectColName)).orderBy(groupByColName)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|              userID|             paperID|libSize|\n",
      "+--------------------+--------------------+-------+\n",
      "|589b870a611c25fa9...|[12832332, 130547...|      5|\n",
      "|90f1a3e6fcdbf9bc5...|[115945, 11733005...|      5|\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read user ratings into Dataframe\n",
    "user_df = spark.read.option(\"delimiter\", \";\").csv('./example0.txt')\n",
    "#user_df = spark.read.option(\"delimiter\", \";\").csv('./example.txt')\n",
    "user_df = user_df.select(col(\"_c0\").alias(\"userID\"), col(\"_c1\").alias(\"paperID\"))\n",
    "\n",
    "user_pre = user_df\n",
    "\n",
    "user_df = user_df.select(\"userID\", f.split(\"paperID\", \",\").alias(\"papers\"), f.explode(f.split(\"paperID\", \",\")).alias(\"paperID\"))\n",
    "user_df = user_df.drop(\"papers\")\n",
    "\n",
    "# Count the number of distinct users\n",
    "numUsers = user_df.select(\"userID\").distinct().count()\n",
    "\n",
    "# Get a dataframe of the distinct papers\n",
    "d_paper = user_df.select(\"paperID\").distinct()\n",
    "\n",
    "userLib = user_pre.withColumn(\"paperID\", split(col(\"paperID\"), \",\").cast(ArrayType(IntegerType()))).orderBy(\"userID\")\n",
    "\n",
    "get_len_udf = udf(lambda x: len(x), IntegerType())\n",
    "\n",
    "userLib = userLib.withColumn(\"libSize\", get_len_udf(col(\"paperID\")))\n",
    "\n",
    "userLib.show()\n",
    "\n",
    "#userLib = userLib.select(\"userID\", \"libSize\", f.explode(\"paperID\").alias(\"paperID\"))\n",
    "\n",
    "# userLib_unexplode = unExplode(userLib, \"userID\", \"paperID\", \"integer\")\n",
    "\n",
    "# userLib_unexplode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in records of paper information\n",
    "#w_df = spark.read.csv('./papers.csv')\n",
    "w_df = spark.read.csv('./paper0.csv')\n",
    "#w_df = w_df.select(\"_c0\", \"_c01\" \"_c06\", \"_c09\", \"_c13\", \"_c14\")\n",
    "w_df = w_df.select(\"_c0\", \"_c1\", \"_c6\", \"_c9\")\n",
    "#w_df = w_df.select(col(\"_c0\").alias(\"paperID\"), col(\"_c01\").alias(\"type\"), col(\"_c06\").alias(\"pages\"), col(\"_c09\").alias(\"year\"), col(\"_c13\").alias(\"title\"), col(\"_c14\").alias(\"abstract\"))\n",
    "w_df = w_df.select(col(\"_c0\").alias(\"paperID\"), col(\"_c1\").alias(\"type\"), col(\"_c6\").alias(\"pages\"), col(\"_c9\").alias(\"year\"))\n",
    "\n",
    "#w_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. 1 (Problem Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------+------+-----+----+-----------+-------+--------+\n",
      "|userID                          |paperID |rating|pages|year|type       |libSize|avgPages|\n",
      "+--------------------------------+--------+------+-----+----+-----------+-------+--------+\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|115945  |1     |11   |2005|article    |5      |12.4    |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|11733005|1     |7    |2012|article    |5      |12.4    |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|9045137 |1     |24   |2007|article    |5      |12.4    |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|3728173 |1     |5    |2007|article    |5      |12.4    |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|8310458 |1     |15   |2008|article    |5      |12.4    |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|352713  |0     |12   |2002|misc       |5      |        |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|1305474 |0     |null |2002|misc       |5      |        |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|956315  |0     |10   |2006|article    |5      |        |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|12832332|0     |29   |2013|inbook     |5      |        |\n",
      "|90f1a3e6fcdbf9bc550e866116bbcea5|1001231 |0     |null |2005|proceedings|5      |        |\n",
      "+--------------------------------+--------+------+-----+----+-----------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a user hash map dataframe by adding a column with descending row numbers \n",
    "# to the pre-explode user dataframe\n",
    "# user_hash_map = user_pre.withColumn(\"user_idx\", F.monotonically_increasing_id().cast(IntegerType()))\n",
    "\n",
    "# Select the user indices and paperID\n",
    "#rating = user_hash_map.select('user_idx', 'paperID')\n",
    "rating = userLib.select('userID', 'paperID', 'libSize')\n",
    "\n",
    "# # Split the string if all paperIDs into individual paperIDs and cast the datatype to int\n",
    "# rating = rating.withColumn(\"papers\", split(col(\"paperID\"), \",\\s*\").cast(ArrayType(IntegerType())).alias(\"papers\"))\n",
    "# # Drop the column with the string of paperIDs\n",
    "# rating = rating.drop(\"paperID\")\n",
    "\n",
    "# Add a column of 1's called ratings for the rated papers w.r.t to the user index\n",
    "rating = rating.withColumn(\"rating\", lit(1))\n",
    "\n",
    "# Transform the distinct paperIDs dataframe to a list\n",
    "paper_list = list(d_paper.select('paperID').toPandas()['paperID'])\n",
    "# Map each distinct paper into int\n",
    "paper_list = list(map(int, paper_list))\n",
    "\n",
    "# Function to call in udf\n",
    "def unrated(papers):\n",
    "    # Transform the list of distinct papers and the list of rated papers of each user to a set\n",
    "    # Substract the two sets to get the list of unrated papers for each user\n",
    "    # Transform back to list\n",
    "    unrated = list(set(paper_list) - set(papers))\n",
    "\n",
    "    # Select n random papers from the unrated papers where n is the \n",
    "    # length of the rated papers list of each user\n",
    "    unrated_papers = random.sample(unrated, len(papers))\n",
    "            \n",
    "    return unrated_papers\n",
    "\n",
    "\n",
    "# udf to get a list of unrated papers with the length of rated papers for each user\n",
    "get_unrated = udf(lambda x: unrated(x), ArrayType(IntegerType()))\n",
    "\n",
    "# Add a new column of unrated papers for each user\n",
    "rating = rating.withColumn(\"unrated\", get_unrated(rating.paperID))\n",
    "\n",
    "#Create a dataframe with the rated papers and their ratings of 1's\n",
    "rated_df = rating.select(\"userID\", f.explode(\"paperID\").alias(\"paperID\"), \"rating\", \"libSize\")\n",
    "\n",
    "# Create a dataframe with the unrated papers\n",
    "unrated_df = rating.select(\"userID\", f.explode(\"unrated\").alias(\"unrated\"), \"libSize\")\n",
    "# Add a column of ratings of 0's to the unrated papers\n",
    "unrated_df = unrated_df.withColumn(\"rating\", lit(0))\n",
    "unrated_df = unrated_df.select(\"userID\", col(\"unrated\").alias(\"paperID\"), \"rating\", \"libSize\")\n",
    "\n",
    "# Union the rated and unrated dataframes and order by the user indices\n",
    "rating_matrix = rated_df.union(unrated_df).orderBy(\"userID\")\n",
    "\n",
    "feature_df = rating_matrix.join(w_df, [\"paperID\"]).orderBy(\"userID\")\n",
    "\n",
    "window = Window.partitionBy(col(\"userID\"))\n",
    "\n",
    "feature_df_rated = feature_df.filter(feature_df.rating == 1).groupBy(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\").agg(f.avg(\"pages\").over(window).alias(\"avgPages\")).orderBy(\"userID\")\n",
    "\n",
    "feature_df_unrated = feature_df.filter(feature_df.rating == 0)\n",
    "feature_df_unrated = feature_df_unrated.withColumn('avgPages', lit(\" \").cast(StringType()))\n",
    "feature_df_unrated = feature_df_unrated.select(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "\n",
    "model_df = feature_df_rated.union(feature_df_unrated)\n",
    "    \n",
    "\n",
    "# # model_df = model_df.withColumn(\"featureVector\", f.concat(col(\"pages\"), lit(\", \"), col(\"year\"), lit(\", \"), col(\"type\"), lit(\", \"), col(\"libSize\"), lit(\", \"), col(\"avgPages\")))\n",
    "# # model_df = model_df.drop(\"pages\", \"year\",\"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "model_df.where(model_df.userID==\"90f1a3e6fcdbf9bc550e866116bbcea5\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------+------+-----+----+-------+-------+---------+-----------------+\n",
      "|userID                          |paperID|rating|pages|year|type   |libSize|unrated  |avgPages         |\n",
      "+--------------------------------+-------+------+-----+----+-------+-------+---------+-----------------+\n",
      "|1eac022a97d683eace8815545ce3153f|1121661|1     |27   |2001|article|334    |[264335] |9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|238188 |1     |13   |1997|article|334    |[8222303]|9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|1042553|1     |11   |1995|article|334    |[619850] |9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|1242600|1     |4    |2007|article|334    |[841854] |9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|523772 |1     |null |2005|article|334    |[2686494]|9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|531300 |1     |5    |1953|article|334    |[4740887]|9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|2492402|1     |1    |2008|article|334    |[406529] |9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|255030 |1     |7    |2000|article|334    |[945310] |9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|3010240|1     |null |2008|article|334    |[322433] |9.714285714285714|\n",
      "|1eac022a97d683eace8815545ce3153f|2058201|1     |null |2005|article|334    |[658723] |9.714285714285714|\n",
      "+--------------------------------+-------+------+-----+----+-------+-------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_df = rating.join(w_df, [\"paperID\"]).orderBy(\"userID\")\n",
    "\n",
    "window = Window.partitionBy(col(\"userID\"))\n",
    "\n",
    "feature_df_rated = feature_df.groupBy(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\", \"unrated\").agg(f.avg(\"pages\").over(window).alias(\"avgPages\")).orderBy(\"userID\")\n",
    "\n",
    "feature_df_rated.where(model_df.userID==\"1eac022a97d683eace8815545ce3153f\").show(truncate=False)\n",
    "\n",
    "# Create a dataframe with the rated papers and their ratings of 1's\n",
    "# rated_df = feature_df_rated.select(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "# unrated_df = rating.select(\"userID\", f.explode(\"unrated\").alias(\"paperID\"), \"libSize\")\n",
    "\n",
    "# unrated_df.show()\n",
    "# # Create a dataframe with the unrated papers\n",
    "# unrated_df = feature_df_rated.select(\"userID\", f.explode(\"unrated\").alias(\"unrated\"), \"libSize\")\n",
    "\n",
    "# # Add a column of ratings of 0's to the unrated papers\n",
    "# unrated_df = unrated_df.withColumn(\"rating\", lit(0))\n",
    "# unrated_df = unrated_df.select(\"userID\", \"papers\", \"rating\", \"libSize\")\n",
    "\n",
    "# # Union the rated and unrated dataframes and order by the user indices\n",
    "# rating_matrix = rated_df.union(unrated_df).orderBy(\"userID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dataframe with the rated papers and their ratings of 1's\n",
    "# rated_df = rating.select(\"userID\", \"papers\", \"rating\", \"libSize\")\n",
    "\n",
    "# # Create a dataframe with the unrated papers\n",
    "# unrated_df = rating.select(\"userID\", col(\"unrated\").alias(\"papers\"), \"libSize\")\n",
    "# # Add a column of ratings of 0's to the unrated papers\n",
    "# unrated_df = unrated_df.withColumn(\"rating\", lit(0))\n",
    "# unrated_df = unrated_df.select(\"userID\", \"papers\", \"rating\", \"libSize\")\n",
    "\n",
    "# # Union the rated and unrated dataframes and order by the user indices\n",
    "# rating_matrix = rated_df.union(unrated_df).orderBy(\"userID\")\n",
    "\n",
    "# # Explode the lists of paperIDs w.r.t. each user\n",
    "# rating_matrix = rating_matrix.select(\"userID\", \"libSize\", f.explode(\"papers\").alias(\"paperID\"), 'rating')\n",
    "\n",
    "# feature_df = rating_matrix.join(w_df, [\"paperID\"]).orderBy(\"userID\")\n",
    "\n",
    "# window = Window.partitionBy(col(\"userID\"))\n",
    "\n",
    "# feature_df_rated = feature_df.filter(feature_df.rating == 1).groupBy(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\").agg(f.avg(\"pages\").over(window).alias(\"avgPages\")).orderBy(\"userID\")\n",
    "\n",
    "# feature_df_rated.where(model_df.userID==\"1eac022a97d683eace8815545ce3153f\").show(truncate=False)\n",
    "\n",
    "# feature_df_unrated = feature_df.filter(feature_df.rating == 0)\n",
    "\n",
    "# feature_df_unrated = feature_df_unrated.withColumn('avgPages', lit(\" \").cast(StringType()))\n",
    "# feature_df_unrated = feature_df_unrated.select(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "# model_df = feature_df_rated.union(feature_df_unrated)\n",
    "\n",
    "# model_df = model_df.withColumn(\"featureVector\", f.concat(col(\"pages\"), lit(\", \"), col(\"year\"), lit(\", \"), col(\"type\"), lit(\", \"), col(\"libSize\"), lit(\", \"), col(\"avgPages\")))\n",
    "# model_df = model_df.drop(\"pages\", \"year\",\"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "#model_df.where(model_df.userID==\"1eac022a97d683eace8815545ce3153f\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the rated papers and their ratings of 1's\n",
    "rated_df = rating.select(\"userID\", \"papers\", \"rating\", \"libSize\")\n",
    "\n",
    "# Create a dataframe with the unrated papers\n",
    "unrated_df = rating.select(\"userID\", col(\"unrated\").alias(\"papers\"), \"libSize\")\n",
    "# Add a column of ratings of 0's to the unrated papers\n",
    "unrated_df = unrated_df.withColumn(\"rating\", lit(0))\n",
    "unrated_df = unrated_df.select(\"userID\", \"papers\", \"rating\", \"libSize\")\n",
    "\n",
    "# Union the rated and unrated dataframes and order by the user indices\n",
    "rating_matrix = rated_df.union(unrated_df).orderBy(\"userID\")\n",
    "\n",
    "# Explode the lists of paperIDs w.r.t. each user\n",
    "rating_matrix = rating_matrix.select(\"userID\", \"libSize\", f.explode(\"papers\").alias(\"paperID\"), 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_unrated = feature_df_unrated.withColumn('avgPages', lit(\" \").cast(StringType()))\n",
    "# feature_df_unrated = feature_df_unrated.select(\"userID\", \"paperID\", \"rating\", \"pages\", \"year\", \"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "# model_df = feature_df_rated.union(feature_df_unrated)\n",
    "\n",
    "# # model_df = model_df.withColumn(\"featureVector\", f.concat(col(\"pages\"), lit(\", \"), col(\"year\"), lit(\", \"), col(\"type\"), lit(\", \"), col(\"libSize\"), lit(\", \"), col(\"avgPages\")))\n",
    "# # model_df = model_df.drop(\"pages\", \"year\",\"type\", \"libSize\", \"avgPages\")\n",
    "\n",
    "# model_df.where(model_df.userID==\"1eac022a97d683eace8815545ce3153f\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------+-------+------+-----------+-----+----+\n",
      "|paperID |userID                          |libSize|rating|type       |pages|year|\n",
      "+--------+--------------------------------+-------+------+-----------+-----+----+\n",
      "|1121661 |1eac022a97d683eace8815545ce3153f|334    |1     |article    |27   |2001|\n",
      "|238188  |1eac022a97d683eace8815545ce3153f|334    |1     |article    |13   |1997|\n",
      "|1042553 |1eac022a97d683eace8815545ce3153f|334    |1     |article    |11   |1995|\n",
      "|1242600 |1eac022a97d683eace8815545ce3153f|334    |1     |article    |4    |2007|\n",
      "|523772  |1eac022a97d683eace8815545ce3153f|334    |1     |article    |null |2005|\n",
      "|531300  |1eac022a97d683eace8815545ce3153f|334    |1     |article    |5    |1953|\n",
      "|2492402 |1eac022a97d683eace8815545ce3153f|334    |1     |article    |1    |2008|\n",
      "|255030  |1eac022a97d683eace8815545ce3153f|334    |1     |article    |7    |2000|\n",
      "|3010240 |1eac022a97d683eace8815545ce3153f|334    |1     |article    |null |2008|\n",
      "|2058201 |1eac022a97d683eace8815545ce3153f|334    |1     |article    |null |2005|\n",
      "|523772  |1eac022a97d683eace8815545ce3153f|334    |0     |article    |null |2005|\n",
      "|1001231 |1eac022a97d683eace8815545ce3153f|334    |0     |proceedings|null |2005|\n",
      "|352713  |1eac022a97d683eace8815545ce3153f|334    |0     |misc       |12   |2002|\n",
      "|100088  |1eac022a97d683eace8815545ce3153f|334    |0     |article    |7    |1990|\n",
      "|81501   |1eac022a97d683eace8815545ce3153f|334    |0     |article    |5    |2002|\n",
      "|255030  |1eac022a97d683eace8815545ce3153f|334    |0     |article    |7    |2000|\n",
      "|129     |1eac022a97d683eace8815545ce3153f|334    |0     |article    |3    |2000|\n",
      "|920055  |1eac022a97d683eace8815545ce3153f|334    |0     |article    |6    |2003|\n",
      "|557229  |1eac022a97d683eace8815545ce3153f|334    |0     |article    |60   |1983|\n",
      "|11191048|1eac022a97d683eace8815545ce3153f|334    |0     |article    |17   |2012|\n",
      "+--------+--------------------------------+-------+------+-----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_df.where(feature_df.userID==\"1eac022a97d683eace8815545ce3153f\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
