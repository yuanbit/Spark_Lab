12832332,inbook,,foreign aid and the making of democracy in nepal,,alliance for aid monitor nepal,29,,,2013,dec,2013-12-14 09:30:14,,deepening democracy at the local level,"local governance bodies ({lgbs}) have been part and parcel of the nepalese people for more than five decades. for nearly all nepa­lese people, the most familiar public organization is one of two local governance bodies, i.e. village development committee ({vdc}) in rural areas or municipalities in urban areas and the district development committee at the district level. since 1997 there has been no election to these bodies and upon completion of the five year term of the representatives elected in july 2002, are being run and managed by government employees. the government funding support to the {lgbs} has, however, been an increasing trend. another major program, the local governance and community development program ({lgcdp}) has been under implementation since 2008 with the support of a number of donors. activities related to demand-strengthening and citizen empowerment, especially the marginalized sections of the society in the planning process of the {lgbs}, are the important components of this program. the ward citizen forum ({wcf}) and the citizen awareness center ({cac}) are institutional arrangements made at the {vdc} and municipality under this component. in this paper the {wcf} and {cac} have been dealt with in the context of the planning process of the {lgbs}, on the basis of available literature and quick field study of two {vdcs} (one each from the district of kathmandu and bhaktapur) and one municipality of the kavre district, all belonging to the central development region of the country, a limitation of the paper in itself."
1305474,misc,,,,,,,,2002,,2007-05-18 16:14:16,,the {tesla} broadcast authentication protocol,"one of the main challenges of securing broadcast communication is source authentication, or enabling receivers of broadcast data to verify that the received data really originates from the claimed source and was not modified en route. this problem is complicated by mutually untrusted receivers and unreliable communication environments where the sender does not retransmit lost packets."
1001231,proceedings,infocom 2005. 24th annual joint conference of the ieee computer and communications societies. proceedings ieee,,,,,3,,2005,,2006-12-19 01:28:53,,anonymous communications in mobile ad hoc networks,"due to the broadcast nature of radio transmissions, communications in mobile ad hoc networks ({manets}) are more susceptible to malicious traffic analysis. in this paper we propose a novel anonymous on-demand routing protocol, termed {mask}, to enable anonymous communications thereby thwarting possible traffic analysis attacks. based on a new cryptographic concept called pairing, we first propose an anonymous neighborhood authentication protocol which allows neighboring nodes to authenticate each other without revealing their identities. then utilizing the secret pairwise link identifiers and keys established between neighbors during the neighborhood authentication process, {mask} fulfills the routing and packet forwarding tasks nicely without disclosing the identities of participating nodes under a rather strong adversarial model. {mask} provides the desirable sender and receiver anonymity, as well as the relationship anonymity of the sender and receiver. it is also resistant to a wide range of adversarial attacks. moreover, {mask} preserves the routing efficiency in contrast to previous proposals. detailed anonymity analysis and simulation studies are carried out to validate and justify the effectiveness of {mask}."
352713,misc,ieee communications magazine,,,,12,,,2002,aug,2007-05-30 11:47:53,,a survey on sensor networks,"recent advancement in wireless communica- tions and electronics has enabled the develop- ment of low-cost sensor networks. the sensor networks can be used for various application areas (e.g., health, military, home). for different application areas, there are different technical issues that researchers are currently resolving. the current state of the art of sensor networks is captured in this article, where solutions are discussed under their related protocol stack layer sections. this article ..."
956315,article,"selected areas in communications, ieee journal on",,,ieee,10,24,2,2006,feb,2006-11-22 03:22:00,,wormhole attacks in wireless networks,"as mobile ad hoc network applications are deployed, security emerges as a central requirement. in this paper, we introduce the wormhole attack, a severe attack in ad hoc networks that is particularly challenging to defend against. the wormhole attack is possible even if the attacker has not compromised any hosts, and even if all communication provides authenticity and confidentiality. in the wormhole attack, an attacker records packets (or bits) at one location in the network, tunnels them (possibly selectively) to another location, and retransmits them there into the network. the wormhole attack can form a serious threat in wireless networks, especially against many ad hoc network routing protocols and location-based wireless security systems. for example, most existing ad hoc network routing protocols, without some mechanism to defend against the wormhole attack, would be unable to find routes longer than one or two hops, severely disrupting communication. we present a general mechanism, called packet leashes, for detecting and, thus defending against wormhole attacks, and we present a specific protocol, called {tik}, that implements leashes. we also discuss topology-based wormhole detection, and show that it is impossible for these approaches to detect some wormhole topologies."
945604,inproceedings,infocom 2003. twenty-second annual joint conference of the ieee computer and communications. ieee societies,infocom 2003. twenty-second annual joint conference of the ieee computer and communications. ieee societies,,ieee,,3,,2003,mar,2006-11-16 04:19:13,,packet leashes: a defense against wormhole attacks in wireless networks,"as mobile ad hoc network applications are deployed, security emerges as a central requirement. in this paper, we introduce the wormhole attack, a severe attack in ad hoc networks that is particularly challenging to defend against. the wormhole attack is possible even if the attacker has not compromised any hosts, and even if all communication provides authenticity and confidentiality. in the wormhole attack, an attacker records packets (or bits) at one location in the network, tunnels them (possibly selectively) to another location, and retransmits them there into the network. the wormhole attack can form a serious threat in wireless networks, especially against many ad hoc network routing protocols and location-based wireless security systems. for example, most existing ad hoc network routing protocols, without some mechanism to defend against the wormhole attack, would be unable to find routes longer than one or two hops, severely disrupting communication. we present a new, general mechanism, called packet leashes, for detecting and thus defending against wormhole attacks, and we present a specific protocol, called {tik}, that implements leashes."
10294999,article,,,,,,,,2012,feb,2012-02-02 10:28:55,,a 2\% distance to z = 0.35 by reconstructing baryon acoustic oscillations - {iii} : cosmological measurements and interpretation,
967275,inproceedings,"security and privacy for emerging areas in communications networks, 2005. securecomm 2005. first international conference on","security and privacy for emerging areas in communications networks, 2005. securecomm 2005. first international conference on",,ieee,11,,,2005,,2006-11-29 18:51:32,,on the survivability of routing protocols in ad hoc wireless networks,"survivable routing protocols are able to provide service in the presence of attacks and failures. the strongest attacks that protocols can experience are attacks where adversaries have full control of a number of authenticated nodes that behave arbitrarily to disrupt the network, also referred to as byzantine attacks. this work examines the survivability of ad hoc wireless routing protocols in the presence of several byzantine attacks: black holes, flood rushing, wormholes and overlay network wormholes. traditional secure routing protocols that assume authenticated nodes can always be trusted, fail to defend against such attacks. our protocol, {odsbr}, is an on-demand wireless routing protocol able to provide correct service in the presence of failures and byzantine attacks. we demonstrate through simulation its effectiveness in mitigating such attacks. our analysis of the impact of these attacks versus the adversarys effort gives insights into their relative strengths, their interaction and their importance when designing wireless routing protocols."
115945,article,"bioessays : news and reviews in molecular, cellular and developmental biology",,,"wiley subscription services, inc., a wiley company",11,27,3,2005,mar,2005-03-07 02:40:55,"department of biology, washington university, campus box 1229, st. louis, mo 63130, usa.",a twelve-step program for evolving multicellularity and a division of labor.,"the volvocine algae provide an unrivalled opportunity to explore details of an evolutionary pathway leading from a unicellular ancestor to multicellular organisms with a division of labor between different cell types. members of this monophyletic group of green flagellates range in complexity from unicellular chlamydomonas through a series of extant organisms of intermediate size and complexity to volvox, a genus of spherical organisms that have thousands of cells and a germ-soma division of labor. it is estimated that these organisms all shared a common ancestor about 50 +/- 20 {mya}. here we outline twelve important ways in which the developmental repertoire of an ancestral unicell similar to modern c. reinhardtii was modified to produce first a small colonial organism like gonium that was capable of swimming directionally, then a sequence of larger organisms (such as pandorina, eudorina and pleodorina) in which there was an increasing tendency to differentiate two cell types, and eventually volvox carteri with its complete germ-soma division of labor."
11733005,article,genome biology and evolution,,,oxford university press,7,4,7,2012,jan,2012-11-20 13:31:29,,evidence for widespread {gc}-biased gene conversion in eukaryotes,"{gc}-biased gene conversion ({gbgc}) is a process that tends to increase the {gc} content of recombining {dna} over evolutionary time and is thought to explain the evolution of {gc} content in mammals and yeasts. evidence for {gbgc} outside these two groups is growing but is still limited. here, we analyzed 36 completely sequenced genomes representing four of the five major groups in eukaryotes (unikonts, excavates, chromalveolates and plantae). {gbgc} was investigated by directly comparing {gc} content and recombination rates in species where recombination data are available, that is, half of them. to study all species of our dataset, we used chromosome size as a proxy for recombination rate and compared it with {gc} content. among the 17 species showing a significant relationship between {gc} content and chromosome size, 15 are consistent with the predictions of the {gbgc} model. importantly, the species showing a pattern consistent with {gbgc} are found in all the four major groups of eukaryotes studied, which suggests that {gbgc} may be widespread in eukaryotes."
9045137,article,annals of botany,,,,24,99,4,2007,apr,2011-03-22 23:55:46,,nuclear {dna} content estimates in green algal lineages: chlorophyta and streptophyta,"background and aims consensus higher-level molecular phylogenies present a compelling case that an ancient divergence separates eukaryotic green algae into two major monophyletic lineages, chlorophyta and streptophyta, and a residuum of green algae, which have been referred to prasinophytes or micromonadophytes. nuclear {dna} content estimates have been published for less than 1\% of the described green algal members of chlorophyta, which includes multicellular green marine algae and freshwater flagellates (e.g. chlamydomonas and volvox). the present investigation summarizes the state of our knowledge and adds substantially to our database of c-values, especially for the streptophyte charophycean lineage which is the sister group of the land plants. a recent list of {2c} nuclear {dna} contents for isolates and species of green algae is expanded by 72 to {157.methods} the {dna}-localizing fluorochrome {dapi} (4′,6-diamidino-2-phenylindole) and red blood cell (chicken erythrocytes) standard were used to estimate {2c} values with static {microspectrophotometry.key} results in chlorophyta, including chlorophyceae, prasinophyceae, trebouxiophyceae and ulvophyceae, {2c} {dna} estimates range from 0·01 to 5·8 pg. nuclear {dna} content variation trends are noted and discussed for specific problematic taxon pairs, including {ulotrichales–ulvales}, and {cladophorales–siphonocladales}. for streptophyta, {2c} nuclear {dna} contents range from 0·2 to 6·4 pg, excluding the highly polyploid charales and desmidiales, which have genome sizes of up to 14·8 and 46·8 pg, respectively. nuclear {dna} content data for streptophyta superimposed on a contemporary molecular phylogeny indicate that early diverging lineages, including some members of chlorokybales, coleochaetales and klebsormidiales, have genomes as small as 0·1–0·5 pg. it is proposed that the streptophyte ancestral nuclear genome common to both the charophyte and the embryophyte lineages can be characterized as {1c} = 0·2 pg and 1n = {6.conclusions} these data will help pre-screen candidate species for the on-going construction of bacterial artificial chromosome nuclear genome libraries for land plant ancestors. data for the prasinophyte mesostigma are of particular interest as this alga reportedly most closely resembles the 'ancestral green flagellate'. both mechanistic and ecological processes are discussed that could have produced the observed c-value increase of >100-fold in the charophyte green algae whereas the ancestral genome was conserved in the embryophytes."
3728173,article,proceedings of the national academy of sciences,,,national academy of sciences,5,104,Suppl 1,2007,may,2008-11-29 20:58:14,,evolution of individuality during the transition from unicellular to multicellular life,"individuality is a complex trait, yet a series of stages each advantageous in itself can be shown to exist allowing evolution to get from unicellular individuals to multicellular individuals. we consider several of the key stages involved in this transition: the initial advantage of group formation, the origin of reproductive altruism within the group, and the further specialization of cell types as groups increase in size. how do groups become individuals? this is the central question we address. our hypothesis is that fitness tradeoffs drive the transition of a cell group into a multicellular individual through the evolution of cells specialized at reproductive and vegetative functions of the group. we have modeled this hypothesis and have tested our models in two ways. we have studied the origin of the genetic basis for reproductive altruism (somatic cells specialized at vegetative functions) in the multicellular volvox carteri by showing how an altruistic gene may have originated through cooption of a life-history tradeoff gene present in a unicellular ancestor. second, we ask why reproductive altruism and individuality arise only in the larger members of the volvocine group (recognizing that high levels of kinship are present in all volvocine algae groups). our answer is that the selective pressures leading to reproductive altruism stem from the increasing cost of reproduction with increasing group size. concepts from population genetics and evolutionary biology appear to be sufficient to explain complexity, at least as it relates to the problem of the major transitions between the different kinds of evolutionary individuals."
8310458,article,evolution,,,blackwell publishing inc,15,62,2,2008,,2010-11-26 15:46:08,,evolution of complexity in the volvocine algae: transitions in individuality through darwin's eye,"the transition from unicellular to differentiated multicellular organisms constitutes an increase in the level complexity, because previously existing individuals are combined to form a new, higher-level individual. the volvocine algae represent a unique opportunity to study this transition because they diverged relatively recently from unicellular relatives and because extant species display a range of intermediate grades between unicellular and multicellular, with functional specialization of cells. following the approach darwin used to understand  ” organs of extreme perfection” such as the vertebrate eye, this jump in complexity can be reduced to a series of small steps that cumulatively describe a gradual transition between the two levels. we use phylogenetic reconstructions of ancestral character states to trace the evolution of steps involved in this transition in volvocine algae. the history of these characters includes several well-supported instances of multiple origins and reversals. the inferred changes can be understood as components of cooperation–conflict–conflict mediation cycles as predicted by multilevel selection theory. one such cycle may have taken place early in volvocine evolution, leading to the highly integrated colonies seen in extant volvocine algae. a second cycle, in which the defection of somatic cells must be prevented, may still be in progress."
80546,article,biology and philosophy,,,,17,19,2,2004,mar,2005-01-26 21:35:21,,the arbitrariness of the genetic code,"the genetic code has been regarded as arbitrary in the sense that the codon-amino acid assignments could be different than they actually are. this general idea has been spelled out differently by previous, often rather implicit accounts of arbitrariness. they have drawn on the frozen accident theory, on evolutionary contingency, on alternative causal pathways, and on the absence of direct stereochemical interactions between codons and amino acids. it has also been suggested that the arbitrariness of the genetic code justifies attributing semantic information to macromolecules, notably to {dna}. i argue that these accounts of arbitrariness are unsatisfactory. i propose that the code is arbitrary in the sense of jacques monod's concept of chemical arbitrariness: the genetic code is arbitrary in that any codon requires certain chemical and structural properties to specify a particular amino acid, but these properties are not required in virtue of a principle of chemistry. this notion of arbitrariness is compatible with several recent hypotheses about code evolution. i maintain that the code's chemical arbitrariness is neither sufficient nor necessary for attributing semantic information to nucleic acids."
5842862,article,molecular cell,,,elsevier,2,35,6,2009,sep,2009-09-30 17:11:23,,how to choose a good scientific problem,"choosing good problems is essential for being a good scientist. but what is a good problem, and how do you choose one? the subject is not usually discussed explicitly within our profession. scientists are expected to be smart enough to figure it out on their own and through the observation of their teachers. this lack of explicit discussion leaves a vacuum that can lead to approaches such as choosing problems that can give results that merit publication in valued journals, resulting in a job and tenure."
1242600,article,oikos,,,blackwell publishing ltd,4,116,5,2007,may,2007-05-01 11:06:49,,how to write consistently boring scientific literature,"although scientists typically insist that their research is very exciting and adventurous when they talk to laymen and prospective students, the allure of this enthusiasm is too often lost in the predictable, stilted structure and language of their scientific publications. i present here, a top-10 list of recommendations for how to write consistently boring scientific publications. i then discuss why we should and how we could make these contributions more accessible and exciting."
3467077,article,plos computational biology,,,public library of science,,4,10,2008,oct,2008-10-30 23:02:02,,defrosting the digital library: bibliographic tools for the next generation web.,"many scientists now manage the bulk of their bibliographic information electronically, thereby organizing their publications and citation material from digital libraries. however, a library has been described as ""thought in cold storage,"" and unfortunately many digital libraries can be cold, impersonal, isolated, and inaccessible places. in this review, we discuss the current chilly state of digital libraries for the computational biologist, including {pubmed}, {ieee} xplore, the {acm} digital library, {isi} web of knowledge, scopus, citeseer, {arxiv}, {dblp}, and google scholar. we illustrate the current process of using these libraries with a typical workflow, and highlight problems with managing data and metadata using {uris}. we then examine a range of new applications such as zotero, mendeley, mekentosj papers, {myncbi}, {citeulike}, connotea, and {hubmed} that exploit the web to make these digital libraries more personal, sociable, integrated, and accessible places. we conclude with how these applications may begin to help achieve a digital defrost, and discuss some of the issues that will help or hinder this in terms of making libraries on the web warmer places in the future, becoming resources that are considerably more useful to both humans and machines."
309395,article,plos medicine,,,public library of science,,2,8,2005,aug,2005-09-15 01:16:48,,why most published research findings are false,"there is increasing concern that most current published research findings are false. the probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. in this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. in this essay, i discuss the implications of these problems for the conduct and interpretation of research."
305755,article,,,,,,,,2005,aug,2005-08-27 18:07:09,,the structure of collaborative tagging systems,
6603134,article,mol cell,,,cell press,1,37,2,2010,jan,2010-01-29 11:33:17,,how to build a motivated research group,"motivated group members experience a full sense of choice: of doing what one wants. such behavior shows high performance, is enjoyable, and enhances innovation. this essay describes principles of building a motivated research group."
99,article,nature,,,nature publishing group,2,393,6684,1998,jun,2004-11-07 13:58:29,"department of theoretical and applied mechanics, cornell university, ithaca, new york 14853, usa. djw24@columbia.edu",collective dynamics of 'small-world' networks,"networks of coupled dynamical systems have been used to model biological oscillators1, 2, 3, 4, josephson junction arrays5,6, excitable media7, neural networks8, 9, 10, spatial games11, genetic control networks12 and many other self-organizing systems. ordinarily, the connection topology is assumed to be either completely regular or completely random. but many biological, technological and social networks lie somewhere between these two extremes. here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. we find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. we call them 'small-world' networks, by analogy with the small-world phenomenon13,14 (popularly known as six degrees of separation15). the neural network of the worm caenorhabditis elegans, the power grid of the western united states, and the collaboration graph of film actors are shown to be small-world networks. models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. in particular, infectious diseases spread more easily in small-world networks than in regular lattices."
105595,book,,,,plume,,,,2003,apr,2005-02-27 02:23:03,,linked: how everything is connected to everything else and what it means,how is the human brain like the {aids} epidemic? ask physicist {albert-l\'{a}szl\'{o
212874,article,nature genetics,,,nature publishing group,4,25,1,2000,may,2005-05-27 13:30:37,"department of genetics, stanford university school of medicine, california, usa. cherry@stanford.edu",gene ontology: tool for the unification of biology. the gene ontology consortium.,"genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. the goal of the gene ontology consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. to this end, three independent ontologies accessible on the {world-wide} web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component."
740681,article,journal of information science,,,sage publications,10,32,2,2006,apr,2006-07-05 18:36:15,"thousand oaks, ca, usa",usage patterns of collaborative tagging systems,"collaborative tagging describes the process by which many users add metadata in the form of keywords to shared content. recently, collaborative tagging has grown in popularity on the web, on sites that allow users to tag bookmarks, photographs and other content. in this paper we analyze the structure of collaborative tagging systems as well as their dynamic aspects. specifically, we discovered regularities in user activity, tag frequencies, kinds of tags used, bursts of popularity in bookmarking and a remarkable stability in the relative proportions of tags within a given {url}. we also present a dynamic model of collaborative tagging that predicts these stable patterns and relates them to imitation and shared knowledge."
101,article,science,,,american association for the advancement of science,3,298,5594,2002,oct,2004-11-08 11:27:57,"departments of physics of complex systems and molecular cell biology, weizmann institute of science, rehovot, israel 76100.",network motifs: simple building blocks of complex networks,"complex networks are studied across many fields of science. to uncover their structural design principles, we defined  ” network motifs,” patterns of interconnections occurring in complex networks at numbers that are significantly higher than those in randomized networks. we found such motifs in networks from biochemistry, neurobiology, ecology, and engineering. the motifs shared by ecological food webs were distinct from the motifs shared by the genetic networks of escherichia coli and saccharomyces cerevisiae or from those found in the world wide web. similar motifs were found in networks that perform information processing, even though they describe elements as different as biomolecules within a cell and synaptic connections between neurons in caenorhabditis elegans. motifs may thus define universal classes of networks. this approach may uncover the basic building blocks of most networks."
99857,article,american journal of sociology,,,the university of chicago press,20,78,6,1973,,2005-02-20 23:48:01,,the strength of weak ties,"analysis of social networks is suggested as a tool for linking micro and macro levels of sociological theory. the procedure is illustrated by elaboration of the macro implications of one aspect of small-scale interaction: the strength of dyadic ties. it is argued that the degree of overlap of two individuals' friendship networks varies directly with the strength of their tie to one another. the impact of this principle on diffusion of influence and information, mobility opportunity, and community organization is explored. stress is laid on the cohesive power of weak ties. most network models deal, implicitly, with strong ties, thus confining their applicability to small, well-defined groups. emphasis on weak ties lends itself to discussion of relations between groups and to analysis of segments of social structure not easily defined in terms of primary groups."
3614773,article,nature reviews genetics,,,nature publishing group,6,10,1,2009,jan,2008-11-20 17:50:25,,{rna}-seq: a revolutionary tool for transcriptomics,"{rna}-seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. {rna}-seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. this article describes the {rna}-seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
873540,book,,,,springer,,,,2006,oct,2006-09-26 18:44:17,,pattern recognition and machine learning,"the field of pattern recognition has undergone substantial development over the years. this book reflects these developments while providing a grounding in the basic concepts of pattern recognition and machine learning. it is aimed at advanced undergraduates or first year {phd} students, as well as researchers and practitioners."
6434100,article,plos comput biol,,,public library of science,,5,12,2009,dec,2009-12-24 05:57:41,,a quick guide for developing effective bioinformatics programming skills,
100088,article,journal of molecular biology,,,,7,215,3,1990,oct,2005-02-21 16:47:05,"national center for biotechnology information, national library of medicine, national institutes of health, bethesda, md 20894.",basic local alignment search tool.,"a new approach to rapid sequence comparison, basic local alignment search tool ({blast}), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair ({msp}) score. recent mathematical results on the stochastic properties of {msp} scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. the basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straightforward {dna} and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long {dna} sequences. in addition to its flexibility and tractability to mathematical analysis, {blast} is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity."
1387765,article,siam review,,,,42,51,4,2009,feb,2007-06-13 17:29:15,,power-law distributions in empirical data,
161814,book,,,,springer,,,,2003,jul,2005-04-15 15:57:22,,the elements of statistical learning,
117535,article,journal of the royal statistical society. series b (methodological),,,blackwell publishing for the royal statistical society,37,39,1,1977,,2005-03-08 19:21:57,,maximum likelihood from incomplete data via the {em} algorithm,"a broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis."
5307378,article,plos computational biology,plos comput biol,,public library of science,,5,7,2009,jul,2009-07-31 09:14:26,,a quick guide to organizing computational biology projects,
361498,article,,,,,,,,2005,sep,2005-10-22 11:31:35,,folksonomy as a complex network,
3283,techreport,,,,,,,,1998,,2004-12-13 09:25:46,,the {pagerank} citation ranking: bringing order to the web,"the importance of a web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. but there is still much that can be said objectively about the relative importance of web pages. this paper describes {pagerank}, a method for rating web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. we compare {pagerank} to an idealized random web surfer. we show how to efficiently compute {pagerank} for large..."
4131662,article,genome biology,genome biology,,biomed central ltd,-15,10,3,2009,mar,2009-03-04 11:12:15,,ultrafast and memory-efficient alignment of short {dna} sequences to the human genome,"bowtie is an ultrafast, memory-efficient alignment program for aligning short {dna} sequence reads to large genomes. for the human genome, {burrows-wheeler} indexing allows bowtie to align more than 25 million reads per {cpu} hour with a memory footprint of approximately 1.3 gigabytes. bowtie extends previous {burrows-wheeler} techniques with a novel quality-aware backtracking algorithm that permits mismatches. multiple processor cores can be used simultaneously to achieve even greater alignment speeds. bowtie is open source http://bowtie.cbcb.umd.edu."
115158,book,,,,addison-wesley professional,,,,1994,jan,2005-03-06 00:48:06,,design patterns: elements of reusable {object-oriented} software,"<{i>design} {patterns</i}> is a modern classic in the literature of object-oriented development, offering timeless and elegant solutions to common problems in software design. it describes patterns for managing object creation, composing objects into larger structures, and coordinating control flow between objects. the book provides numerous examples where using composition rather than inheritance can improve the reusability and flexibility of code. note, though, that it's not a tutorial but a catalog that you can use to find an object-oriented design pattern that's appropriate for the needs of your particular application--a selection for virtuoso programmers who appreciate (or require) consistent, well-engineered object-oriented designs. now on {cd}, this internationally acclaimed bestseller is more valuable than ever! <p> use the contents of the {cd} to create your own design documents and reusable components. the {cd} contains: 23 patterns you can cut and paste into your own design documents; sample code demonstrating pattern implementation; complete design patterns content in standard {html} format, with numerous hyperlinked cross-references; accessed through a standard web browser; java-based dynamic search mechanism, enhancing online seach capabilities; graphical user environment, allowing ease of navigation. <p> first published in 1995, this landmark work on object-oriented software design presents a catalog of simple and succinct solutions to common design problems. created by four experienced designers, the 23 patterns contained herein have become an essential resource for anyone developing reusable object-oriented software. in response to reader demand, the complete text and pattern catalog are now available on {cd}-{rom}. this electronic version of <{i>design} patterns</i> enables programmers to install the book directly onto a computer or network for use as an online reference for creating reusable object-oriented software. <p> the authors first describe what patterns are and how they can help you in the design process. they then systematically name, explain, evaluate, and catalog recurring designs in object-oriented systems. all patterns are compiled from real-world examples and include code that demonstrates how they may be implemented in object-oriented programming languages such as c++ and smalltalk. readers who already own the book will want the {cd} to take advantage of its dynamic search mechanism and ready-to-install patterns."
5662136,article,plos comput biol,,,public library of science,,5,8,2009,aug,2009-08-28 08:29:46,,a quick guide to teaching r programming to computational biology students,
816066,inproceedings,,proceedings of the seventeenth conference on hypertext and hypermedia,hypertext,acm,9,,,2006,,2006-08-24 21:17:15,"new york, ny, usa","{ht06}, tagging paper, taxonomy, flickr, academic article, to read","in recent years, tagging systems have become increasingly popular. these systems enable users to add keywords (i.e., ""tags"") to internet resources (e.g., web pages, images, videos) without relying on a controlled vocabulary. tagging systems have the potential to improve search, spam detection, reputation systems, and personal organization while introducing new modalities of social communication and opportunities for data mining. this potential is largely due to the social structure that underlies many of the current {systems.despite} the rapid expansion of applications that support tagging of resources, tagging systems are still not well studied or understood. in this paper, we provide a short description of the academic related work to date. we offer a model of tagging systems, specifically in the context of web-based systems, to help us illustrate the possible benefits of these tools. since many such systems already exist, we provide a taxonomy of tagging systems to help inform their analysis and design, and thus enable researchers to frame and compare evidence for the sustainability of such systems. we also provide a simple taxonomy of incentives and contribution models to inform potential evaluative frameworks. while this work does not present comprehensive empirical results, we present a preliminary study of the photo-sharing and tagging system flickr to demonstrate our model and explore some of the issues in one sample system. this analysis helps us outline and motivate possible future directions of research in tagging systems."
10132366,article,science,,,american association for the advancement of science,6,334,6062,2011,dec,2011-12-15 21:05:31,,detecting novel associations in large data sets,"identifying interesting relationships between pairs of variables in large data sets is increasingly important. here, we present a measure of dependence for two-variable relationships: the maximal information coefficient ({mic}). {mic} captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (r(2)) of the data relative to the regression function. {mic} belongs to a larger class of maximal information-based nonparametric exploration ({mine}) statistics for identifying and classifying relationships. we apply {mic} and {mine} to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships."
1688531,article,faseb journal,,,federation of american societies for experimental biology,4,22,2,2008,feb,2007-09-24 07:31:33,"*alfa institute of biomedical sciences, athens, greece;department of medicine, tufts university school of medicine, boston, massachusetts, usa; andinstitute of continuing medical education of ioannina, ioannina, greece.","comparison of {pubmed}, scopus, web of science, and google scholar: strengths and weaknesses.","the evolution of the electronic age has led to the development of numerous medical databases on the world wide web, offering search facilities on a particular subject and the ability to perform citation analysis. we compared the content coverage and practical utility of {pubmed}, scopus, web of science, and google scholar. the official web pages of the databases were used to extract information on the range of journals covered, search facilities and restrictions, and update frequency. we used the example of a keyword search to evaluate the usefulness of these databases in biomedical information retrieval and a specific published article to evaluate their utility in performing citation analysis. all databases were practical in use and offered numerous search facilities. {pubmed} and google scholar are accessed for free. the keyword search with {pubmed} offers optimal update frequency and includes online early articles; other databases can rate articles by number of citations, as an index of importance. for citation analysis, scopus offers about 20\% more coverage than web of science, whereas google scholar offers results of inconsistent accuracy. {pubmed} remains an optimal tool in biomedical electronic research. scopus covers a wider journal range, of help both in keyword searching and citation analysis, but it is currently limited to recent articles (published after 1995) compared with web of science. google scholar, as for the web in general, can help in the retrieval of even the most obscure information but its use is marred by inadequate, less often updated, citation information."
70828,article,contemporary physics,,,taylor \& francis,28,46,5,2005,sep,2004-12-29 16:08:54,,"power laws, pareto distributions and zipf's law","when the probability of measuring a particular value of some quantity varies inversely as a power of that value, the quantity is said to follow a power law, also known variously as zipf's law or the pareto distribution. power laws appear widely in physics, biology, earth and planetary sciences, economics and finance, computer science, demography and the social sciences. for instance, the distributions of the sizes of cities, earthquakes, forest fires, solar flares, moon craters and people's personal fortunes all appear to follow power laws. the origin of power-law behaviour has been a topic of debate in the scientific community for more than a century. here we review some of the empirical evidence for the existence of power-law forms and the theories proposed to explain them."
1272533,article,the journal of cell biology,j. cell biol.,,rockefeller university press,4,177,1,2007,apr,2007-05-02 19:37:24,,error bars in experimental biology.,"error bars commonly appear in figures in publications, but experimental biologists are often unsure how they should be used and interpreted. in this article we illustrate some basic features of error bars and explain how they can help communicate data and assist correct interpretation. error bars may show confidence intervals, standard errors, standard deviations, or other quantities. different types of error bars give quite different information, and so figure legends must make clear what error bars represent. we suggest eight simple rules to assist with effective use and interpretation of error bars."
141092,book,,,,cambridge university press,,,,2003,oct,2005-03-26 08:56:53,,"information theory, inference and learning algorithms",
525366,article,proceedings of the national academy of sciences,proceedings of the national academy of sciences of the united states of america,,national academy of sciences,5,102,43,2005,oct,2006-03-01 14:37:54,,gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles,"although genomewide {rna} expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. here, we describe a powerful analytical method called gene set enrichment analysis ({gsea}) for interpreting gene expression data. the method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. we demonstrate how {gsea} yields insights into several cancer-related data sets, including leukemia and lung cancer. notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, {gsea} reveals many biological pathways in common. the {gsea} method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets."
238188,article,nucleic acids research,,,oxford university press,13,25,17,1997,sep,2005-07-18 11:44:05,"national center for biotechnology information, national library of medicine, national institutes of health, bethesda, md 20894, usa. altschul@ncbi.nlm.nih.gov",gapped {blast} and {psi}-{blast}: a new generation of protein database search programs.,"the {blast} programs are widely used tools for searching protein and {dna} databases for sequence similarities. for protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the {blast} programs to be decreased substantially while enhancing their sensitivity to weak similarities. a new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped {blast} program that runs at approximately three times the speed of the original. in addition, a method is introduced for automatically combining statistically significant alignments produced by {blast} into a position-specific score matrix, and searching the database using this matrix. the resulting {position-specific} iterated {blast} ({psi}-{blast}) program runs at approximately the same speed per iteration as gapped {blast}, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. {psi}-{blast} is used to uncover several new and interesting members of the {brct} superfamily."
4778506,article,"bioinformatics (oxford, england)",,,oxford university press,1,25,16,2009,aug,2009-06-09 07:53:59,,the sequence {alignment/map} format and {samtools}.,"the sequence {alignment/map} ({sam}) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 mbp) produced by different sequencing platforms. it is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 genomes project are released. {samtools} implements various utilities for post-processing alignments in the {sam} format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. http://samtools.sourceforge.net."
6397938,article,nature reviews. genetics,,,nature publishing group,15,11,1,2010,jan,2009-12-17 21:44:38,,sequencing technologies - the next generation.,"demand has never been greater for revolutionary technologies that deliver fast, inexpensive and accurate genome information. this challenge has catalysed the development of next-generation sequencing ({ngs}) technologies. the inexpensive production of large volumes of sequence data is the primary advantage over conventional methods. here, i present a technical review of template preparation, sequencing and imaging, genome alignment and assembly approaches, and recent advances in current and near-term commercially available {ngs} instruments. i also outline the broad range of applications for {ngs} technologies, in addition to providing guidelines for platform selection to address biological questions of interest."
155,misc,,,,,,,,2003,mar,2004-11-10 17:13:30,,the structure and function of complex networks,
523772,article,plos comput biol,,,public library of science,,1,5,2005,oct,2006-02-27 19:00:43,,ten simple rules for getting published,
3010240,article,journal of cell science,,,company of biologists,,121,11,2008,jun,2008-07-16 22:25:46,,the importance of stupidity in scientific research,10.1242/jcs.033340
2860398,article,nat meth,nat meth,,nature publishing group,7,5,7,2008,jul,2008-06-12 00:57:36,"[1] division of biology, mc 156-29, california institute of technology, pasadena, california 91125, usa. [2] these authors contributed equally to this work.",mapping and quantifying mammalian transcriptomes by {rna}-seq,"we have mapped and quantified mouse transcriptomes by deeply sequencing them and recording how frequently each gene is represented in the sequence sample ({rna}-seq). this provides a digital measure of the presence and prevalence of transcripts from known and previously unknown genes. we report reference measurements composed of 41-52 million mapped 25-base-pair reads for {poly(a})-selected {rna} from adult mouse brain, liver and skeletal muscle tissues. we used {rna} standards to quantify transcript prevalence and to test the linear range of transcript detection, which spanned five orders of magnitude. although >90\% of uniquely mapped reads fell within known exons, the remaining data suggest new and revised gene models, including changed or additional promoters, exons and 3' untranscribed regions, as well as new candidate {microrna} precursors. {rna} splice events, which are not readily measured by standard gene expression microarray or serial analysis of gene expression methods, were detected directly by mapping splice-crossing sequence reads. we observed 1.45 x 10(5) distinct splices, and alternative splices were prominent, with 3,500 different genes expressing one or more alternate internal splices."
90558,article,science,,,american association for the advancement of science,3,286,5439,1999,oct,2005-06-14 03:29:04,,emergence of scaling in random networks,"systems as diverse as genetic networks or the world wide web are best described as networks with complex topology. a common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. this feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. a model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems."
1206611,article,nature,,,nature publishing group,3,446,7136,2007,apr,2007-04-04 19:39:59,,quantifying social group evolution,"the rich set of interactions between individuals in society1, 2, 3, 4, 5, 6, 7 results in complex community structure, capturing highly connected circles of friends, families or professional cliques in a social network3, 7, 8, 9, 10. thanks to frequent changes in the activity and communication patterns of individuals, the associated social and communication network is subject to constant evolution7, 11, 12, 13, 14, 15, 16. our knowledge of the mechanisms governing the underlying community dynamics is limited, but is essential for a deeper understanding of the development and self-optimization of society as a whole17, 18, 19, 20, 21, 22. we have developed an algorithm based on clique percolation23, 24 that allows us to investigate the time dependence of overlapping communities on a large scale, and thus uncover basic relationships characterizing community evolution. our focus is on networks capturing the collaboration between scientists and the calls between mobile phone users. we find that large groups persist for longer if they are capable of dynamically altering their membership, suggesting that an ability to change the group composition results in better adaptability. the behaviour of small groups displays the opposite tendency—the condition for stability is that their composition remains unchanged. we also show that knowledge of the time commitment of members to a given community can be used for estimating the community's lifetime. these findings offer insight into the fundamental differences between the dynamics of small groups and large institutions."
167581,book,,,,wiley-interscience,,,,2000,nov,2005-04-22 18:33:13,,pattern classification (pt.1),"this edition has been completely revised, enlarged and formatted in two colour. it is a systematic account of the major topics in pattern recognition, based on the fundamental principles. it includes extensive examples, exercises and a solutions manual."
4544032,article,bioinformatics,,,oxford university press,6,25,14,2009,jul,2009-05-19 00:37:13,,fast and accurate short read alignment with {burrows–wheeler} transform,"motivation: the enormous amount of short reads generated by the new {dna} sequencing technologies call for the development of fast and accurate read alignment programs. a first generation of hash table-based methods has been developed, including {maq}, which is accurate, feature rich and fast enough to align short reads from a single individual. however, {maq} does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. the speed of {maq} is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals."
484851,electronic,,,,,,,,2005,dec,2006-01-29 15:41:43,,collaborative tagging as a tripartite network,
2199619,article,oikos,,,blackwell publishing ltd,4,116,5,2007,may,2008-01-06 08:41:21,,how to write consistently boring scientific literature,"although scientists typically insist that their research is very exciting and adventurous when they talk to laymen and prospective students, the allure of this enthusiasm is too often lost in the predictable, stilted structure and language of their scientific publications. i present here, a top-10 list of recommendations for how to write consistently boring scientific publications. i then discuss why we should and how we could make these contributions more accessible and exciting."
268,article,nat rev genet,,,nature publishing group,12,5,2,2004,feb,2004-11-12 19:49:45,"department of physics, university of notre dame, notre dame, indiana 46556, usa. alb@nd.edu",network biology: understanding the cell's functional organization,"a key aim of postgenomic biomedical research is to systematically catalogue all molecules and their interactions within a living cell. there is a clear need to understand how these molecules and the interactions between them determine the function of this enormously complex machinery, both in isolation and when surrounded by other cells. rapid advances in network biology indicate that cellular networks are governed by universal laws and offer a new conceptual framework that could potentially revolutionize our view of biology and disease pathologies in the twenty-first century."
81501,article,proceedings of the national academy of sciences,,,national academy of sciences,5,99,12,2002,jun,2005-01-21 16:03:13,"santa fe institute, 1399 hyde park road, santa fe, nm 87501, usa. girvan@santafe.edu",community structure in social and biological networks,"a number of recent studies have focused on the statistical properties of networked systems such as social networks and the worldwide web. researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. in this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. we propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. we test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. we also apply the method to two networks whose community structure is not well known—a collaboration network and a food web—and find that it detects significant and informative community divisions in both cases."
65083,article,artificial organs,,,blackwell publishing,1,29,1,2005,jan,2005-01-11 06:43:05,"general, visceral and transplantation surgery, experimental surgery and regenerative medicine, charitcampus virchow, university medicine berlin, berlin, germany.","""blogs"" and ""wikis"" are valuable software tools for communication within research groups.",
822253,inproceedings,,proceedings of the seventeenth conference on hypertext and hypermedia,hypertext,acm,3,,,2006,,2006-08-30 17:39:21,"new york, ny, usa",harvesting social knowledge from folksonomies,"collaborative tagging systems, or folksonomies, have the potential of becoming technological infrastructure to support knowledge management activities in an organization or a society. there are many challenges, however. this paper presents designs that enhance collaborative tagging systems to meet some key challenges: community identification, ontology generation, user and document recommendation. design prototypes, evaluation methodology and selected preliminary results are presented."
44,article,nature,,,nature publishing group,8,410,6825,2001,mar,2004-11-04 02:26:33,"department of theoretical and applied mechanics and center for applied mathematics, cornell university, ithaca, new york 14853-1503, usa. strogatz@cornell.edu",exploring complex networks,"the study of networks pervades all of science, from neurobiology to statistical physics. the most basic issues are structural: how does one characterize the wiring diagram of a food web or the internet or the metabolic network of the bacterium escherichia coli? are there any unifying principles underlying their topology? from the perspective of nonlinear dynamics, we would also like to understand how an enormous network of interacting dynamical systems — be they neurons, power stations or lasers — will behave collectively, given their individual dynamics and coupling architecture. researchers are only now beginning to unravel the structure and dynamics of complex networks."
3391364,article,nature biotechnology,nat biotech,,nature publishing group,10,26,10,2008,oct,2008-10-09 20:09:55,,next-generation {dna} sequencing,"{dna} sequence represents a single format onto which a broad range of biological phenomena can be projected for high-throughput data collection. over the past three years, massively parallel {dna} sequencing platforms have become widely available, reducing the cost of {dna} sequencing by over two orders of magnitude, and democratizing the field by putting the sequencing capacity of a major genome center in the hands of individual investigators. these new technologies are rapidly evolving, and near-term challenges include the development of robust protocols for generating sequencing libraries, building effective new approaches to data-analysis, and often a rethinking of experimental design. next-generation {dna} sequencing has the potential to dramatically accelerate biological and biomedical research, by enabling the comprehensive analysis of genomes, transcriptomes and interactomes to become inexpensive, routine and widespread, rather than requiring significant production-scale efforts."
8133402,article,nature,,,nature research,12,467,7319,2010,oct,2010-10-27 18:35:05,,a map of human genome variation from population-scale sequencing,"the 1000 genomes project aims to provide a deep characterization of human genome sequence variation as a foundation for investigating the relationship between genotype and phenotype. here we present results of the pilot phase of the project, designed to develop and compare different strategies for genome-wide sequencing with high-throughput platforms. we undertook three projects: low-coverage whole-genome sequencing of 179 individuals from four populations; high-coverage sequencing of two mother-father-child trios; and exon-targeted sequencing of 697 individuals from seven populations. we describe the location, allele frequency and local haplotype structure of approximately 15 million single nucleotide polymorphisms, 1 million short insertions and deletions, and 20,000 structural variants, most of which were previously undescribed. we show that, because we have catalogued the vast majority of common variation, over 95\% of the currently accessible variants found in any individual are present in this data set. on average, each person is found to carry approximately 250 to 300 loss-of-function variants in annotated genes and 50 to 100 variants previously implicated in inherited disorders. we demonstrate how these results can be used to inform association and functional studies. from the two trios, we directly estimate the rate of de novo germline base substitution mutations to be approximately 10(-8) per base pair per generation. we explore the data with regard to signatures of natural selection, and identify a marked reduction of genetic variation in the neighbourhood of genes, due to selection at linked sites. these methods and public data will support the next phase of human genetic research."
4200367,article,"bioinformatics (oxford, england)",,,oxford university press,6,25,9,2009,may,2009-03-20 18:39:43,,{tophat}: discovering splice junctions with {rna}-seq.,"a new protocol for sequencing the messenger {rna} in a cell, known as {rna}-seq, generates millions of short sequence fragments in a single run. these fragments, or 'reads', can be used to measure levels of gene expression and to identify novel splice variants of genes. however, current software for aligning {rna}-seq data to a genome relies on known splice junctions and cannot identify novel ones. {tophat} is an efficient read-mapping algorithm designed to align reads from an {rna}-seq experiment to a reference genome without relying on known splice sites. we mapped the {rna}-seq reads from a recent mammalian {rna}-seq experiment and recovered more than 72\% of the splice junctions reported by the annotation-based software from that study, along with nearly 20,000 previously unreported junctions. the {tophat} pipeline is much faster than previous systems, mapping nearly 2.2 million reads per {cpu} hour, which is sufficient to process an entire {rna}-seq experiment in less than a day on a standard desktop computer. we describe several challenges unique to ab initio splice site discovery from {rna}-seq reads that will require further algorithm development. {tophat} is free, open-source software available from http://tophat.cbcb.umd.edu. supplementary data are available at bioinformatics online."
197260,book,,,,cambridge university press,,,,1991,sep,2005-05-11 21:28:08,,"situated learning: legitimate peripheral participation (learning in doing: social, cognitive and computational perspectives)",
4968720,article,plos comput biol,plos comput biol,,public library of science,,5,6,2009,jun,2009-06-26 09:00:26,,managing and analyzing {next-generation} sequence data,
1042553,article,journal of the royal statistical society. series b (methodological),,,blackwell publishing for the royal statistical society,11,57,1,1995,,2007-01-15 14:10:29,,controlling the false discovery rate: a practical and powerful approach to multiple testing,"the common approach to the multiplicity problem calls for controlling the familywise error rate ({fwer}). this approach, though, has faults, and we point out a few. a different approach to problems of multiple significance testing is presented. it calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. this error rate is equivalent to the {fwer} when all hypotheses are true but is smaller otherwise. therefore, in problems where the control of the false discovery rate rather than that of the {fwer} is desired, there is potential for a gain in power. a simple sequential bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. the use of the new procedure and the appropriateness of the criterion are illustrated with examples."
469428,article,nature reviews genetics,,,nature publishing group,10,7,2,2006,feb,2006-01-21 06:09:24,,literature mining for the biologist: from information retrieval to biological discovery,"for the average biologist, hands-on literature mining currently means a keyword search in {pubmed}. however, methods for extracting biomedical facts from the scientific literature have improved considerably, and the associated tools will probably soon be used in many laboratories to automatically annotate and analyse the growing number of system-wide experimental data sets. owing to the increasing body of text and the open-access policies of many journals, literature mining is also becoming useful for both hypothesis generation and biological discovery. however, the latter will require the integration of literature and high-throughput data, which should encourage close collaborations between biologists and computational linguists."
2492402,article,nature biotechnology,,,nature publishing group,1,26,3,2008,mar,2008-03-09 12:24:32,,what is principal component analysis?,"principal component analysis is often incorporated into genome-wide expression studies, but what is it and how can it be used to explore high-dimensional data?"
83751,article,acm comput. surv.,,,acm,59,31,3,1999,sep,2005-01-26 09:13:20,"new york, ny, usa",data clustering: a review,
3721754,article,nucleic acids research,,,oxford university press,12,37,1,2009,jan,2008-11-28 13:45:48,,bioinformatics enrichment tools: paths toward the comprehensive functional analysis of large gene lists,"functional analysis of large gene lists, derived in most cases from emerging high-throughput genomic, proteomic and bioinformatics scanning approaches, is still a challenging and daunting task. the gene-annotation enrichment analysis is a promising high-throughput strategy that increases the likelihood for investigators to identify biological processes most pertinent to their study. approximately 68 bioinformatics enrichment tools that are currently available in the community are collected in this survey. tools are uniquely categorized into three major classes, according to their underlying enrichment algorithms. the comprehensive collections, unique tool classifications and associated questions/issues will provide a more comprehensive and up-to-date view regarding the advantages, pitfalls and recent trends in a simpler tool-class level rather than by a tool-by-tool approach. thus, the survey will help tool designers/developers and experienced end users understand the underlying algorithms and pertinent details of particular tool categories/tools, enabling them to make the best choices for their particular research interests."
938,article,commun. acm,,,acm,5,47,12,2004,dec,2004-11-23 02:13:34,"new york, ny, usa",semantic blogging and decentralized knowledge management,tapping into the structured metadata in snippets of information gives communities of interest effective access to their collective knowledge.
405907,article,proceedings of the ieee,proceedings of the ieee,,ieee,29,77,2,1989,feb,2005-11-23 14:41:25,,a tutorial on hidden markov models and selected applications in speech recognition,"this tutorial provides an overview of the basic theory of hidden markov models ({hmms}) as originated by {l.e}. baum and t. petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. the author first reviews the theory of discrete markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. the theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. three fundamental problems of {hmms} are noted and several practical techniques for solving these problems are given. the various types of {hmms} that have been studied, including ergodic as well as left-right models, are described"
2620950,article,genome research,genome research,,cold spring harbor laboratory press,8,18,5,2008,may,2008-04-01 21:51:05,,velvet: algorithms for de novo short read assembly using de bruijn graphs.,"we have developed a new set of algorithms, collectively called ""velvet,"" to manipulate de bruijn graphs for genomic sequence assembly. a de bruijn graph is a compact representation based on short words (k-mers) that is ideal for high coverage, very short read (25-50 bp) data sets. applying velvet to very short reads and paired-ends information only, one can produce contigs of significant length, up to 50-kb n50 length in simulations of prokaryotic data and 3-kb n50 on simulated mammalian {bacs}. when applied to real solexa data sets without read pairs, velvet generated contigs of approximately 8 kb in a prokaryote and 2 kb in a mammalian {bac}, in close agreement with our simulated results without read-pair information. velvet represents a new approach to assembly that can leverage very short reads in combination with read pairs to produce useful assemblies."
4265782,article,science,,,american association for the advancement of science,4,324,5923,2009,apr,2009-04-03 03:48:42,,the automation of science,"the basis of science is the hypothetico-deductive method and the recording of experiments in sufficient detail to enable reproducibility. we report the development of robot scientist  ” adam,” which advances the automation of both. adam has autonomously generated functional genomics hypotheses about the yeast saccharomyces cerevisiae and experimentally tested these hypotheses by using laboratory automation. we have confirmed adam's conclusions through manual experiments. to describe adam's research, we have developed an ontology and logical language. the resulting formalization involves over 10,000 different research units in a nested treelike structure, 10 levels deep, that relates the 6.6 million biomass measurements to their logical description. this formalization describes how a machine contributed to scientific knowledge."
227153,article,nature,,,nature publishing group,61,409,6822,2001,feb,2005-06-14 02:46:37,,initial sequencing and analysis of the human genome,"the human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. we also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence."
255030,article,nucleic acids research,,,oxford university press,7,28,1,2000,jan,2005-07-13 17:11:25,"research collaboratory for structural bioinformatics (rcsb), rutgers university, piscataway, nj 08854-8087, usa. berman@rcsb.rutgers.edu",the protein data bank,"the protein data bank ({pdb}; http://www.rcsb.org/pdb/ ) is the single worldwide archive of structural data of biological macromolecules. this paper describes the goals of the {pdb}, the systems in place for data deposition and access, how to obtain further information, and near-term plans for the future development of the resource."
2058201,article,,,,,,,,2005,may,2009-09-16 12:38:25,,spike and slab variable selection: frequentist and bayesian strategies,
5394760,article,nature biotechnology,,,nature publishing group,6,27,8,2009,aug,2009-08-08 08:00:03,,the systems biology graphical notation.,"circuit diagrams and unified modeling language diagrams are just two examples of standard visual languages that help accelerate work by promoting regularity, removing ambiguity and enabling software tool support for communication of complex information. ironically, despite having one of the highest ratios of graphical to textual information, biology still lacks standard graphical notations. the recent deluge of biological knowledge makes addressing this deficit a pressing concern. toward this goal, we present the systems biology graphical notation ({sbgn}), a visual language developed by a community of biochemists, modelers and computer scientists. {sbgn} consists of three complementary languages: process diagram, entity relationship diagram and activity flow diagram. together they enable scientists to represent networks of biochemical interactions in a standard, unambiguous way. we believe that {sbgn} will foster efficient and accurate representation, visualization, storage, exchange and reuse of information on all kinds of biological knowledge, from gene regulation, to metabolism, to cellular signaling."
5785226,article,plos biol,,,public library of science,,7,9,2009,sep,2009-09-15 07:43:42,,real lives and white lies in the funding of scientific research,
4524121,article,plos comput biol,,,public library of science,,5,6,2009,jun,2009-05-15 18:13:22,,ten simple rules for choosing between industry and academia,
2883810,article,genome research,,,cold spring harbor laboratory press,8,18,9,2008,sep,2008-06-11 21:57:14,,{rna}-seq: an assessment of technical reproducibility and comparison with gene expression arrays,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
481248,article,physics reports,,,,133,424,4-5,2006,feb,2006-01-26 05:04:14,,complex networks: structure and dynamics,"coupled biological and chemical systems, neural networks, social interacting species, the internet and the world wide web, are only a few examples of systems composed by a large number of highly interconnected dynamical units. the first approach to capture the global properties of such systems is to model them as graphs whose nodes represent the dynamical units, and whose links stand for the interactions between them. on the one hand, scientists have to cope with structural issues, such as characterizing the topology of a complex wiring architecture, revealing the unifying principles that are at the basis of real networks, and developing models to mimic the growth of a network and reproduce its structural properties. on the other hand, many relevant questions arise when studying complex networks' dynamics, such as learning how a large ensemble of dynamical systems that interact through a complex wiring topology can behave collectively. we review the major concepts and results recently achieved in the study of the structure and dynamics of complex networks, and summarize the relevant applications of these ideas in many different disciplines, ranging from nonlinear science to biology, from statistical mechanics to medicine and engineering."
4025955,article,nat rev neurosci,,,nature publishing group,12,10,3,2009,mar,2009-02-09 16:40:14,,complex brain networks: graph theoretical analysis of structural and functional systems,"recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. the brain's structural and functional systems have features of complex networks--such as small-world topology, highly connected hubs and modularity--both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. in this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional {mri}, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. we also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field."
965334,inproceedings,,proceedings of the 2006 20th anniversary conference on computer supported cooperative work,cscw,acm,9,,,2006,,2006-11-28 14:56:29,"new york, ny, usa","tagging, communities, vocabulary, evolution","a tagging community's vocabulary of tags forms the basis for social navigation and shared {expression.we} present a user-centric model of vocabulary evolution in tagging communities based on community influence and personal tendency. we evaluate our model in an emergent tagging system by introducing tagging features into the {movielens} recommender {system.we} explore four tag selection algorithms for displaying tags applied by other community members. we analyze the algorithms 'effect on vocabulary evolution, tag utility, tag adoption, and user satisfaction."
820297,article,pattern recognition letters,roc analysis in pattern recognition,,elsevier science inc.,13,27,8,2006,jun,2006-08-29 02:24:46,"new york, ny, usa",an introduction to {roc} analysis,"receiver operating characteristics ({roc}) graphs are useful for organizing classifiers and visualizing their performance. {roc} graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. although {roc} graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. the purpose of this article is to serve as an introduction to {roc} graphs and as a guide for using them in research."
2739852,article,nature,,,nature publishing group,3,453,7191,2008,may,2008-04-30 21:28:34,,hierarchical structure and the prediction of missing links in networks,"networks have in recent years emerged as an invaluable tool for describing and quantifying complex systems in many branches of science1, 2, 3. recent studies suggest that networks often exhibit hierarchical organization, in which vertices divide into groups that further subdivide into groups of groups, and so forth over multiple scales. in many cases the groups are found to correspond to known functional units, such as ecological niches in food webs, modules in biochemical networks (protein interaction networks, metabolic networks or genetic regulatory networks) or communities in social networks4, 5, 6, 7. here we present a general technique for inferring hierarchical structure from network data and show that the existence of hierarchy can simultaneously explain and quantitatively reproduce many commonly observed topological properties of networks, such as right-skewed degree distributions, high clustering coefficients and short path lengths. we further show that knowledge of hierarchical structure can be used to predict missing connections in partly known networks with high accuracy, and for more general network structures than competing techniques8. taken together, our results suggest that hierarchy is a central organizing principle of complex networks, capable of offering insight into many network phenomena."
7122989,article,nature biotechnology,,,nature publishing group,4,28,5,2010,may,2010-05-04 21:31:11,,transcript assembly and quantification by {rna}-seq reveals unannotated transcripts and isoform switching during cell differentiation.,"high-throughput {mrna} sequencing ({rna}-seq) promises simultaneous transcript discovery and abundance estimation. however, this would require algorithms that are not restricted by prior gene annotations and that account for alternative transcription and splicing. here we introduce such algorithms in an open-source software program called cufflinks. to test cufflinks, we sequenced and analyzed >430 million paired 75-bp {rna}-seq reads from a mouse myoblast cell line over a differentiation time series. we detected 13,692 known transcripts and 3,724 previously unannotated ones, 62\% of which are supported by independent expression data or by homologous genes in other species. over the time series, 330 genes showed complete switches in the dominant transcription start site ({tss}) or splice isoform, and we observed more subtle shifts in 1,304 other genes. these results suggest that cufflinks can illuminate the substantial regulatory flexibility and complexity in even this well-studied model of muscle development and that it can improve transcriptome-based genome annotation."
172550,article,acm trans. inf. syst.,,,acm,48,22,1,2004,jan,2005-04-27 18:41:15,"new york, ny, usa",evaluating collaborative filtering recommender systems,"recommender systems have been evaluated in many, often incomparable, ways. in this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. in addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated."
168573,article,personal ubiquitous comput.,,,springer-verlag,11,8,1,2004,feb,2005-04-24 00:19:48,"london, uk, uk",what we talk about when we talk about context,"the emergence of ubiquitous computing as a new design paradigm poses significant challenges for human-computer interaction ({hci}) and interaction design. traditionally, {hci} has taken place within a constrained and well-understood domain of experience—single users sitting at desks and interacting with conventionally-designed computers employing screens, keyboards and mice for interaction. new opportunities have engendered considerable interest in  ” context-aware computing”—computational systems that can sense and respond to aspects of the settings in which they are used. however, considerable confusion surrounds the notion of  ” context”—what it means, what it includes and what role it plays in interactive systems. this paper suggests that the representational stance implied by conventional interpretations of  ” context” misinterprets the role of context in everyday human activity, and proposes an alternative model that suggests different directions for design."
556495,article,reviews of modern physics,,,american physical society,50,74,1,2002,jan,2006-03-18 18:52:38,,statistical mechanics of complex networks,"complex networks describe a wide range of systems in nature and society. frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the internet, a network of routers and computers connected by physical links. while traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. this article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. after reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network's robustness against failures and attacks."
430834,inproceedings,osdi '04,,,,13,,,-1,,2005-12-08 17:10:09,,{mapreduce}: simplified data processing on large clusters,"{mapreduce} is a programming model and an associated implementation for processing and generating large data sets.  users specify a \_map\_ function that processes a key/value pair to generate a set of intermediate key/value pairs, and a \_reduce\_ function that merges all intermediate values associated with the same intermediate key.  many real world tasks are expressible in this model, as shown in the paper. <p> programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. the run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter- machine communication.  this allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.  <p> our implementation of {mapreduce} runs on a large cluster of commodity machines and is highly scalable: a typical {mapreduce} computation processes many terabytes of data on thousands of machines. programmers find the system easy to use: hundreds of {mapreduce} programs have been implemented and upwards of one thousand {mapreduce} jobs are executed on google's clusters every day.     <p>"
154,article,physical review e,,,american physical society,,69,2,2003,aug,2004-11-10 17:09:17,,finding and evaluating community structure in networks,
5434882,article,science,science,,american association for the advancement of science,4,325,5942,2009,aug,2009-08-14 06:24:48,,"strategic reading, ontologies, and the future of scientific publishing","the revolution in scientific publishing that has been promised since the 1980s is about to take place. scientists have always read strategically, working with many articles simultaneously to search, filter, scan, link, annotate, and analyze fragments of content. an observed recent increase in strategic reading in the online environment will soon be further intensified by two current trends: (i) the widespread use of digital indexing, retrieval, and navigation resources and (ii) the emergence within many scientific disciplines of interoperable ontologies. accelerated and enhanced by reading tools that take advantage of ontologies, reading practices will become even more rapid and indirect, transforming the ways in which scientists engage the literature and shaping the evolution of scientific publishing."
2883820,article,nature,,,nature publishing group,9,453,7197,2008,jun,2008-06-11 22:05:46,,what we can do and what we cannot do with {fmri},"functional magnetic resonance imaging ({fmri}) is currently the mainstay of neuroimaging in cognitive neuroscience. advances in scanner technology, image acquisition protocols, experimental design, and analysis methods promise to push forward {fmri} from mere cartography to the true study of brain organization. however, fundamental questions concerning the interpretation of {fmri} data abound, as the conclusions drawn often ignore the actual limitations of the methodology. here i give an overview of the current state of {fmri}, and draw on neuroimaging and physiological data to present the current understanding of the haemodynamic signals and the constraints they impose on neuroimaging data interpretation."
200871,book,,,,basic books,,,,2002,sep,2005-05-15 20:37:03,,the design of everyday things,"even the smartest among us can feel inept as we fail to figure out which switch turns on which light or stove burner, or whether to push, pull, or slide a door. the fault lies in product designs that ignore the needs of users and the principles of cognitive psychology. a bestseller in the united states, this classic work on the cognitive aspects of design contains examples of both good and bad design and simple rules that designers can use to improve the usability of objects as diverse as cars, computers, doors, and {telephones.--from} publisher description."
1307464,article,nat rev genet,nat rev genet,,nature publishing group,11,8,6,2007,jun,2007-05-20 11:38:23,,network motifs: theory and experimental approaches,"transcription regulation networks control the expression of genes. the transcription networks of well-studied microorganisms appear to be made up of a small set of recurring regulation patterns, called network motifs. the same network motifs have recently been found in diverse organisms from bacteria to humans, suggesting that they serve as basic building blocks of transcription networks. here i review network motifs and their functions, with an emphasis on experimental studies. network motifs in other biological networks are also mentioned, including signalling and neuronal networks."
6758396,article,nature,,,nature publishing group,6,464,7285,2010,mar,2010-03-03 19:29:56,,a human gut microbial gene catalogue established by metagenomic sequencing,"to understand the impact of gut microbes on human health and well-being it is crucial to assess their genetic potential. here we describe the illumina-based metagenomic sequencing, assembly and characterization of 3.3 million non-redundant microbial genes, derived from 576.7 gigabases of sequence, from faecal samples of 124 european individuals. the gene set, \~{}150 times larger than the human gene complement, contains an overwhelming majority of the prevalent (more frequent) microbial genes of the cohort and probably includes a large proportion of the prevalent human intestinal microbial genes. the genes are largely shared among individuals of the cohort. over 99\% of the genes are bacterial, indicating that the entire cohort harbours between 1,000 and 1,150 prevalent bacterial species and each individual at least 160 such species, which are also largely shared. we define and describe the minimal gut metagenome and the minimal gut bacterial genome in terms of functions present in all individuals and most bacteria, respectively."
4302361,article,trends in biochemical sciences,,,,6,34,5,2009,may,2009-04-12 03:45:47,,four stages of a scientific discipline; four types of scientist,
197238,article,science,science,,american association for the advancement of science,47,291,5507,2001,feb,2005-05-11 20:15:06,"celera genomics, 45 west gude drive, rockville, md 20850, usa. humangenome@celera.com",the sequence of the human genome,
4511,article,commun. acm,,,acm,5,47,12,2004,dec,2004-12-22 16:50:14,"new york, ny, usa",why we blog,"bloggers are driven to document their lives, provide commentary and opinions, express deeply felt emotions, articulate ideas through writing, and form and maintain community forums."
113848,book,,,prentice hall series in artificial intelligence,prentice hall,,,,2002,dec,2005-03-04 08:43:31,,artificial intelligence: a modern approach (2nd edition),"presents a guide to artificial intelligence, covering such topics as intelligent agents, problem-solving, logical agents, planning, uncertainty, learning, and robotics."
2800782,article,nature reviews genetics,,,nature publishing group,6,9,7,2008,may,2008-05-16 05:31:42,"carnegie institution for science, department of plant biology, 260 panama street, stanford, california 94305, usa.",use and misuse of the gene ontology annotations,
1320727,article,proceedings of the national academy of sciences of the united states of america,,,national academy of sciences,5,104,21,2007,may,2007-05-23 09:40:03,,the human disease network.,"a network of disorders and disease genes linked by known disorder-gene associations offers a platform to explore in a single graph-theoretic framework all known phenotype and disease gene associations, indicating the common genetic origin of many diseases. genes associated with similar disorders show both higher likelihood of physical interactions between their products and higher expression profiling similarity for their transcripts, supporting the existence of distinct disease-specific functional modules. we find that essential human genes are likely to encode hub proteins and are expressed widely in most tissues. this suggests that disease genes also would play a central role in the human interactome. in contrast, we find that the vast majority of disease genes are nonessential and show no tendency to encode hub proteins, and their expression pattern indicates that they are localized in the functional periphery of the network. a selection-based model explains the observed difference between essential and disease genes and also suggests that diseases caused by somatic mutations should not be peripheral, a prediction we confirm for cancer genes."
340715,book,,,morgan kaufmann series in data management systems,morgan kaufmann,,,,2005,jun,2005-10-04 15:35:50,,data mining: practical machine learning tools and techniques,"as with any burgeoning technology that enjoys commercial attention, the use of data mining is surrounded by a great deal of hype. exaggerated reports tell of secrets that can be uncovered by setting algorithms loose on oceans of data. but there is no magic in machine learning, no hidden power, no alchemy. instead there is an identifiable body of practical techniques that can extract useful information from raw data. this book describes these techniques and shows how they work. <{br><br>the} book is a major revision of the first edition that appeared in 1999. while the basic core remains the same, it has been updated to reflect the changes that have taken place over five years, and now has nearly double the references. the highlights for the new edition include thirty new technique sections; an enhanced weka machine learning workbench, which now features an interactive interface; comprehensive information on neural networks; a new section on bayesian networks; plus much more.<br><br>+ authors, ian witten and eibe frank, recipients of the 2005 {acm} {sigkdd} service award.<br>+ algorithmic methods at the heart of successful data miningincluding tried and true techniques as well as leading edge methods; <br>+ performance improvement techniques that work by transforming the input or output; <br>+ downloadable weka, a collection of machine learning algorithms for data mining tasks, including tools for data pre-processing, classification, regression, clustering, association rules, and visualizationin a new, interactive interface."
688160,inproceedings,,www,,acm press,9,,,2006,,2006-06-07 11:20:08,"new york, ny, usa",visualizing tags over time,
3158518,article,genome research,,,cold spring harbor laboratory press,7,18,11,2008,nov,2008-08-27 16:06:37,sanger institute;,mapping short {dna} sequencing reads and calling variants using mapping quality scores.,"new sequencing technologies promise a new era in the use of {dna} sequence. however, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. in particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. we describe the software {maq} that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. {maq} makes full use of mate-pair information and estimates the error probability of each read alignment. error probabilities are also derived for the final genotype calls, using a bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. both read mapping and genotype calling are evaluated on simulated data and real data. {maq} is accurate, efficient, versatile, and user-friendly. it is freely available at http://maq.sourceforge.net."
165614,book,,,"structural analysis in the social sciences, 8",cambridge university press,,,,1994,nov,2005-04-21 02:34:58,,social network analysis: methods and applications (structural analysis in the social sciences),
105906,book,,,,the mit press,,,,1999,jun,2005-02-27 13:16:43,,foundations of statistical natural language processing,
201598,article,commun. acm,,,acm,2,40,3,1997,mar,2005-05-16 18:36:58,"new york, ny, usa",referral web: combining social networks and collaborative filtering,an abstract is not available.
8132834,article,genome biology,,,biomed central ltd,,11,10,2010,oct,2010-10-27 16:53:08,,differential expression analysis for sequence count data.,"high-throughput sequencing assays such as {rna}-seq, {chip}-seq or barcode counting provide quantitative readouts in the form of count data. to infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. we propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, {deseq}, as an {r/bioconductor} package."
6573750,article,science,,,american association for the advancement of science,6,327,5964,2010,jan,2010-01-21 19:49:16,,the genetic landscape of a cell,
9300222,article,nature biotechnology,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",8,29,7,2011,jul,2011-05-15 22:32:06,,full-length transcriptome assembly from {rna}-seq data without a reference genome.,"massively parallel sequencing of {cdna} has enabled deep and efficient probing of transcriptomes. current approaches for transcript reconstruction from such data often rely on aligning reads to a reference genome, and are thus unsuitable for samples with a partial or missing reference genome. here we present the trinity method for de novo assembly of full-length transcripts and evaluate it on samples from fission yeast, mouse and whitefly, whose reference genome is not yet available. by efficiently constructing and analyzing sets of de bruijn graphs, trinity fully reconstructs a large fraction of transcripts, including alternatively spliced isoforms and transcripts from recently duplicated genes. compared with other de novo transcriptome assemblers, trinity recovers more full-length transcripts across a broad range of expression levels, with a sensitivity similar to methods that rely on genome alignments. our approach provides a unified solution for transcriptome reconstruction in any sample, especially in the absence of a reference genome."
143101,book,,,,the mit press,,,,1996,oct,2005-03-30 20:06:19,,the sciences of the artificial - 3rd edition,
1051630,article,science,,,american association for the advancement of science,4,315,5814,2007,feb,2007-01-19 13:03:14,"department of electrical and computer engineering, university of toronto, 10 king's college road, toronto, ontario m5s 3g4, canada.",clustering by passing messages between data points,"clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. such  ” exemplars” can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. we devised a method called  ” affinity propagation,” which takes as input measures of similarity between pairs of data points. real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. we used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time."
6734445,article,plos comput biol,,,public library of science,,6,2,2010,feb,2010-02-26 17:20:09,,a primer on metagenomics,"metagenomics is a discipline that enables the genomic study of uncultured microorganisms. faster, cheaper sequencing technologies and the ability to sequence uncultured microbes sampled directly from their habitats are expanding and transforming our view of the microbial world. distilling meaningful information from the millions of new genomic sequences presents a serious challenge to bioinformaticians. in cultured microbes, the genomic data come from a single clone, making sequence assembly and annotation tractable. in metagenomics, the data come from heterogeneous microbial communities, sometimes containing more than 10,000 species, with the sequence data being noisy and partial. from sampling, to assembly, to gene calling and function prediction, bioinformatics faces new demands in interpreting voluminous, noisy, and often partial sequence data. although metagenomics is a relative newcomer to science, the past few years have seen an explosion in computational methods applied to metagenomic-based research. it is therefore not within the scope of this article to provide an exhaustive review. rather, we provide here a concise yet comprehensive introduction to the current computational requirements presented by metagenomics, and review the recent progress made. we also note whether there is software that implements any of the methods presented here, and briefly review its utility. nevertheless, it would be useful if readers of this article would avail themselves of the comment section provided by this journal, and relate their own experiences. finally, the last section of this article provides a few representative studies illustrating different facets of recent scientific discoveries made using metagenomics."
368051,book,,,,o'reilly media,,,,2005,oct,2005-10-27 19:31:24,,ambient findability: what we find changes who we become,"{how do you find your way in an age of information overload? how can you filter streams of complex information to pull out only what you want? why does it matter how information is structured when google seems to magically bring up the right answer to your questions? what does it mean to be ""findable"" in this day and age?  this eye-opening new book examines the convergence of information and connectivity. written by peter morville, author of the groundbreaking <i>information architecture for the world wide web</i>, the book defines our current age as a state of unlimited findability. in other words, anyone can find anything at any time. complete navigability.   <p>  morville discusses the internet, gis, and other network technologies that are coming together to make unlimited findability possible. he explores how the melding of these innovations impacts society, since web access is now a standard requirement for successful people and businesses. but before he does that, morville looks back at the history of wayfinding and human evolution, suggesting that our fear of being lost has driven us to create maps, charts, and now, the mobile internet.</p>  <p>  the book's central thesis is that information literacy, information architecture, and usability are all critical components of this new world order. hand in hand with that is the contention that only by planning and designing the best possible software, devices, and internet, will we be able to maintain this connectivity in the future. morville's book is highlighted with full color illustrations and rich examples that bring his prose to life.</p>  <p>  <i>ambient findability</i> doesn't preach or pretend to know all the answers. instead, it presents research, stories, and examples in support of its novel ideas. are we truly at a critical point in our evolution where the quality of our digital networks will dictate how we behave as a species? is findability indeed the primary key to a successful global marketplace in the 21st century and beyond. peter morville takes you on a thought-provoking tour of these memes and more -- ideas that will not only fascinate but will stir your creativity in practical ways that you can apply to your work immediately.</p>  <p>  <i>""a lively, enjoyable and informative tour of a topic that's only going to become more important.""</i><br>  --david weinberger, author, <i>small pieces loosely joined</i> and <i>the cluetrain manifesto</i></br></p>  <p>  <i>""i envy the young scholar who finds this inventive book, by whatever strange means are necessary. the future isn't just unwritten--it's unsearched.""</i><br>  --bruce sterling, writer, futurist, and co-founder, the electronic frontier foundation</br></p>  <p>  <i>""search engine marketing is the hottest thing in internet business, and deservedly so. ambient findability puts sem into a broader context and provides deeper insights into human behavior. this book will help you grow your online business in a world where being found is not at all certain.""</i><br>  --jakob nielsen, ph.d., author, <i>designing web usability: the practice of simplicity</i></br></p>  <p>  <i>""information that's hard to find will remain information that's hardly found--from one of the fathers of the discipline of information architecture, and one of its most experienced practitioners, come penetrating observations on why findability is elusive and how the act of seeking changes us.""</i><br>  --steve papa, founder and chairman, endeca</br></p>  <p>  <i>""whether it's a fact or a figure, a person or a place, peter morville knows how to make it findable. morville explores the possibilities of a world where everything can always be found--and the challenges in getting there--in this wide-ranging, thought-provoking book.""</i><br>  --jesse james garrett, author, <i>the elements of user experience</i></br></p>  <p>  <i>""it is easy to assume that current searching of the world wide web is the last word in finding and using information. peter morville shows us that search engines are just the beginning. skillfully weaving together information science research with his own extensive experience, he develops for the reader a feeling for the near future when information is truly findable all around us. there are immense implications, and morville's lively and humorous writing brings them home.""</i><br>  --marcia j. bates, ph.d., university of california los angeles</br></p>  <p>  <i>""i've always known that peter morville was smart. after reading ambient findability, i now know he's (as we say in boston) wicked smart. this is a timely book that will have lasting effects on how we create our future.</i><br>  --jared spool, founding principal, user interface engineering</br></p>  <p>  <i>""in ambient findability, peter morville has put his mind and keyboard on the pulse of the electronic noosphere. with tangible examples and lively writing, he lays out the challenges and wonders of finding our way in cyberspace, and explains the mutually dependent evolution of our changing world and selves. this is a must read for everyone and a practical guide for designers.""</i><br>  --gary marchionini, ph.d., university of north carolina</br></p>  <p>  <i>""find this book! anyone interested in making information easier to find, or understanding how finding and being found is changing, will find this thoroughly researched, engagingly written, literate, insightful and very, very cool book well worth their time. myriad examples from rich and varied domains and a valuable idea on nearly every page. fun to read, too!</i><br>  --joseph janes, ph.d., founder, internet public library</br></p>}"
90557,article,science,,,american association for the advancement of science,3,286,5439,1999,oct,2005-02-09 21:05:22,"department of physics, university of notre dame, notre dame, in 46556, usa.",emergence of scaling in random networks,
5913660,article,science,,,american association for the advancement of science,4,326,5950,2009,oct,2009-10-09 03:21:11,,comprehensive mapping of {long-range} interactions reveals folding principles of the human genome,"we describe {hi-c}, a method that probes the three-dimensional architecture of whole genomes by coupling proximity-based ligation with massively parallel sequencing. we constructed spatial proximity maps of the human genome with {hi-c} at a resolution of 1 megabase. these maps confirm the presence of chromosome territories and the spatial proximity of small, gene-rich chromosomes. we identified an additional level of genome organization that is characterized by the spatial segregation of open and closed chromatin to form two genome-wide compartments. at the megabase scale, the chromatin conformation is consistent with a fractal globule, a knot-free, polymer conformation that enables maximally dense packing while preserving the ability to easily fold and unfold any genomic locus. the fractal globule is distinct from the more commonly used globular equilibrium model. our results demonstrate the power of {hi-c} to map the dynamic conformations of whole genomes."
1033358,article,siam review,,,siam,89,45,2,2003,,2007-01-15 20:43:39,,the structure and function of complex networks,"inspired by empirical studies of networked systems such as the internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks."
920055,article,genome research,,,cold spring harbor laboratory press,6,13,11,2003,nov,2006-10-31 10:30:16,"institute for systems biology, seattle, washington 98103, usa.",cytoscape: a software environment for integrated models of biomolecular interaction networks,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
305879,book,,,,oxford university press,,,,1977,aug,2005-11-27 21:34:00,,"a pattern language: towns, buildings, construction (center for environmental structure)",
241030,article,proceedings of the national academy of sciences,,,national academy of sciences,5,100,16,2003,aug,2005-06-30 18:30:23,"department of biostatistics, university of washington, seattle, wa 98195, usa. jstorey@u.washington.edu",statistical significance for genomewide studies,"with the increase in genomewide experiments and the sequencing of multiple genomes, the analysis of large data sets has become commonplace in biology. it is often the case that thousands of features in a genomewide data set are tested against some null hypothesis, where a number of features are expected to be significant. here we propose an approach to measuring statistical significance in these genomewide studies based on the concept of the false discovery rate. this approach offers a sensible balance between the number of true and false positives that is automatically calibrated and easily interpreted. in doing so, a measure of statistical significance called the q value is associated with each tested feature. the q value is similar to the well known p value, except it is a measure of significance in terms of the false discovery rate rather than the false positive rate. our approach avoids a flood of false positive results, while offering a more liberal criterion than what has been used in genome scans for linkage."
336118,article,physical review e,,,american physical society,,68,3,2003,sep,2005-09-30 10:20:41,,why social networks are different from other types of networks,"we argue that social networks differ from most other types of networks, including technological and biological networks, in two important ways. first, they have nontrivial clustering or network transitivity and second, they show positive correlations, also called assortative mixing, between the degrees of adjacent vertices. social networks are often divided into groups or communities, and it has recently been suggested that this division could account for the observed clustering. we demonstrate that group structure in networks can also account for degree correlations. we show using a simple model that we should expect assortative mixing in such networks whenever there is variation in the sizes of the groups and that the predicted level of assortative mixing compares well with that observed in real-world networks."
6346339,article,nature biotechnology,nat biotech,,nature publishing group,2,27,12,2009,dec,2009-12-09 23:25:07,,how does multiple testing correction work?,"when prioritizing hits from a high-throughput experiment, it is important to correct for random events that falsely appear significant. how is this done and what methods should be used?"
1263124,article,plos comput biol,,,public library of science,,3,4,2007,apr,2007-04-28 12:32:03,,ten simple rules for making good oral presentations,
664041,inproceedings,,chi,chi,acm,3,,,2006,,2006-05-22 08:30:55,"new york, ny, usa",why do tagging systems work?,"the panel will explore the relevance of the emerging tagging systems (flickr, del.icio.us, {rawsugar} and more). why do they seem to work? what kinds of incentives are required for users to participate? will tagging survive and scale to mass adoption? what are the behavioral, economic, and social models that underlie each tagging system? what are the dynamics of those systems, and how are they derived from the specific application's design and {affordances?.we} will demand answers to these questions and others from some of the pioneering practitioners and academics in the field. bring your wireless laptop to participate in a live tagging experiment! the experiment results will be shown and discussed at the end of the panel. to add to the fun, parts of the discussion will be motivated by short video segments."
477450,article,nature,,,nature publishing group,5,440,7084,2006,jan,2006-01-25 04:59:31,,proteome survey reveals modularity of the yeast cell machinery,"protein complexes are key molecular entities that integrate multiple gene products to perform cellular functions. here we report the first genome-wide screen for complexes in an organism, budding yeast, using affinity purification and mass spectrometry. through systematic tagging of open reading frames ({orfs}), the majority of complexes were purified several times, suggesting screen saturation. the richness of the data set enabled a de novo characterization of the composition and organization of the cellular machinery. the ensemble of cellular proteins partitions into 491 complexes, of which 257 are novel, that differentially combine with additional attachment proteins or protein modules to enable a diversification of potential functions. support for this modular organization of the proteome comes from integration with available data on expression, localization, function, evolutionary conservation, protein structure and binary interactions. this study provides the largest collection of physically determined eukaryotic cellular machines so far and a platform for biological data integration and modelling."
201641,book,,,,the university of chicago press,,,,1996,dec,2005-05-16 22:28:45,,"the structure of scientific revolutions, 3rd edition","{there's a ""frank \& ernest"" comic strip showing a chick breaking out of its shell, looking around, and saying, ""oh, wow! paradigm shift!"" blame the late thomas kuhn. few indeed are the philosophers or historians influential enough to make it into the funny papers, but kuhn is one.<p>  <i>the structure of scientific revolutions</i> is indeed a paradigmatic work in the history of science. kuhn's use of terms such as ""paradigm shift"" and ""normal science,"" his ideas of how scientists move from disdain through doubt to acceptance of a new theory, his stress on social and psychological factors in science--all have had profound effects on historians, scientists, philosophers, critics, writers, business gurus, and even the cartoonist in the street.<p>  some scientists (such as steven weinberg and ernst mayr) are profoundly irritated by kuhn, especially by the doubts he casts--or the way  his work has been used to cast doubt--on the idea of scientific progress. yet it has been said that the acceptance of plate tectonics in the 1960s, for instance, was sped by geologists' reluctance to be on the downside of a paradigm shift. even weinberg has said that ""<i>structure</i> has had a wider influence than any other book on the history of science."" as one of kuhn's obituaries noted, ""we all live in a post-kuhnian age."" <i>--mary ellen curtin</i> }"
4202607,article,"bioinformatics (oxford, england)",,,oxford university press,1,25,11,2009,jun,2009-03-21 11:58:12,,biopython: freely available python tools for computational molecular biology and bioinformatics.,"the biopython project is a mature open source international collaboration of volunteer developers, providing python libraries for a wide range of bioinformatics problems. biopython includes modules for reading and writing different sequence file formats and multiple sequence alignments, dealing with {3d} macro molecular structures, interacting with common tools such as {blast}, {clustalw} and {emboss}, accessing key online databases, as well as providing numerical methods for statistical learning. biopython is freely available, with documentation and source code at (www.biopython.org) under the biopython license."
165117,inproceedings,,proceedings of the 2004 acm conference on computer supported cooperative work,cscw,acm,9,,,2004,,2005-04-19 19:59:44,"new york, ny, usa",using social psychology to motivate contributions to online communities,"under-contribution is a problem for many online communities. social psychology theories of social loafing and goal-setting can provide mid-level design principles to address this problem. we tested the design principles in two field experiments. in one, members of an online movie recommender community were reminded of the uniqueness of their contributions and the benefits that follow from them. in the second, they were given a range of individual or group goals for contribution. as predicted by theory, individuals contributed when they were reminded of their uniqueness and when they were given specific and challenging goals, but other predictions were not borne out. the paper ends with suggestions and challenges for mining social science theories as well as implications for design."
244827,book,,,,{sage publications},,,,2000,jan,2005-07-04 18:17:47,,social network analysis: a handbook,"{the revised and updated edition of this bestselling text provides an accessible introduction to the theory and practice of network analysis in the social sciences. it gives a clear and authoritative guide to the general framework of network analysis, explaining the basic concepts, technical measures and reviewing the available computer programs.<p></p><p>the book outlines both the theoretical basis of network analysis and the key techniques for using it as a research tool. building upon definitions of points, lines and paths, john scott demonstrates their use in clarifying such measures as density, fragmentation and centralization. he identifies the various cliques, components and circles into which networks are formed, and outlines an approach to the study of socially structured positions. he also discusses the use of multidimensional methods for investigating social networks.</p><p></p><p><b>social network analysis</b> is an invaluable resource for researchers across the social sciences and for students of social theory and research methods.</p>}"
1279898,inproceedings,,proceedings of the sigchi conference on human factors in computing systems,chi,acm,9,,,2007,,2007-05-05 20:33:20,"new york, ny, usa",why we tag: motivations for annotation in mobile and online media,"why do people tag? users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. we investigate the incentives for annotation in flickr, a popular web-based photo-sharing system, and {zonetag}, a cameraphone photo capture and annotation tool that uploads images to flickr. in flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. {zonetag}, in turn, makes it easier to tag cameraphone photos that are uploaded to flickr by allowing annotation and suggesting relevant tags immediately after capture. a qualitative study of {zonetag}/flickr users exposed various tagging patterns and emerging motivations for photo annotation. we offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation."
6043685,article,nat meth,nat meth,,nature publishing group,10,6,11s,2009,nov,2009-10-30 17:15:59,,computation for {chip}-seq and {rna}-seq studies,"genome-wide measurements of {protein-dna} interactions and transcriptomes are increasingly done by deep {dna} sequencing methods ({chip}-seq and {rna}-seq). the power and richness of these counting-based measurements comes at the cost of routinely handling tens to hundreds of millions of reads. whereas early adopters necessarily developed their own custom computer code to analyze the first {chip}-seq and {rna}-seq datasets, a new generation of more sophisticated algorithms and software tools are emerging to assist in the analysis phase of these projects. here we describe the multilayered analyses of {chip}-seq and {rna}-seq datasets, discuss the software packages currently available to perform tasks at each layer and describe some upcoming challenges and features for future analysis tools. we also discuss how software choices and uses are affected by specific aspects of the underlying biology and data structure, including genome size, positional clustering of transcription factor binding sites, transcript discovery and expression quantification."
3623940,article,science,,,american association for the advancement of science,5,323,5910,2009,jan,2008-11-20 22:53:43,,{real-time} {dna} sequencing from single polymerase molecules,"we present single-molecule, real-time sequencing data obtained from a {dna} polymerase performing uninterrupted template-directed synthesis using four distinguishable fluorescently labeled deoxyribonucleoside triphosphates ({dntps}). we detected the temporal order of their enzymatic incorporation into a growing {dna} strand with zero-mode waveguide nanostructure arrays, which provide optical observation volume confinement and enable parallel, simultaneous detection of thousands of single-molecule sequencing reactions. conjugation of fluorophores to the terminal phosphate moiety of the {dntps} allows continuous observation of {dna} synthesis over thousands of bases without steric hindrance. the data report directly on polymerase dynamics, revealing distinct polymerization states and pause sites corresponding to {dna} secondary structure. sequence data were aligned with the known reference sequence to assay biophysical parameters of polymerization for each template position. consensus sequences were generated from the single-molecule reads at 15-fold coverage, showing a median accuracy of 99.3\%, with no systematic error beyond fluorophore-dependent error rates."
2709781,book,,,,cambridge university press,,,,2008,jul,2008-04-23 19:59:52,cambridge,introduction to information retrieval,"""class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. all the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures."" -- publisher's description."
478707,article,nature,,,nature publishing group,1,411,6833,2001,may,2006-01-24 10:12:20,,lethality and centrality in protein networks,"proteins are traditionally identified on the basis of their individual actions as catalysts, signalling molecules, or building blocks in cells and microorganisms. but our post-genomic view is expanding the protein's role into an element in a network of protein–protein interactions as well, in which it has a contextual or cellular function within functional modules1, 2. here we provide quantitative support for this idea by demonstrating that the phenotypic consequence of a single gene deletion in the yeast saccharomyces cerevisiae is affected to a large extent by the topological position of its protein product in the complex hierarchical web of molecular interactions."
468899,article,d-lib magazine,,,,,12,1,2006,,2006-01-18 12:33:50,,folksonomies: tidying up tags?,"a folksonomy is a type of distributed classification system. it is usually created by a group of individuals, typically the resource users. users add tags to online items, such as images, videos, bookmarks and text. these tags are then shared and sometimes refined. a general review of social bookmarking tools, one popular use area of folksonomies, was given in the april edition of {d-lib} [1]. in the article the authors elaborate on the approach taken by social classification systems and the motivators behind tagging. they write, ""...tags are just one kind of metadata and are not a replacement for formal classification systems such as dublin core, {mods"
4117809,article,genome research,,,cold spring harbor laboratory press,6,19,6,2009,jun,2009-03-02 01:17:50,,{abyss}: a parallel assembler for short read sequence data,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
459365,article,science,,,american association for the advancement of science,2,311,5757,2006,jan,2006-01-13 06:08:51,,empirical analysis of an evolving social network,"social networks evolve over time, driven by the shared activities and affiliations of their members, by similarity of individuals' attributes, and by the closure of short network cycles. we analyzed a dynamic social network comprising 43,553 students, faculty, and staff at a large university, in which interactions between individuals are inferred from time-stamped e-mail headers recorded over one academic year and are matched with affiliations and attributes. we found that network evolution is dominated by a combination of effects arising from network topology itself and the organizational structure in which the network is embedded. in the absence of global perturbations, average network properties appear to approach an equilibrium state, whereas individual properties are unstable."
922,article,computer networks and isdn systems,,,,10,30,1--7,1998,,2004-11-22 17:49:53,,the anatomy of a large-scale hypertextual web search engine,"in this paper, we present google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. google is designed to crawl and index the web efficiently and produce much more satisfying search results than existing systems. the prototype with a full text and hyperlink database of at least 24 million pages is available at"
7157821,article,briefings in bioinformatics,,,oxford university press,10,11,5,2010,sep,2010-05-12 10:29:45,,a survey of sequence alignment algorithms for next-generation sequencing,"rapidly evolving sequencing technologies produce data on an unparalleled scale. a central challenge to the analysis of this data is sequence alignment, whereby sequence reads must be compared to a reference. a wide variety of alignment algorithms and software have been subsequently developed over the past two years. in this article, we will systematically review the current development of these algorithms and introduce their practical applications on different types of experimental data. we come to the conclusion that short-read alignment is no longer the bottleneck of data analyses. we also consider future development of alignment algorithms with respect to emerging long sequence reads and the prospect of cloud computing."
2212959,article,commun. acm,,,acm,6,51,1,2008,jan,2008-01-10 03:49:25,"new york, ny, usa",{mapreduce}: simplified data processing on large clusters,"{mapreduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. programmers find the system easy to use: more than ten thousand distinct {mapreduce} programs have been implemented internally at google over the past four years, and an average of one hundred thousand {mapreduce} jobs are executed on google's clusters every day, processing a total of more than twenty petabytes of data per day."
3746363,article,microbiology and molecular biology reviews,,,american society for microbiology,21,72,4,2008,dec,2008-12-04 12:34:48,,a bioinformatician's guide to metagenomics,"summary: as random shotgun metagenomic projects proliferate and become the dominant source of publicly available sequence data, procedures for the best practices in their execution and analysis become increasingly important. based on our experience at the joint genome institute, we describe the chain of decisions accompanying a metagenomic project from the viewpoint of the bioinformatic analysis step by step. we guide the reader through a standard workflow for a metagenomic project beginning with presequencing considerations such as community composition and sequence data type that will greatly influence downstream analyses. we proceed with recommendations for sampling and data generation including sample and metadata collection, community profiling, construction of shotgun libraries, and sequencing strategies. we then discuss the application of generic sequence processing steps (read preprocessing, assembly, and gene prediction and annotation) to metagenomic data sets in contrast to genome projects. different types of data analyses particular to metagenomes are then presented, including binning, dominant population analysis, and gene-centric analysis. finally, data management issues are presented and discussed. we hope that this review will assist bioinformaticians and biologists in making better-informed decisions on their journey during a metagenomic project."
7203126,article,"science (new york, n.y.)",,,american association for the advancement of science,4,329,5987,2010,jul,2010-05-20 18:55:26,,creation of a bacterial cell controlled by a chemically synthesized genome.,
6699577,article,bmc bioinformatics,bmc bioinformatics,,biomed central,-81,11,1,2010,feb,2010-02-18 19:33:31,,evaluation of statistical methods for normalization and differential expression in {mrna}-seq experiments,"{background}:high-throughput sequencing technologies, such as the illumina genome analyzer, are powerful new tools for investigating a wide range of biological and medical questions. statistical and computational methods are key for drawing meaningful and accurate conclusions from the massive and complex datasets generated by the sequencers. we provide a detailed evaluation of statistical methods for normalization and differential expression ({de}) analysis of illumina transcriptome sequencing ({mrna}-seq) {data.results}:we compare statistical methods for detecting genes that are significantly {de} between two types of biological samples and find that there are substantial differences in how the test statistics handle low-count genes. we evaluate how {de} results are affected by features of the sequencing platform, such as, varying gene lengths, base-calling calibration method (with and without phi x control lane), and flow-cell/library preparation effects. we investigate the impact of the read count normalization method on {de} results and show that the standard approach of scaling by total lane counts (e.g., {rpkm}) can bias estimates of {de}. we propose more general quantile-based normalization procedures and demonstrate an improvement in {de} {detection.conclusions}:our results have significant practical and methodological implications for the design and analysis of {mrna}-seq experiments. they highlight the importance of appropriate statistical methods for normalization and {de} inference, to account for features of the sequencing platform that could impact the accuracy of results. they also reveal the need for further research in the development of statistical and computational methods for {mrna}-seq."
261749,book,,,,harvard university press,,,,1978,mar,2005-07-21 18:09:44,,mind in society: the development of higher psychological processes,
5759073,article,nature reviews. genetics,,,nature publishing group,11,10,10,2009,oct,2009-09-09 15:04:02,,{chip}-seq: advantages and challenges of a maturing technology.,"chromatin immunoprecipitation followed by sequencing ({chip}-seq) is a technique for genome-wide profiling of {dna}-binding proteins, histone modifications or nucleosomes. owing to the tremendous progress in next-generation sequencing technology, {chip}-seq offers higher resolution, less noise and greater coverage than its array-based predecessor {chip}-chip. with the decreasing cost of sequencing, {chip}-seq has become an indispensable tool for studying gene regulation and epigenetic mechanisms. in this review, i describe the benefits and challenges in harnessing this technique with an emphasis on issues related to experimental design and data analysis. {chip}-seq experiments generate large quantities of data, and effective computational analysis will be crucial for uncovering biological mechanisms."
148945,book,,,,mcgraw-hill science/engineering/math,,,,1997,mar,2005-04-03 21:01:30,,machine learning,"{this book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. the book is intended to support upper level undergraduate and introductory level graduate courses in machine learning.}"
975331,inproceedings,,proceedings of the 12th acm sigkdd international conference on knowledge discovery and data mining,kdd,acm,6,,,2006,,2006-12-05 14:42:30,"new york, ny, usa",structure and evolution of online social networks,"in this paper, we consider the evolution of structure within large online social networks. we present a series of measurements of two such networks, together comprising in excess of five million people and ten million friendship links, annotated with metadata capturing the time of every event in the life of the network. our measurements expose a surprising segmentation of these networks into three regions: singletons who do not participate in the network; isolated communities which overwhelmingly display star structure; and a giant component anchored by a well-connected core region which persists even in the absence of {stars.we} present a simple model of network growth which captures these aspects of component structure. the model follows our experimental results, characterizing users as either passive members of the network; inviters who encourage offline friends and acquaintances to migrate online; and linkers who fully participate in the social evolution of the network."
9345497,article,nature methods,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",8,8,6,2011,jun,2011-05-27 19:23:18,,computational methods for transcriptome annotation and quantification using {rna}-seq.,"high-throughput {rna} sequencing ({rna}-seq) promises a comprehensive picture of the transcriptome, allowing for the complete annotation and quantification of all genes and their isoforms across samples. realizing this promise requires increasingly complex computational methods. these computational challenges fall into three main categories: (i) read mapping, (ii) transcriptome reconstruction and (iii) expression quantification. here we explain the major conceptual and practical challenges, and the general classes of solutions for each category. finally, we highlight the interdependence between these categories and discuss the benefits for different biological applications."
270463,article,nature,nature,,nature publishing group,4,437,7057,2005,jul,2005-09-15 07:31:37,,genome sequencing in microfabricated high-density picolitre reactors,"the proliferation of large-scale {dna}-sequencing projects in recent years has driven a search for alternative methods to reduce time and cost. here we describe a scalable, highly parallel sequencing system with raw throughput significantly greater than that of state-of-the-art capillary electrophoresis instruments. the apparatus uses a novel fibre-optic slide of individual wells and is able to sequence 25 million bases, at 99\% or better accuracy, in one four-hour run. to achieve an approximately 100-fold increase in throughput over current sanger sequencing technology, we have developed an emulsion method for {dna} amplification and an instrument for sequencing by synthesis using a pyrosequencing protocol optimized for solid support and picolitre-scale volumes. here we show the utility, throughput, accuracy and robustness of this system by shotgun sequencing and de novo assembly of the mycoplasma genitalium genome with 96\% coverage at 99.96\% accuracy in one run of the machine."
332255,article,nature,,,nature publishing group,5,402,6761 Suppl,1999,dec,2005-09-26 02:40:38,"fred hutchinson cancer center, seattle, washington 98109, usa.",from molecular to modular cell biology.,"cellular functions, such as signal transmission, are carried out by 'modules' made up of many species of interacting molecules. understanding how modules work has depended on combining phenomenological analysis with molecular studies. general principles that govern the structure and behaviour of modules may be discovered with help from synthetic sciences such as engineering and computer science, from stronger interactions between experiment and theory in cell biology, and from an appreciation of evolutionary constraints."
142465,article,sociological theory,social structure and network analysis,,sage publications,32,1,,1982,,2005-12-09 01:53:37,"beverly hills, ca",the strength of weak ties: a network theory revisited,"in this chapter i review empirical studies directly testing the hypotheses of my 1973 paper ""the strength of weak ties"" (hereafter ""{swt}"") and work that elaborates those hypotheses theoretically or uses them to suggest new empirical research not discussed in my original formulation. along the way, i will reconsider various aspects of the theoretical argument, attempt to plug some holes, and broaden its base."
7355647,article,nature,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",3,466,7307,2010,aug,2010-06-24 08:15:19,,link communities reveal multiscale complexity in networks.,"networks have become a key approach to understanding systems of interacting objects, unifying the study of diverse phenomena including biological organisms and human society. one crucial step when studying the structure and dynamics of networks is to identify communities: groups of related nodes that correspond to functional subunits such as protein complexes or social spheres. communities in networks often overlap such that nodes simultaneously belong to several groups. meanwhile, many networks are known to possess hierarchical organization, where communities are recursively grouped into a hierarchical structure. however, the fact that many real networks have communities with pervasive overlap, where each and every node belongs to more than one group, has the consequence that a global hierarchy of nodes cannot capture the relationships between overlapping groups. here we reinvent communities as groups of links rather than nodes and show that this unorthodox approach successfully reconciles the antagonistic organizing principles of overlapping communities and hierarchy. in contrast to the existing literature, which has entirely focused on grouping nodes, link communities naturally incorporate overlap while revealing hierarchical organization. we find relevant link communities in many networks, including major biological networks such as protein-protein interaction and metabolic networks, and show that a large social network contains hierarchically organized community structures spanning inner-city to regional scales while maintaining pervasive overlap. our results imply that link communities are fundamental building blocks that reveal overlap and hierarchical organization in networks to be two aspects of the same phenomenon."
248,article,"science (new york, n.y.)",,,american association for the advancement of science,2,295,5560,2002,mar,2004-11-12 15:27:40,"sony computer science laboratories, inc., 3-14-13 higashi-gotanda, shinagawa, tokyo 141-0022, japan. kitano@csl.sony.co.jp",systems biology: a brief overview.,"to understand biology at the system level, we must examine the structure and dynamics of cellular and organismal function, rather than the characteristics of isolated parts of a cell or organism. properties of systems, such as robustness, emerge as central issues, and understanding these properties may have an impact on the future of medicine. however, many breakthroughs in experimental devices, advanced software, and analytical methods are required before the achievements of systems biology can live up to their much-touted potential."
217178,book,,,,addison wesley,,,,1999,may,2005-06-02 22:50:32,,modern information retrieval,
1116998,article,molecular systems biology,,,nature publishing group,,3,1,2007,feb,2007-02-21 21:52:46,,how to infer gene networks from expression profiles.,"inferring, or 'reverse-engineering', gene networks can be defined as the process of identifying gene interactions from experimental data through computational analysis. gene expression data from microarrays are typically used for this purpose. here we compared different reverse-engineering algorithms for which ready-to-use software was available and that had been tested on experimental data sets. we show that reverse-engineering algorithms are indeed able to correctly infer regulatory interactions among genes, at least when one performs perturbation experiments complying with the algorithm requirements. these algorithms are superior to classic clustering algorithms for the purpose of finding regulatory interactions among genes, and, although further improvements are needed, have reached a discreet performance for being practically useful."
46,article,nature,,,nature publishing group,4,417,6887,2002,may,2004-11-04 02:28:11,"european molecular biology laboratory, meyerhofstrasse 1, 69012 heidelberg, germany.",comparative assessment of large-scale data sets of protein-protein interactions,"comprehensive protein protein interaction maps promise to reveal many aspects of the complex regulatory network underlying cellular function. recently, large-scale approaches have predicted many new protein interactions in yeast. to measure their accuracy and potential as well as to identify biases, strengths and weaknesses, we compare the methods with each other and with a reference set of previously reported protein interactions."
9753548,article,nat rev genet,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",11,12,10,2011,oct,2011-09-08 17:04:31,,next-generation transcriptome assembly,"transcriptomics studies often rely on partial reference transcriptomes that fail to capture the full catalogue of transcripts and their variations. recent advances in sequencing technologies and assembly algorithms have facilitated the reconstruction of the entire transcriptome by deep {rna} sequencing ({rna}-seq), even without a reference genome. however, transcriptome assembly from billions of {rna}-seq reads, which are often very short, poses a significant informatics challenge. this review summarizes the recent developments in transcriptome assembly approaches — reference-based, de novo and combined strategies — along with some perspectives on transcriptome assembly in the near future."
6756679,article,genome biology,genome biology,,biomed central,8,11,3,2010,mar,2010-03-03 11:51:17,,a scaling normalization method for differential expression analysis of {rna}-seq data.,"the fine detail provided by sequencing-based transcriptome surveys suggests that {rna}-seq is likely to become the platform of choice for interrogating steady state {rna}. in order to discover biologically important changes in expression, we show that normalization continues to be an essential step in the analysis. we outline a simple and effective method for performing normalization and show dramatically improved results for inferring differential expression in simulated and publicly available data sets."
129,article,proceedings of the national academy of sciences,,,national academy of sciences,3,97,21,2000,oct,2004-11-08 17:15:37,"center for polymer studies and department of physics, boston university, boston, ma 02215, usa. amaral@buphy.bu.edu",classes of small-world networks,"we study the statistical properties of a variety of diverse real-world networks. we present evidence of the occurrence of three classes of small-world networks: (a) scale-free networks, characterized by a vertex connectivity distribution that decays as a power law; (b) broad-scale networks, characterized by a connectivity distribution that has a power law regime followed by a sharp cutoff; and (c) single-scale networks, characterized by a connectivity distribution with a fast decaying tail. moreover, we note for the classes of broad-scale and single-scale networks that there are constraints limiting the addition of new links. our results suggest that the nature of such constraints may be the controlling factor for the emergence of different classes of networks."
90413,article,computer mediated communication,,,,,,,2004,dec,2005-02-08 16:06:26,,folksonomies - cooperative classification and communication through shared metadata,
4163618,article,plos one,plos one,,public library of science,,4,3,2009,mar,2009-03-11 02:30:29,,clickstream data yields {high-resolution} maps of science,"intricate maps of science have been created from citation data to visualize the structure of scientific activity. however, most scientific publications are now accessed online. scholarly web portals record detailed log data at a scale that exceeds the number of all existing citations combined. such log data is recorded immediately upon publication and keeps track of the sequences of user requests (clickstreams) that are issued by a variety of users across many different domains. given these advantages of log datasets over citation data, we investigate whether they can produce high-resolution, more current maps of science. over the course of 2007 and 2008, we collected nearly 1 billion user interactions recorded by the scholarly web portals of some of the most significant publishers, aggregators and institutional consortia. the resulting reference data set covers a significant part of world-wide use of scholarly web portals in 2006, and provides a balanced coverage of the humanities, social sciences, and natural sciences. a journal clickstream model, i.e. a first-order markov chain, was extracted from the sequences of user interactions in the logs. the clickstream model was validated by comparing it to the getty research institute's architecture and art thesaurus. the resulting model was visualized as a journal network that outlines the relationships between various scientific domains and clarifies the connection of the social sciences and humanities to the natural sciences. maps of science resulting from large-scale clickstream data provide a detailed, contemporary view of scientific activity and correct the underrepresentation of the social sciences and humanities that is commonly found in citation data."
266187,article,"science (new york, n.y.)",,,american association for the advancement of science,4,290,5500,2000,dec,2005-07-27 22:07:17,"department of psychology, stanford university, stanford, ca 94305, usa. jbt@psych.stanford.edu",a global geometric framework for nonlinear dimensionality reduction.,"scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. the human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. unlike classical techniques such as principal component analysis ({pca}) and multidimensional scaling ({mds}), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. in contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure."
8468415,article,genome biology,,,biomed central ltd,,11,12,2010,dec,2010-12-22 17:45:46,,from {rna}-seq reads to differential expression results,many methods and tools are available for preprocessing high-throughput {rna} sequencing data and detecting differential expression.
4774374,article,bioinformatics,,,oxford university press,1,25,15,2009,aug,2009-06-08 07:52:19,,{soap2}: an improved ultrafast tool for short read alignment,"summary: {soap2} is a significantly improved version of the short oligonucleotide alignment program that both reduces computer memory usage and increases alignment speed at an unprecedented rate. we used a burrows wheeler transformation ({bwt}) compression index to substitute the seed strategy for indexing the reference sequence in the main memory. we tested it on the whole human genome and found that this new algorithm reduced memory usage from 14.7 to 5.4 {gb} and improved alignment speed by 20–30 times. {soap2} is compatible with both single- and paired-end reads. additionally, this tool now supports multiple text and compressed file formats. a consensus builder has also been developed for consensus assembly and {snp} detection from alignment of short reads on a reference {genome.availability}: {http://soap.genomics.org.cncontact}: soap@genomics.org.cn"
1288839,inproceedings,,proceedings of the 16th international conference on world wide web,www,acm,9,,,2007,,2007-05-10 20:43:05,"new york, ny, usa",google news personalization: scalable online collaborative filtering,"several approaches to collaborative filtering have been studied but seldom have studies been reported for large (several millionusers and items) and dynamic (the underlying item set is continually changing) settings. in this paper we describe our approach to collaborative filtering for generating personalized recommendations for users of google news. we generate recommendations using three approaches: collaborative filtering using {minhash} clustering, probabilistic latent semantic indexing ({plsi}), and covisitation counts. we combine recommendations from different algorithms using a linear model. our approach is content agnostic and consequently domain independent, making it easily adaptable for other applications and languages with minimal effort. this paper will describe our algorithms and system setup in detail, and report results of running the recommendations engine on google news."
95914,article,commun. acm,,,acm,5,15,12,1972,dec,2005-02-15 16:43:34,"new york, ny, usa",on the criteria to be used in decomposing systems into modules,"this paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. the effectiveness of a  ” modularization” is dependent upon the criteria used in dividing the system into modules. a system design problem is presented and both a conventional and unconventional decomposition are described. it is shown that the unconventional decompositions have distinct advantages for the goals outlined. the criteria used in arriving at the decompositions are discussed. the unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. an alternative approach to implementation which does not have this effect is sketched."
72879,article,nature biotechnology,,,nature publishing group,7,23,1,2005,jan,2005-10-24 16:46:29,,assessing computational tools for the discovery of transcription factor binding sites,"the prediction of regulatory elements is a problem where computational methods offer great hope. over the past few years, numerous tools have become available for this task. the purpose of the current assessment is twofold: to provide some guidance to users regarding the accuracy of currently available tools in various settings, and to provide a benchmark of data sets for assessing future tools."
4495448,article,nature biotechnology,,,nature publishing group,2,27,5,2009,may,2009-05-10 23:47:19,,how to map billions of short reads onto genomes.,mapping the vast quantities of short sequence fragments produced by next-generation sequencing platforms is a challenge. what programs are available and how do they work?
10401697,article,nature protocols,,,nature research,16,7,3,2012,mar,2012-03-01 16:19:23,,differential gene and transcript expression analysis of {rna}-seq experiments with {tophat} and cufflinks,
163662,book,,,,cambridge university press,,,,2004,mar,2005-04-18 20:01:17,,convex optimization,"{convex optimization problems arise frequently in many different fields. a comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. the focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. the text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.}"
1099,article,personal ubiquitous comput.,personal and ubiquitous computing,,springer-verlag,3,5,1,2001,jan,2004-11-27 18:24:34,"london, uk, uk",understanding and using context,"context is a poorly used source of information in our computing environments. as a result, we have an impoverished understanding of what context is and how it can be used. in this paper, we provide an operational definition of context and discuss the different ways in which context can be used by context-aware applications. we also present the context toolkit, an architecture that supports the building of these context-aware applications. we discuss the features and abstractions in the toolkit that make the task of building applications easier. finally, we introduce a new abstraction, a situation which we believe will provide additional support to application designers."
5907455,article,nature,nature,,nature publishing group,6,461,7265,2009,oct,2009-10-07 21:25:36,,finding the missing heritability of complex diseases.,"genome-wide association studies have identified hundreds of genetic variants associated with complex human diseases and traits, and have provided valuable insights into their genetic architecture. most variants identified so far confer relatively small increments in risk, and explain only a small proportion of familial clustering, leading many to question how the remaining, 'missing' heritability can be explained. here we examine potential sources of missing heritability and propose research strategies, including and extending beyond current genome-wide association approaches, to illuminate the genetics of complex diseases and enhance its potential to enable effective disease prevention or treatment."
227174,article,nature,,,nature publishing group,5,430,6995,2004,jul,2005-06-14 03:31:29,,evidence for dynamically organized modularity in the yeast protein-protein interaction network,
318263,article,genome research,,,cold spring harbor laboratory press,8,12,4,2002,apr,2005-09-13 17:15:06,"department of biology and center for molecular biology of rna, university of california-santa cruz, santa cruz, ca 95064, usa. kent@biology.ucsc.edu",{blat}—the {blast}-like alignment tool,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
2862276,article,nature,,,nature publishing group,3,453,7196,2008,jun,2008-06-05 04:06:24,,understanding individual human mobility patterns,"despite their importance for urban planning1, traffic forecasting2 and the spread of biological3, 4, 5 and mobile viruses6, our understanding of the basic laws governing human motion remains limited owing to the lack of tools to monitor the time-resolved location of individuals. here we study the trajectory of 100,000 anonymized mobile phone users whose position is tracked for a six-month period. we find that, in contrast with the random trajectories predicted by the prevailing l\'{e}vy flight and random walk models7, human trajectories show a high degree of temporal and spatial regularity, each individual being characterized by a time-independent characteristic travel distance and a significant probability to return to a few highly frequented locations. after correcting for differences in travel distances and the inherent anisotropy of each trajectory, the individual travel patterns collapse into a single spatial probability distribution, indicating that, despite the diversity of their travel history, humans follow simple reproducible patterns. this inherent similarity in travel patterns could impact all phenomena driven by human mobility, from epidemic prevention to emergency response, urban planning and agent-based modelling."
4265776,article,"science (new york, n.y.)",,,american association for the advancement of science,4,324,5923,2009,apr,2009-04-03 04:51:25,,distilling free-form natural laws from experimental data.,"for centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. a key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. we propose a principle for the identification of nontriviality. we demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered hamiltonians, lagrangians, and other laws of geometric and momentum conservation. the discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the ""alphabet"" used to describe those systems."
346450,book,,,,cambridge university press,,,,1999,sep,2005-10-09 17:04:18,,"communities of practice: learning, meaning, and identity (learning in doing: social, cognitive and computational perspectives)",{presents a broad conceptual framework for thinking about learning as a process of social participation.}
5248382,article,"science (new york, n.y.)",,,american association for the advancement of science,1,325,5939,2009,jul,2009-07-24 08:30:04,,scale-free networks: a decade and beyond.,"for decades, we tacitly assumed that the components of such complex systems as the cell, the society, or the internet are randomly wired together. in the past decade, an avalanche of research has shown that many real networks, independent of their age, function, and scope, converge to similar architectures, a universality that allowed researchers from different disciplines to embrace network theory as a common paradigm. the decade-old discovery of scale-free networks was one of those events that had helped catalyze the emergence of network science, a new research field with its distinct set of challenges and accomplishments."
95936,article,phys. rev. e,,,american physical society,,70,6,2004,dec,2005-02-15 17:26:20,,finding community structure in very large networks,"the discovery and analysis of community structure in networks is a topic of considerable recent interest within the physics community, but most methods proposed so far are unsuitable for very large networks because of their computational cost. here we present a hierarchical agglomeration algorithm for detecting community structure which is faster than many competing algorithms: its running time on a network with \$n\$ vertices and \$m\$ edges is \$o(md\phantom{\rule{0.2em}{0ex}}\mathrm{log}\phantom{\rule{0.2em}{0ex}}n)\$ where \$d\$ is the depth of the dendrogram describing the community structure. many real-world networks are sparse and hierarchical, with \$m\ensuremath{\sim}n\$ and \$d\ensuremath{\sim}\mathrm{log}\phantom{\rule{0.2em}{0ex}}n\$, in which case our algorithm runs in essentially linear time, \$o(n\phantom{\rule{0.2em}{0ex}}{\mathrm{log}}^{2}\phantom{\rule{0.2em}{0ex}}n)\$. as an example of the application of this algorithm we use it to analyze a network of items for sale on the web site of a large on-line retailer, items in the network being linked if they are frequently purchased by the same buyer. the network has more than 400 000 vertices and \$2\ifmmode\times\else\texttimes\fi{}{10}^{6}\$ edges. we show that our algorithm can extract meaningful communities from this network, revealing large-scale patterns present in the purchasing habits of customers."
1022500,article,science,,,american association for the advancement of science,3,314,5805,2006,dec,2007-01-02 22:43:01,"program for evolutionary dynamics, department of organismic and evolutionary biology, and department of mathematics, harvard university, cambridge, ma 02138, usa. martin\_nowak@harvard.edu",five rules for the evolution of cooperation,"cooperation is needed for evolution to construct new levels of organization. genomes, cells, multicellular organisms, social insects, and human society are all based on cooperation. cooperation means that selfish replicators forgo some of their reproductive potential to help one another. but natural selection implies competition and therefore opposes cooperation unless a specific mechanism is at work. here i discuss five mechanisms for the evolution of cooperation: kin selection, direct reciprocity, indirect reciprocity, network reciprocity, and group selection. for each mechanism, a simple rule is derived that specifies whether natural selection can lead to cooperation."
880918,article,science,,,american association for the advancement of science,6,313,5795,2006,sep,2006-10-02 09:35:58,"broad institute of massachusetts institute of technology and harvard university, cambridge, ma 02142, usa. justin@broad.mit.edu","the connectivity map: using {gene-expression} signatures to connect small molecules, genes, and disease","to pursue a systematic approach to the discovery of functional connections among diseases, genetic perturbation, and drug action, we have created the first installment of a reference collection of gene-expression profiles from cultured human cells treated with bioactive small molecules, together with pattern-matching software to mine these data. we demonstrate that this ""connectivity map"" resource can be used to find connections among small molecules sharing a mechanism of action, chemicals and physiological processes, and diseases and drugs. these results indicate the feasibility of the approach and suggest the value of a large-scale community connectivity map project."
3281478,article,genome biology,,,biomed central ltd,,9,9,2008,sep,2008-09-17 18:30:52,,model-based analysis of {chip}-seq ({macs}),"we present model-based analysis of {chip}-seq data, {macs}, which analyzes data generated by short read sequencers such as solexa's genome analyzer. {macs} empirically models the shift size of {chip}-seq tags, and uses it to improve the spatial resolution of predicted binding sites. {macs} also uses a dynamic poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. {macs} compares favorably to existing {chip}-seq peak-finding algorithms, and is freely available."
270732,article,commun. acm,,,acm,7,18,11,1975,nov,2005-08-01 12:57:53,"new york, ny, usa",a vector space model for automatic indexing,"in a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. an approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. typical evaluation results are shown, demonstating the usefulness of the model."
333353,article,proceedings of the national academy of sciences of the united states of america,,,national academy of sciences,5,102,39,2005,sep,2005-09-27 19:51:25,"departments of molecular cell biology and physics of complex systems, the weizmann institute of science, rehovot 76100, israel.",spontaneous evolution of modularity and network motifs,"biological networks have an inherent simplicity: they are modular with a design that can be separated into units that perform almost independently. furthermore, they show reuse of recurring patterns termed network motifs. little is known about the evolutionary origin of these properties. current models of biological evolution typically produce networks that are highly nonmodular and lack understandable motifs. here, we suggest a possible explanation for the origin of modularity and network motifs in biology. we use standard evolutionary algorithms to evolve networks. a key feature in this study is evolution under an environment (evolutionary goal) that changes in a modular fashion. that is, we repeatedly switch between several goals, each made of a different combination of subgoals. we find that such  ” modularly varying goals” lead to the spontaneous evolution of modular network structure and network motifs. the resulting networks rapidly evolve to satisfy each of the different goals. such switching between related goals may represent biological evolution in a changing environment that requires different combinations of a set of basic biological functions. the present study may shed light on the evolutionary forces that promote structural simplicity in biological networks and offers ways to improve the evolutionary design of engineered systems."
9277950,article,nature,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",6,473,7346,2011,may,2011-05-11 18:54:12,,controllability of complex networks,
613999,electronic,,,,,,,,2006,may,2006-05-05 06:07:46,,collaborative tagging and semiotic dynamics,
141840,article,proceedings of the national academy of sciences,,,national academy of sciences,5,95,25,1998,dec,2005-03-28 01:37:14,"department of genetics, stanford university school of medicine, 300 pasteur avenue, stanford, ca 94305, usa.",cluster analysis and display of genome-wide expression patterns,"a system of cluster analysis for genome-wide expression data from {dna} microarray hybridization is described that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. the output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. we have found in the budding yeast saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. also, coexpression of genes of known function with poorly characterized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently."
222956,article,nature,,,nature publishing group,4,435,7043,2005,jun,2005-12-21 21:12:41,,uncovering the overlapping community structure of complex networks in nature and society,"many complex systems in nature and society can be described in terms of networks capturing the intricate web of connections among the units they are made of1, 2, 3, 4. a key question is how to interpret the global organization of such networks as the coexistence of their structural subunits (communities) associated with more highly interconnected parts. identifying these a priori unknown building blocks (such as functionally related proteins5, 6, industrial sectors7 and groups of people8, 9) is crucial to the understanding of the structural and functional properties of networks. the existing deterministic methods used for large networks find separated communities, whereas most of the actual networks are made of highly overlapping cohesive groups of nodes. here we introduce an approach to analysing the main statistical features of the interwoven sets of overlapping communities that makes a step towards uncovering the modular structure of complex systems. after defining a set of new characteristic quantities for the statistics of communities, we apply an efficient technique for exploring overlapping communities on a large scale. we find that overlaps are significant, and the distributions we introduce reveal universal features of networks. our studies of collaboration, word-association and protein interaction graphs show that the web of communities has non-trivial correlations and specific scaling properties."
4295691,article,"science (new york, n.y.)",,,,3,324,5924,2009,apr,2009-04-10 02:22:29,,coding-sequence determinants of gene expression in escherichia coli.,"synonymous mutations do not alter the encoded protein, but they can influence gene expression. to investigate how, we engineered a synthetic library of 154 genes that varied randomly at synonymous sites, but all encoded the same green fluorescent protein ({gfp}). when expressed in escherichia coli, {gfp} protein levels varied 250-fold across the library. {gfp} messenger {rna} ({mrna}) levels, {mrna} degradation patterns, and bacterial growth rates also varied, but codon bias did not correlate with gene expression. rather, the stability of {mrna} folding near the ribosomal binding site explained more than half the variation in protein levels. in our analysis, {mrna} folding and associated rates of translation initiation play a predominant role in shaping expression levels of individual genes, whereas codon bias influences global translation efficiency and cellular fitness."
249,article,nature,,,nature publishing group,4,420,6912,2002,nov,2004-11-12 15:34:56,"sony computer science laboratories, inc., shinagwa, tokyo, japan. kitano@csl.sony.co.jp",computational systems biology.,"to understand complex biological systems requires the integration of experimental and computational research -- in other words a systems biology approach. computational biology, through pragmatic modelling and theoretical exploration, provides a powerful foundation from which to address critical scientific questions head-on. the reviews in this insight cover many different aspects of this energetic field, although all, in one way or another, illuminate the functioning of modular circuits, including their robustness, design and manipulation. computational systems biology addresses questions fundamental to our understanding of life, yet progress here will lead to practical innovations in medicine, drug discovery and engineering."
678563,article,int. j. comput. vision,international journal of computer vision,,kluwer academic publishers,19,60,2,2004,nov,2006-05-31 16:26:29,"hingham, ma, usa",distinctive image features from {scale-invariant} keypoints,"this paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. the features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in {3d} viewpoint, addition of noise, and change in illumination. the features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. this paper also describes an approach to using these features for object recognition. the recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. this approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
300020,inproceedings,sigops oper. syst. rev.,proceedings of the nineteenth acm symposium on operating systems principles,sosp,acm,14,37,5,2003,oct,2005-08-21 13:10:35,"new york, ny, usa",the google file system,an abstract is not available.
5961524,article,nature,,,macmillan publishers limited. all rights reserved,4,461,7268,2009,oct,2009-10-18 20:18:43,,genome evolution and adaptation in a long-term experiment with escherichia coli,"the relationship between rates of genomic evolution and organismal adaptation remains uncertain, despite considerable interest. the feasibility of obtaining genome sequences from experimentally evolving populations offers the opportunity to investigate this relationship with new precision. here we sequence genomes sampled through 40,000 generations from a laboratory population of escherichia coli. although adaptation decelerated sharply, genomic evolution was nearly constant for 20,000 generations. such clock-like regularity is usually viewed as the signature of neutral evolution, but several lines of evidence indicate that almost all of these mutations were beneficial. this same population later evolved an elevated mutation rate and accumulated hundreds of additional mutations dominated by a neutral signature. thus, the coupling between genomic and adaptive evolution is complex and can be counterintuitive even in a constant environment. in particular, beneficial substitutions were surprisingly uniform over time, whereas neutral substitutions were highly variable."
4238864,article,genome biology,,,,,10,3,2009,,2009-03-31 08:39:38,,evaluation of next generation sequencing platforms for population targeted sequencing studies.,
4041910,article,science,,,american association for the advancement of science,3,323,5916,2009,feb,2009-02-13 01:51:55,,network analysis in the social sciences,"over the past decade, there has been an explosion of interest in network research across the physical and social sciences. for social scientists, the theory of networks has been a gold mine, yielding explanations for social phenomena in a wide variety of disciplines from psychology to economics. here, we review the kinds of things that social scientists have tried to explain using social network analysis and provide a nutshell description of the basic assumptions, goals, and explanatory mechanisms prevalent in the field. we hope to contribute to a dialogue among researchers from across the physical and social sciences who share a common interest in understanding the antecedents and consequences of network phenomena."
498902,article,science,,,american association for the advancement of science,3,297,5584,2002,aug,2006-02-08 15:44:54,"laboratory of cancer biology, center for studies in physics and biology, rockefeller university, new york, ny 10021, usa. elowitm@rockefeller.edu",stochastic gene expression in a single cell,"clonal populations of cells exhibit substantial phenotypic variation. such heterogeneity can be essential for many biological processes and is conjectured to arise from stochasticity, or noise, in gene expression. we constructed strains of escherichia coli that enable detection of noise and discrimination between the two mechanisms by which it is generated. both stochasticity inherent in the biochemical process of gene expression (intrinsic noise) and fluctuations in other cellular components (extrinsic noise) contribute substantially to overall variation. transcription rate, regulatory dynamics, and genetic factors control the amplitude of noise. these results establish a quantitative foundation for modeling noise in genetic networks and reveal how low intracellular copy numbers of molecules can fundamentally limit the precision of gene regulation."
8493482,article,nat rev genet,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",11,12,2,2011,feb,2010-12-30 11:37:09,,"{rna} sequencing: advances, challenges and opportunities",
560813,article,nature,,,nature publishing group,6,440,7084,2006,mar,2006-03-30 17:19:25,,global landscape of protein complexes in the yeast saccharomyces cerevisiae.,"identification of protein-protein interactions often provides insight into protein function, and many cellular processes are performed by stable protein complexes. we used tandem affinity purification to process 4,562 different tagged proteins of the yeast saccharomyces cerevisiae. each preparation was analysed by both matrix-assisted laser desorption/ionization-time of flight mass spectrometry and liquid chromatography tandem mass spectrometry to increase coverage and accuracy. machine learning was used to integrate the mass spectrometry scores and assign probabilities to the protein-protein interactions. among 4,087 different proteins identified with high confidence by mass spectrometry from 2,357 successful purifications, our core data set (median precision of 0.69) comprises 7,123 protein-protein interactions involving 2,708 proteins. a markov clustering algorithm organized these interactions into 547 protein complexes averaging 4.9 subunits per complex, about half of them absent from the {mips} database, as well as 429 additional interactions between pairs of complexes. the data (all of which are available online) will help future studies on individual proteins as well as functional genomics and systems biology."
77453,article,,cscw,,acm press,9,,,2004,,2005-01-13 12:13:54,,"blogging as social activity, or, would you let 900 million people read your diary?",
957831,article,nature,nature,,nature publishing group,10,444,7118,2006,nov,2006-11-22 18:15:13,,global variation in copy number in the human genome.,"copy number variation ({cnv}) of {dna} sequences is functionally significant but has yet to be fully ascertained. we have constructed a first-generation {cnv} map of the human genome through the study of 270 individuals from four populations with ancestry in europe, africa or asia (the {hapmap} collection). {dna} from these individuals was screened for {cnv} using two complementary technologies: single-nucleotide polymorphism ({snp}) genotyping arrays, and clone-based comparative genomic hybridization. a total of 1,447 copy number variable regions ({cnvrs}), which can encompass overlapping or adjacent gains or losses, covering 360 megabases (12\% of the genome) were identified in these populations. these {cnvrs} contained hundreds of genes, disease loci, functional elements and segmental duplications. notably, the {cnvrs} encompassed more nucleotide content per genome than {snps}, underscoring the importance of {cnv} in genetic diversity and evolution. the data obtained delineate linkage disequilibrium patterns for many {cnvs}, and reveal marked variation in copy number among populations. we also demonstrate the utility of this resource for genetic disease studies."
108703,article,science,,,american association for the advancement of science,3,290,5500,2000,dec,2005-03-01 19:34:33,,nonlinear dimensionality reduction by locally linear embedding,"many areas of science depend on exploratory data analysis and visualization. the need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. here, we introduce locally linear embedding ({lle}), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. unlike clustering methods for local dimensionality reduction, {lle} maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. by exploiting the local symmetries of linear reconstructions, {lle} is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text."
531300,article,the journal of chemical physics,,,aip,5,21,6,1953,jun,2006-03-06 13:34:11,,equation of state calculations by fast computing machines,"a general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. the method consists of a modified monte carlo integration over configuration space. results for the two-dimensional rigid-sphere system have been obtained on the los alamos {maniac} and are presented here. these results are compared to the free volume equation of state and to a four-term virial coefficient expansion. the journal of chemical physics is copyrighted by the american institute of physics."
114322,book,,,,addison-wesley professional,,,,2001,apr,2005-03-04 21:41:20,,the wiki way: quick collaboration on the web,"{suitable for system administrators or managers seeking an affordable content-management solution, <i>the wiki way</i> shows off how to take advantage of wiki collaborative software, which allows users to post and edit content remotely. this book is all you need to get up and running with this exciting (and free) way to build and manage content.<p>  this text is first and foremost a guide to what wiki software is and how to install, customize, and administer it within your organization. early sections discuss the advantages of wiki web sites, which allow all users to add and edit content. while it might sound like a free-for-all, the authors suggest such web sites have been used successfully in research, business, and education to document project designs, for brainstorming, and for otherwise creating content in a collaborative fashion. case studies for such organizations as georgia tech, new york times digital, and motorola give a glimpse of wiki used in real settings, so you will get a sense of what to expect.<p>  this book is also a guide to the nuts and bolts of downloading and installing wiki and customizing it for your site. sections on basic tweaks to wiki's perl scripts will let you customize your site to match your organization's needs. standout material includes almost three dozen customization tips. this volume is illustrated with actual screen shots of wiki, so you can get a sense of what it is like for users to work together in such an unrestricted fashion. <p>  throughout the text, the authors are suitably upbeat about wiki's prospects for wider adoption, but they are realistic enough to note compromises (such as requiring passwords and restricting edit rights) required in business settings. they also survey the field of wiki open-source projects and clones, as well as other similar content-management solutions (such as zope and the emerging webdav standard).<p>  while it's hard to predict whether wiki-based web sites are for everyone, this book presents the pros and cons of a potentially exciting and useful tool that promotes collaborative content creation. this title can help any organization get going with a wiki web site, from the standpoint of planning, deployment, and basic administration. <i>--richard dragan</i><p>  <b>topics covered:</b><ul><li>collaboration tools explained <li>web-based collaboration <li>webdav <li>introduction to wiki <li>user conventions with wiki <li>survey of wiki open-source projects and clones <li>installing wiki (including apache web server and security issues) <li>using wiki (making notes, wiki used as a pim, content management and links, page editing) <li>how to structure wiki content (suggested default structure: pros and cons) <li>customizing wiki <li>tour of wiki perl scripts and tips for customizing your wiki site <li>wiki add-ons (including spellchecking and uploading files) <li>administration in wiki (viewing events, controlling access and authentication, database administration, and debugging techniques) <li>guidelines for wiki projects (dos and don'ts) <li>wiki case studies for education <li>business and research</ul> }"
166220,article,genome biology,genome biology,,biomed central,-64,5,10,2004,,2005-04-21 14:38:20,"department of biostatistical science, dana-farber cancer institute, 44 binney st, boston, ma 02115, usa. rgentlem@jimmy.harvard.edu",bioconductor: open software development for computational biology and bioinformatics.,"the bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. the goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. we describe details of our aims and methods, identify current challenges, compare bioconductor to other open bioinformatics projects, and provide working examples."
7280291,article,nat rev genet,,,nature publishing group,10,11,7,2010,jul,2010-06-09 09:59:02,,next-generation genomics: an integrative approach,
238,article,nature,,,nature publishing group,3,407,6804,2000,oct,2004-11-12 15:04:14,"department of physics, university of notre dame, indiana 46556, usa.",the large-scale organization of metabolic networks,"in a cell or microorganism, the processes that generate mass, energy, information transfer and cell-fate specification are seamlessly integrated through a complex network of cellular constituents and reactions1. however, despite the key role of these networks in sustaining cellular functions, their large-scale structure is essentially unknown. here we present a systematic comparative mathematical analysis of the metabolic networks of 43 organisms representing all three domains of life. we show that, despite significant variation in their individual constituents and pathways, these metabolic networks have the same topological scaling properties and show striking similarities to the inherent organization of complex non-biological systems2. this may indicate that metabolic organization is not only identical for all living organisms, but also complies with the design principles of robust and error-tolerant scale-free networks2, 3, 4, 5, and may represent a common blueprint for the large-scale organization of interactions among all cellular constituents."
3819677,article,nature protocols,nat. protocols,,nature publishing group,13,4,1,2009,dec,2008-12-22 20:45:42,,systematic and integrative analysis of large gene lists using {david} bioinformatics resources.,"{david} bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. this protocol explains how to use {david}, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. the procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. by following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies."
115243,inproceedings,,proceedings of the ninth acm sigkdd international conference on knowledge discovery and data mining,kdd,acm,9,,,2003,,2005-03-06 14:42:24,"new york, ny, usa",maximizing the spread of influence through a social network,"models for the processes by which ideas and influence propagate through a social network have been studied in a number of domains, including the diffusion of medical and technological innovations, the sudden and widespread adoption of various strategies in game-theoretic settings, and the effects of ""word of mouth"" in the promotion of new products. recently, motivated by the design of viral marketing strategies, domingos and richardson posed a fundamental algorithmic problem for such social network processes: if we can try to convince a subset of individuals to adopt a new product or innovation, and the goal is to trigger a large cascade of further adoptions, which set of individuals should we {target?we} consider this problem in several of the most widely studied models in social network analysis. the optimization problem of selecting the most influential nodes is {np}-hard here, and we provide the first provable approximation guarantees for efficient algorithms. using an analysis framework based on submodular functions, we show that a natural greedy strategy obtains a solution that is provably within 63\% of optimal for several classes of models; our framework suggests a general approach for reasoning about the performance guarantees of algorithms for these types of influence problems in social {networks.we} also provide computational experiments on large collaboration networks, showing that in addition to their provable guarantees, our approximation algorithms significantly out-perform node-selection heuristics based on the well-studied notions of degree centrality and distance centrality from the field of social networks."
801422,inproceedings,,proceedings of the 15th international conference on world wide web,www,acm,9,,,2006,,2006-08-14 22:57:24,"new york, ny, usa",exploring social annotations for the semantic web,"in order to obtain a machine understandable semantics for web resources, research on the semantic web tries to annotate web resources with concepts and relations from explicitly defined formal ontologies. this kind of formal annotation is usually done manually or semi-automatically. in this paper, we explore a complement approach that focuses on the ""social annotations of the web"" which are annotations manually made by normal web users without a pre-defined formal ontology. compared to the formal annotations, although social annotations are coarse-grained, informal and vague, they are also more accessible to more people and better reflect the web resources' meaning from the users' point of views during their actual usage of the web resources. using a social bookmark service as an example, we show how emergent semantics [2] can be statistically derived from the social annotations. furthermore, we apply the derived emergent semantics to discover and search shared web bookmarks. the initial evaluation on our implementation shows that our method can effectively discover semantically related web bookmarks that current social bookmark service can not discover easily."
363166,article,interactions,,,acm,9,7,6,2000,,2005-10-24 00:39:19,"new york, ny, usa",social navigation: techniques for building more usable systems,note: {ocr} errors may be found in this reference list extracted from the full text article.  {acm} has opted to expose the complete list rather than only correct and linked references.
572874,article,nature genetics,,,nature publishing group,10,34,2,2003,may,2006-04-02 03:35:56,"computer science department, stanford university, stanford, california, 94305, usa. eran@cs.stanford.edu",module networks: identifying regulatory modules and their condition-specific regulators from gene expression data,"much of a cell's activity is organized as a network of interacting modules: sets of genes coregulated to respond to different conditions. we present a probabilistic method for identifying regulatory modules from gene expression data. our procedure identifies modules of coregulated genes, their regulators and the conditions under which regulation occurs, generating testable hypotheses in the form 'regulator x regulates module y under conditions w'. we applied the method to a saccharomyces cerevisiae expression data set, showing its ability to identify functionally coherent modules and their correct regulators. we present microarray experiments supporting three novel predictions, suggesting regulatory roles for previously uncharacterized proteins."
302050,article,"science (new york, n.y.)",,,american association for the advancement of science,4,297,5586,2002,aug,2005-08-24 03:24:55,,hierarchical organization of modularity in metabolic networks.,"spatially or chemically isolated functional modules composed of several cellular components and carrying discrete functions are considered fundamental building blocks of cellular organization, but their presence in highly integrated biochemical networks lacks quantitative support. here, we show that the metabolic networks of 43 distinct organisms are organized into many small, highly connected topologic modules that combine in a hierarchical manner into larger, less cohesive units, with their number and degree of clustering following a power law. within escherichia coli, the uncovered hierarchical modularity closely overlaps with known metabolic functions. the identified network architecture may be generic to system-level cellular organization."
438129,article,nature,,,nature publishing group,1,438,7070,2005,dec,2005-12-17 01:31:29,,internet encyclopaedias go head to head,"jimmy wales' wikipedia comes close to britannica in terms of the accuracy of its science entries, a nature investigation finds. {update}: see details of how the data were collected for this article in the supplementary information. {update} 2 (28 march 2006). the results reported in this news story and their interpretation have been disputed by encyclopaedia britannica. nature responded to these objections . one of the extraordinary stories of the internet age is that of wikipedia, a free online encyclopaedia that anyone can edit. this radical and rapidly growing publication, which includes close to 4 million entries, is now a much-used resource."
778023,article,science,,,american association for the advancement of science,3,313,5786,2006,jul,2006-07-28 16:18:56,,reducing the dimensionality of data with neural networks,"high-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. gradient descent can be used for fine-tuning the weights in such ""autoencoder"" networks, but this works well only if the initial weights are close to a good solution. we describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
2620752,article,genome research,,,cold spring harbor laboratory press,8,18,4,2008,apr,2008-04-01 19:32:16,,protein networks in disease.,"during a decade of proof-of-principle analysis in model organisms, protein networks have been used to further the study of molecular evolution, to gain insight into the robustness of cells to perturbation, and for assignment of new protein functions. following these analyses, and with the recent rise of protein interaction measurements in mammals, protein networks are increasingly serving as tools to unravel the molecular basis of disease. we review promising applications of protein networks to disease in four major areas: identifying new disease genes; the study of their network properties; identifying disease-related subnetworks; and network-based disease classification. applications in infectious disease, personalized medicine, and pharmacology are also forthcoming as the available protein network information improves in quality and coverage."
346599,article,networker,,,acm,7,9,3,2005,sep,2005-10-10 04:30:49,"new york, ny, usa",the power of collective intelligence,"though the overall health of the tech sector may have looked bleak a few years back---at least in the eyes of financial analysts---a blend of old and new ideas, evolving technologies, and changing cultural values have recently given the online world new vigor. with content derived primarily by community contribution, popular and influential services like flickr and wikipedia represent the emergence of ""collective intelligence"" as the new driving force behind the evolution of the internet."
105949,book,,,,chapman and hall/crc,,,,2003,jul,2005-02-27 14:40:33,,"bayesian data analysis, second edition (chapman \& {hall/crc} texts in statistical science)","{incorporating new and updated information, this second edition of the bestselling text in bayesian data analysis continues to emphasize practice over theory, describing how to conceptualize, perform, and critique statistical analyses from a bayesian perspective. its world-class authors provide guidance on all aspects of bayesian data analysis and include examples of real statistical analyses, based on their own research, that demonstrate how to solve complicated problems. changes in the new edition include: \&\#183;stronger focus on mcmc\&\#183;revision of the computational advice in part iii\&\#183;new chapters on nonlinear models and decision analysis\&\#183;several additional applied examples from the authors' recent research\&\#183;additional chapters on current models for bayesian data analysis such as nonlinear models, generalized linear mixed models, and more\&\#183;reorganization of chapters 6 and 7 on model checking and data collectionbayesian computation is currently at a stage where there are many reasonable ways to compute any given posterior distribution. however, the best approach is not always clear ahead of time. reflecting this, the new edition offers a more pluralistic presentation, giving advice on performing computations from many perspectives while making clear the importance of being aware that there are different ways to implement any given iterative simulation computation. the new approach, additional examples, and updated information make bayesian data analysis an excellent introductory text and a reference that working scientists will use throughout their professional life.}"
171426,article,"knowledge and data engineering, ieee transactions on",,,,15,17,6,2005,,2005-04-26 13:50:21,,toward the next generation of recommender systems: a survey of the {state-of-the-art} and possible extensions,"this paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. this paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. these extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multcriteria ratings, and a provision of more flexible and less intrusive types of recommendations."
2283763,article,proceedings of the national academy of sciences,,,national academy of sciences,5,105,4,2008,jan,2008-01-24 08:30:49,,maps of random walks on complex networks reveal community structure,"to comprehend the multipartite organization of large-scale biological and social systems, we introduce an information theoretic approach that reveals community structure in weighted and directed networks. we use the probability flow of random walks on a network as a proxy for information flows in the real system and decompose the network into modules by compressing a description of the probability flow. the result is a map that both simplifies and highlights the regularities in the structure and their relationships. we illustrate the method by making a map of scientific communication as captured in the citation patterns of >6,000 journals. we discover a multicentric organization with fields that vary dramatically in size and degree of integration into the network of science. along the backbone of the network—including physics, chemistry, molecular biology, and medicine—information flows bidirectionally, but the map reveals a directional pattern of citation from the applied fields to the basic sciences."
6791223,article,genomics,,,,12,95,6,2010,jun,2010-03-10 11:26:23,,assembly algorithms for next-generation sequencing data,"the emergence of next-generation sequencing platforms led to resurgence of research in whole-genome shotgun assembly algorithms and software. {dna} sequencing data from the roche 454, {illumina/solexa}, and {abi} {solid} platforms typically present shorter read lengths, higher coverage, and different error profiles compared with sanger sequencing data. since 2005, several assembly software packages have been created or revised specifically for de novo assembly of next-generation sequencing data. this review summarizes and compares the published descriptions of packages named {ssake}, {sharcgs}, {vcake}, newbler, celera assembler, euler, velvet, {abyss}, {allpaths}, and {soapdenovo}. more generally, it compares the two standard methods known as the de bruijn graph approach and the overlap/layout/consensus approach to assembly."
6497618,article,bioinformatics,,,oxford university press,10,26,4,2010,feb,2010-01-07 10:57:33,,bioinformatics challenges for genome-wide association studies,"motivation: the sequencing of the human genome has made it possible to identify an informative set of >1 million single nucleotide polymorphisms ({snps}) across the genome that can be used to carry out genome-wide association studies ({gwass}). the availability of massive amounts of {gwas} data has necessitated the development of new biostatistical methods for quality control, imputation and analysis issues including multiple testing. this work has been successful and has enabled the discovery of new associations that have been replicated in multiple studies. however, it is now recognized that most {snps} discovered via {gwas} have small effects on disease susceptibility and thus may not be suitable for improving health care through genetic testing. one likely explanation for the mixed results of {gwas} is that the current biostatistical analysis paradigm is by design agnostic or unbiased in that it ignores all prior knowledge about disease pathobiology. further, the linear modeling framework that is employed in {gwas} often considers only one {snp} at a time thus ignoring their genomic and environmental context. there is now a shift away from the biostatistical approach toward a more holistic approach that recognizes the complexity of the genotype–phenotype relationship that is characterized by significant heterogeneity and gene–gene and gene–environment interaction. we argue here that bioinformatics has an important role to play in addressing the complexity of the underlying genetic basis of common human diseases. the goal of this review is to identify and discuss those {gwas} challenges that will require computational methods."
1453145,article,j. inf. sci.,journal of information science,,"sage publications, inc.",6,34,1,2008,feb,2007-07-13 01:16:09,"thousand oaks, ca, usa",the folksonomy tag cloud: when is it useful?,"the weighted list, known popularly as a 'tag cloud', has appeared on many popular folksonomy-based web-sites. flickr, delicious, technorati and many others have all featured a tag cloud at some point in their history. however, it is unclear whether the tag cloud is actually useful as an aid to finding information. we conducted an experiment, giving participants the option of using a tag cloud or a traditional search interface to answer various questions. we found that where the information-seeking task required specific information, participants preferred the search interface. conversely, where the information-seeking task was more general, participants preferred the tag cloud. while the tag cloud is not without value, it is not sufficient as the sole means of navigation for a folksonomy-based dataset. 10.1177/0165551506078083"
557229,article,biopolymers,,,"wiley subscription services, inc., a wiley company",60,22,12,1983,dec,2006-03-20 18:16:12,"biophysics department, max planck institute of medical research, 6900 heidelberg, federal republic of germany",dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features.,"for a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. we have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern-recognition process of hydrogen-bonded and geometrical features extracted from x-ray coordinates. cooperative secondary structure is recognized as repeats of the elementary hydrogen-bonding patterns  ” turn” and  ” bridge.” repeating turns are  ” helices,” repeating bridges are  ” ladders,” connected ladders are  ” sheets.” geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. local chain  ” chirality” is the torsional handedness of four consecutive cα positions and is positive for right-handed helices and negative for ideal twisted β-sheets. curved pieces are defined as  ” bends.” solvent  ” exposure” is given as the number of water molecules in possible contact with a residue. the end result is a compilation of the primary structure, including {ss} bonds, secondary structure, and solvent exposure of 62 different globular proteins. the presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. the dictionary is also available in computer-readable form for protein structure prediction work."
1369386,article,nature,,,nature publishing group,17,447,7145,2007,jun,2007-06-07 06:47:43,,"genome-wide association study of 14,000 cases of seven common diseases and 3,000 shared controls.","there is increasing evidence that genome-wide association ({gwa}) studies represent a powerful approach to the identification of genes involved in common human diseases. we describe a joint {gwa} study (using the affymetrix {genechip} {500k} mapping array set) undertaken in the british population, which has examined approximately 2,000 individuals for each of 7 major diseases and a shared set of approximately 3,000 controls. case-control comparisons identified 24 independent association signals at p < 5 x 10(-7): 1 in bipolar disorder, 1 in coronary artery disease, 9 in crohn's disease, 3 in rheumatoid arthritis, 7 in type 1 diabetes and 3 in type 2 diabetes. on the basis of prior findings and replication studies thus-far completed, almost all of these signals reflect genuine susceptibility effects. we observed association at many previously identified loci, and found compelling evidence that some loci confer risk for more than one of the diseases studied. across all diseases, we identified a large number of further signals (including 58 loci with single-point p values between 10(-5) and 5 x 10(-7)) likely to yield additional susceptibility loci. the importance of appropriately large samples was confirmed by the modest effect sizes observed at most loci identified. this study thus represents a thorough validation of the {gwa} approach. it has also demonstrated that careful use of a shared control group represents a safe and effective approach to {gwa} analyses of multiple disease phenotypes; has generated a genome-wide genotype database for future studies of common diseases in the british population; and shown that, provided individuals with {non-european} ancestry are excluded, the extent of population stratification in the british population is generally modest. our findings offer new avenues for exploring the pathophysiology of these important disorders. we anticipate that our data, results and software, which will be widely available to other investigators, will provide a powerful resource for human genetics research."
4222049,article,"intelligent systems, ieee","intelligent systems, ieee",,ieee,4,24,2,2009,mar,2009-03-26 12:22:08,"los alamitos, ca, usa",the unreasonable effectiveness of data,"at brown university, there is excitement of having access to the brown corpus, containing one million english words. since then, we have seen several notable corpora that are about 100 times larger, and in 2006, google released a trillion-word corpus with frequency counts for all sequences up to five words long. in some ways this corpus is a step backwards from the brown corpus: it's taken from unfiltered web pages and thus contains incomplete sentences, spelling errors, grammatical errors, and all sorts of other errors. it's not annotated with carefully hand-corrected part-of-speech tags. but the fact that it's a million times larger than the brown corpus outweighs these drawbacks. a trillion-word corpus - along with other web-derived corpora of millions, billions, or trillions of links, videos, images, tables, and user interactions - captures even very rare aspects of human behavior. so, this corpus could serve as the basis of a complete model for certain tasks - if only we knew how to extract the model from the data."
363614,article,science,,,american association for the advancement of science,4,303,5663,2004,mar,2005-10-24 14:40:13,"departments of molecular cell biology, physics of complex systems, and computer science, weizmann institute of science, rehovot 76100, israel.",superfamilies of evolved and designed networks,"complex biological, technological, and sociological networks can be of very different sizes and connectivities, making it difficult to compare their structures. here we present an approach to systematically study similarity in the local structure of networks, based on the significance profile ({sp}) of small subgraphs in the network compared to randomized networks. we find several superfamilies of previously unrelated networks with very similar {sps}. one superfamily, including transcription networks of microorganisms, represents  ” rate-limited” information-processing networks strongly constrained by the response time of their components. a distinct superfamily includes protein signaling, developmental genetic networks, and neuronal wiring. additional superfamilies include power grids, protein-structure networks and geometric networks, world wide web links and social networks, and word-adjacency networks from different languages."
272363,article,briefings in bioinformatics,,,oxford university press,14,6,1,2005,mar,2005-08-03 23:18:37,"department of medical informatics and clinical epidemiology, school of medicine, oregon health \& science university, 3181 s.w. sam jackson park road, portland, or 97239-309, usa. cohenaa@ohsu.edu",a survey of current work in biomedical text mining,"the volume of published biomedical research, and therefore the underlying biomedical knowledge base, is expanding at an increasing rate. among the tools that can aid researchers in coping with this information overload are text mining and knowledge extraction. significant progress has been made in applying text mining to named entity recognition, text classification, terminology extraction, relationship extraction and hypothesis generation. several research groups are constructing integrated flexible text-mining systems intended for multiple uses. the major challenge of biomedical text mining over the next 5–10 years is to make these systems useful to biomedical researchers. this will require enhanced access to full text, better understanding of the feature space of biomedical literature, better methods for measuring the usefulness of systems to users, and continued cooperation with the biomedical research community to ensure that their needs are addressed."
205973,book,,,,harvard business school press,,,,2002,feb,2005-05-20 10:45:48,,the social life of information,
851137,article,the journal of physiology,,,the physiological society,44,117,4,1952,aug,2006-09-20 11:57:06,,a quantitative description of membrane current and its application to conduction and excitation in nerve.,
466068,article,nature,,,nature publishing group,5,431,7004,2004,sep,2006-01-16 14:51:12,,transcriptional regulatory code of a eukaryotic genome,"{dna}-binding transcriptional regulators interpret the genome's regulatory code by binding to specific sequences to induce or repress gene expression1. comparative genomics has recently been used to identify potential cis-regulatory sequences within the yeast genome on the basis of phylogenetic conservation2, 3, 4, 5, 6, but this information alone does not reveal if or when transcriptional regulators occupy these binding sites. we have constructed an initial map of yeast's transcriptional regulatory code by identifying the sequence elements that are bound by regulators under various conditions and that are conserved among saccharomyces species. the organization of regulatory elements in promoters and the environment-dependent use of these elements by regulators are discussed. we find that environment-specific use of regulatory elements predicts mechanistic models for the function of a large population of yeast's transcriptional regulators."
3483363,article,nature,nature,,nature publishing group,6,456,7218,2008,nov,2008-11-05 21:28:59,,accurate whole human genome sequencing using reversible terminator chemistry,"{dna} sequence information underpins genetic research, enabling discoveries of important biological or medical benefit. sequencing projects have traditionally used long (400–800 base pair) reads, but the existence of reference sequences for the human and many other genomes makes it possible to develop new, fast approaches to re-sequencing, whereby shorter reads are compared to a reference to identify intraspecies genetic variation. here we report an approach that generates several billion bases of accurate nucleotide sequence per experiment at low cost. single molecules of {dna} are attached to a flat surface, amplified in situ and used as templates for synthetic sequencing with fluorescent reversible terminator deoxyribonucleotides. images of the surface are analysed to generate high-quality sequence. we demonstrate application of this approach to human genome sequencing on flow-sorted x chromosomes and then scale the approach to determine the genome sequence of a male yoruba from ibadan, nigeria. we build an accurate consensus sequence from >30 average depth of paired 35-base reads. we characterize four million single-nucleotide polymorphisms and four hundred thousand structural variants, many of which were previously unknown. our approach is effective for accurate, rapid and economical whole-genome re-sequencing and many other biomedical applications."
167555,article,j. mach. learn. res.,,,jmlr.org,25,3,,2003,mar,2005-04-22 18:17:10,"cambridge, ma, usa",an introduction to variable and feature selection,"variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. these areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. the objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. the contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods."
658201,article,commun. acm,,,acm,5,49,4,2006,apr,2006-07-08 21:10:21,"new york, ny, usa",exploratory search: from finding to understanding,research tools critical for exploratory search success involve the creation of new interfaces that move the process beyond predictable fact retrieval.
239528,article,"biostatistics (oxford, england)",,,oxford university press,15,4,2,2003,apr,2005-06-28 16:56:27,"department of biostatistics, johns hopkins university, baltimore, md 21205, usa. rafa@jhu.edu","exploration, normalization, and summaries of high density oligonucleotide array probe level data.","in this paper we report exploratory analyses of high-density oligonucleotide array data from the affymetrix {genechip} system with the objective of improving upon currently used measures of gene expression. our analyses make use of three data sets: a small experimental study consisting of five {mgu74a} mouse {genechip} arrays, part of the data from an extensive spike-in study conducted by gene logic and wyeth's genetics institute involving 95 {hg}-{u95a} human {genechip} arrays; and part of a dilution study conducted by gene logic involving 75 {hg}-{u95a} {genechip} arrays. we display some familiar features of the perfect match and mismatch probe ({pm} and {mm}) values of these data, and examine the variance-mean relationship with probe-level data from probes believed to be defective, and so delivering noise only. we explain why we need to normalize the arrays to one another using probe level intensities. we then examine the behavior of the {pm} and {mm} using spike-in data and assess three commonly used summary measures: affymetrix's (i) average difference ({avdiff}) and (ii) {mas} 5.0 signal, and (iii) the li and wong multiplicative model-based expression index ({mbei}). the exploratory data analyses of the probe level data motivate a new summary measure that is a robust multi-array average ({rma}) of background-adjusted, normalized, and log-transformed {pm} values. we evaluate the four expression summary measures using the dilution study data, assessing their behavior in terms of bias, variance and (for {mbei} and {rma}) model fit. finally, we evaluate the algorithms in terms of their ability to detect known levels of differential expression using the spike-in data. we conclude that there is no obvious downside to using {rma} and attaching a standard error ({se}) to this quantity using a linear model which removes probe-specific affinities."
211804,article,nucleic acids research,,,oxford university press,5,32,5,2004,mar,2005-05-26 10:24:04,bob@drive5.com,{muscle}: multiple sequence alignment with high accuracy and high throughput,"we describe {muscle}, a new computer program for creating multiple alignments of protein sequences. elements of the algorithm include fast distance estimation using kmer counting, progressive alignment using a new profile function we call the log‐expectation score, and refinement using tree‐dependent restricted partitioning. the speed and accuracy of {muscle} are compared with {t‐coffee}, {mafft} and {clustalw} on four test sets of reference alignments: {balibase}, {sabmark}, {smart} and a new benchmark, {prefab}. {muscle} achieves the highest, or joint highest, rank in accuracy on each of these sets. without refinement, {muscle} achieves average accuracy statistically indistinguishable from {t‐coffee} and {mafft}, and is the fastest of the tested methods for large numbers of sequences, aligning 5000 sequences of average length 350 in 7 min on a current desktop computer. the {muscle} program, source code and {prefab} test data are freely available at http://www.drive5. com/muscle."
4280,article,plos biol,,,public library of science,,2,12,2004,dec,2004-12-19 17:14:50,"laboratory of populations, rockefeller and columbia universities, new york, new york, usa. cohen@rockefeller.edu","mathematics is biology's next microscope, only better; biology is mathematics' next physics, only better",joel cohen offers a historical and prospective analysis of the relationship between mathematics and biology.
149386,book,,,,harvard business review press,,,,2000,mar,2005-04-05 02:41:12,,the social life of information,"{how many times has your pc crashed today? while gordon moore's now famous law projecting the doubling of computer power every 18 months has more than borne itself out, it's too bad that a similar trajectory projecting the reliability and usefulness of all that power didn't come to pass, as well. advances in information technology are most often measured in the cool numbers of megahertz, throughput, and bandwidth--but, for many us, the experience of these advances may be better measured in hours of frustration.<p>  the gap between the hype of the information age and its reality is often wide and deep, and it's into this gap that john seely brown and paul duguid plunge. not that these guys are luddites--far from it. brown, the chief scientist at xerox and the director of its palo alto research center (parc), and duguid, a historian and social theorist who also works with parc, measure how information technology interacts and meshes with the social fabric. they write, ""technology design often takes aim at the surface of life. there it undoubtedly scores lots of worthwhile hits. but such successes can make designers blind to the difficulty of more serious challenges--primarily the resourcefulness that helps embed certain ways of doing things deep in our lives.""<p>  the authors cast their gaze on the many trends and ideas proffered by infoenthusiasts over the years, such as software agents, ""still a long way from the predicted insertion into the woof and warp of ordinary life""; the electronic cottage that alvin toffler wrote about 20 years ago and has yet to be fully realized; and the rise of knowledge management and the challenges it faces trying to manage how people actually work and learn in the workplace. their aim is not to pass judgment but to help remedy the tunnel vision that prevents technologists from seeing larger the social context that their ideas must ultimately inhabit. <i>the social life of information</i> is a thoughtful and challenging read that belongs on the bookshelf of anyone trying to invent or make sense of the new world of information. <i>--harry c. edwards</i>} {<b>to see the future we can build with information technology, we must look beyond mere information to the social context that creates and gives meaning to it.</b><p>for years pundits have predicted that information technology will obliterate the need for almost everything-from travel to supermarkets to business organizations to social life itself. individual users, however, tend to be more skeptical.  beaten down by info-glut and exasperated by computer systems fraught with software crashes, viruses, and unintelligible error messages, they find it hard to get a fix on the true potential of the digital revolution.<p>john seely brown and paul duguid help us to see through frenzied visions of the future to the real forces for change in society.  they argue that the gap between digerati hype and end-user gloom is largely due to the ""tunnel vision"" that information-driven technologies breed.  we've become so focused on where we think we ought to be-a place where technology empowers individuals and obliterates social organizations-that we often fail to see where we're really going and what's helping us get there.  we need, they argue, to look beyond our obsession with information and individuals to include the critical social networks of which these are always a part.<p>drawing from rich learning experiences at xerox parc, from examples such as ibm, chiat/day advertising, and california's ""virtual university,"" and from historical, social, and cultural research, the authors sharply challenge the futurists' sweeping predictions. they explain how many of the tools, jobs, and organizations seemingly targeted for future extinction in fact provide useful social resources that people will fight to keep. rather than aiming technological bullets at these ""relics,"" we should instead look for ways that the new world of bits can learn from and complement them. <p>arguing elegantly for the important role that human sociability plays, even-perhaps especially-in the world of bits, <b>the social life of information</b> gives us an optimistic look beyond the simplicities of information and individuals.  it shows how a better understanding of the contribution that communities, organizations, and institutions make to learning, working and innovating can lead to the richest possible use of technology in our work and everyday lives.} {drawing from recent research and practical examples across a range of organizations, the social life of information dispels many of the futurists' sweeping predictions that information technology will obliterate the need for everything from travel to supermarkets to business organizations to social life itself. the authors examine the potential and limitations of technology with regard to intelligent software agents, the automated home office, business reorganization for innovation, knowledge management and work practices, the paperless society, and the digital university. arguing eloquently for the important role human sociability plays in the world of bits, brown and duguid give us an optimistic look beyond the simplicities of information and individuals. they show how a better understanding of the contribution that communities, organizations, and institutions make to learning, knowledge, and judgment can lead to the richest possible use of technology in our work and everyday lives.  }"
1288940,inproceedings,,proceedings of the 16th international conference on world wide web,www,acm,9,,,2007,,2007-05-10 23:37:47,"new york, ny, usa",optimizing web search using social annotations,"this paper explores the use of social annotations to improve websearch. nowadays, many services, e.g. del.icio.us, have been developed for web users to organize and share their favorite webpages on line by using social annotations. we observe that the social annotations can benefit web search in two aspects: 1) the annotations are usually good summaries of corresponding webpages; 2) the count of annotations indicates the popularity of webpages. two novel algorithms are proposed to incorporate the above information into page ranking: 1) {socialsimrank} ({ssr})calculates the similarity between social annotations and webqueries; 2) {socialpagerank} ({spr}) captures the popularity of webpages. preliminary experimental results show that {ssr} can find the latent semantic association between queries and annotations, while {spr} successfully measures the quality (popularity) of a webpage from the web users' perspective. we further evaluate the proposed methods empirically with 50 manually constructed queries and 3000 auto-generated queries on a dataset crawledfrom delicious. experiments show that both {ssr} and {sprbenefit} web search significantly."
7706897,article,genome biology,,,biomed central ltd,,11,8,2010,aug,2010-08-25 16:05:23,,"galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences.","increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. galaxy pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis."
384502,article,commun. acm,,,acm,7,21,7,1978,jul,2005-11-09 11:01:14,"new york, ny, usa","time, clocks, and the ordering of events in a distributed system","the concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. a distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. the use of the total ordering is illustrated with a method for solving synchronization problems. the algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become."
1362387,article,"science (new york, n.y.)",,,american association for the advancement of science,5,316,5830,2007,jun,2007-06-04 12:09:26,,genome-wide mapping of in vivo {protein-dna} interactions.,"in vivo {protein-dna} interactions connect each transcription factor with its direct targets to form a gene network scaffold. to map these {protein-dna} interactions comprehensively across entire mammalian genomes, we developed a large-scale chromatin immunoprecipitation assay ({chipseq}) based on direct ultrahigh-throughput {dna} sequencing. this sequence census method was then used to map in vivo binding of the neuron-restrictive silencer factor ({nrsf}; also known as {rest}, for repressor element-1 silencing transcription factor) to 1946 locations in the human genome. the data display sharp resolution of binding position [+/-50 base pairs (bp)], which facilitated our finding motifs and allowed us to identify noncanonical {nrsf}-binding motifs. these {chipseq} data also have high sensitivity and specificity [{roc} (receiver operator characteristic) area >/= 0.96] and statistical confidence (p <10(-4)), properties that were important for inferring new candidate interactions. these include key transcription factors in the gene network that regulates pancreatic islet cell development."
7736929,misc,arxiv e-prints,,,,,,,2010,aug,2010-08-30 08:03:05,,data analysis recipes: fitting a model to data,
9134853,article,nature genetics,,,nature research,7,43,5,2011,apr,2011-04-11 09:41:41,,a framework for variation discovery and genotyping using next-generation {dna} sequencing data,"recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. the amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. we present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) {snp} discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. we here discuss the application of these tools, instantiated in the genome analysis toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass (∼4×) 1000 genomes project datasets."
686555,article,proceedings of the national academy of sciences,,,national academy of sciences,5,103,23,2006,jun,2006-06-06 12:41:09,,modularity and community structure in networks,"many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. the problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. one highly effective approach is the optimization of the quality function known as  ” modularity” over the possible divisions of a network. here i show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which i call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. i illustrate the method with applications to several published network data sets."
270495,article,bioinformatics,bioinformatics,,oxford university press,8,19,2,2003,jan,2005-07-31 22:53:00,"group in biostatistics, university of california, berkeley, ca 94720, usa. bolstad@stat.berkeley.edu",a comparison of normalization methods for high density oligonucleotide array data based on variance and bias,"motivation: when running experiments that involve multiple high density oligonucleotide arrays, it is important to remove sources of variation between arrays of non-biological origin. normalization is a process for reducing this variation. it is common to see non-linear relations between arrays and the standard normalization provided by affymetrix does not perform well in these situations."
849862,article,"automatic control, ieee transactions on",,,ieee,7,19,6,1974,dec,2006-09-19 17:26:06,,a new look at the statistical model identification,the history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. the classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion ({aic}) estimate ({maice}) which is designed for the purpose of statistical identification is introduced. when there are several competing models the {maice} is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of {aic} defined by {aic} = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). {maice} provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. the practical utility of {maice} in time series analysis is demonstrated with some numerical examples.
11191048,article,nature,,,nature research,17,489,7414,2012,sep,2012-09-05 20:21:09,,an integrated encyclopedia of {dna} elements in the human genome,"the human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. the encyclopedia of {dna} elements ({encode}) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. these data enabled us to assign biochemical functions for 80\% of the genome, in particular outside of the well-studied protein-coding regions. many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. the newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research."
1451915,article,"science (new york, n.y.)",,,american association for the advancement of science,9,220,4598,1983,may,2007-07-12 13:09:35,,optimization by simulated annealing.,there is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). a detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. this connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.
686543,article,bmc bioinformatics,,,biomed central ltd,,7,Suppl 1,2006,mar,2006-06-06 12:25:05,"department of biomedical informatics, columbia university, new york, ny 10032, usa. adam@dbmi.columbia.edu",{aracne}: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context,"elucidating gene regulatory networks is crucial for understanding normal cell physiology and complex pathologic phenotypes. existing computational methods for the genome-wide ""reverse engineering"" of such networks have been successful only for lower eukaryotes with simple genomes. here we present {aracne}, a novel algorithm, using microarray expression profiles, specifically designed to scale up to the complexity of regulatory networks in mammalian cells, yet general enough to address a wider range of network deconvolution problems. this method uses an information theoretic approach to eliminate the majority of indirect interactions inferred by co-expression methods."
7168344,article,science,,,american association for the advancement of science,2,328,5980,2010,may,2010-05-14 07:25:42,,"community structure in {time-dependent}, multiscale, and multiplex networks","network science is an interdisciplinary endeavor, with methods and applications drawn from across the natural, social, and information sciences. a prominent problem in network science is the algorithmic detection of tightly connected groups of nodes known as communities. we developed a generalized framework of network quality functions that allowed us to study the community structure of arbitrary multislice networks, which are combinations of individual networks coupled through links that connect each node in one network slice to itself in other slices. this framework allows studies of community structure in a general setting encompassing networks that evolve over time, have multiple types of links (multiplexity), and have multiple scales."
200340,book,,,,the mit press,,,,2004,aug,2005-05-14 22:46:10,,where the action is: the foundations of embodied interaction,
6569530,article,bioinformatics,,,oxford university press,6,26,5,2010,mar,2010-01-20 23:32:59,,fast and accurate long-read alignment with {burrows–wheeler} transform,"motivation: many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. most of them are very efficient for short reads but inefficient or not applicable for reads >200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate. however, some sequencing platforms already produce longer reads and others are expected to become available soon. for longer reads, hashing-based software such as {blat} and {ssaha2} remain the only choices. nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time."
94348,article,nucleic acids research,,,oxford university press,7,22,22,1994,nov,2005-02-14 12:22:28,"european molecular biology laboratory, heidelberg, germany.","{clustal} w: improving the sensitivity of progressive multiple sequence alignment through sequence weighting, position-specific gap penalties and weight matrix choice.","the sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. these modifications are incorporated into a new program, {clustal} w which is freely available."
318897,book,,,,cambridge university press,,,,1992,oct,2005-09-13 20:35:47,,"numerical recipes in c: the art of scientific computing, second edition",
2288308,article,science,,,,3,319,5862,2008,jan,2008-01-25 07:09:15,,alignment uncertainty and genomic analysis,"the statistical methods applied to the analysis of genomic data do not account for uncertainty in the sequence alignment. indeed, the alignment is treated as an observation, and all of the subsequent inferences depend on the alignment being correct. this may not have been too problematic for many phylogenetic studies, in which the gene is carefully chosen for, among other things, ease of alignment. however, in a comparative genomics study, the same statistical methods are applied repeatedly on thousands of genes, many of which will be difficult to align. using genomic data from seven yeast species, we show that uncertainty in the alignment can lead to several problems, including different alignment methods resulting in different conclusions."
131325,article,"science (new york, n.y.)",,,american association for the advancement of science,8,304,5667,2004,apr,2005-03-17 15:10:29,,environmental genome shotgun sequencing of the sargasso sea.,"we have applied ""whole-genome shotgun sequencing"" to microbial populations collected en masse on tangential flow and impact filters from seawater samples collected from the sargasso sea near bermuda. a total of 1.045 billion base pairs of nonredundant sequence was generated, annotated, and analyzed to elucidate the gene content, diversity, and relative abundance of the organisms within these environmental samples. these data are estimated to derive from at least 1800 genomic species based on sequence relatedness, including 148 previously unknown bacterial phylotypes. we have identified over 1.2 million previously unknown genes represented in these samples, including more than 782 new rhodopsin-like photoreceptors. variation in species present and stoichiometry suggests substantial oceanic microbial diversity."
77267,article,commun. acm,,,acm,2,47,12,2004,dec,2005-01-13 12:14:28,"new york, ny, usa",how blogging software reshapes the online community,"spurred by easy-to-use commercial software, blogging is less about creating links and references to sites and sources, and increasingly about bloggers' own comments and personal interests."
71749,proceedings,,proceedings of the 32nd acm symposium on theory of computing,,,,,,-1,,2005-01-02 16:35:14,,the {small-world} phenomenon: an algorithmic perspective,"long a matter of folklore, the \&quot;small-world phenomenon\&quot; -- the principle that we are all linked by short chains of acquaintances -- was inaugurated as an area of experimental study in the social sciences through the pioneering work of stanley milgram in the 1960's. this work was among the first to make the phenomenon quantitative, allowing people to speak of the \&quot;six degrees of separation\&quot; between any two people in the united states. since then, a number of network models have been proposed as..."
102131,article,acm comput. surv.,,,acm,36,36,4,2004,dec,2005-02-23 21:53:02,"new york, ny, usa",a survey of peer-to-peer content distribution technologies,"distributed computer architectures labeled ""peer-to-peer"" are designed for the sharing of computer resources (content, storage, {cpu} cycles) by direct exchange, rather than requiring the intermediation or support of a centralized server or authority. peer-to-peer architectures are characterized by their ability to adapt to failures and accommodate transient populations of nodes while maintaining acceptable connectivity and {performance.content} distribution is an important peer-to-peer application on the internet that has received considerable research attention. content distribution applications typically allow personal computers to function in a coordinated manner as a distributed storage medium by contributing, searching, and obtaining digital {content.in} this survey, we propose a framework for analyzing peer-to-peer content distribution technologies. our approach focuses on nonfunctional characteristics such as security, scalability, performance, fairness, and resource management potential, and examines the way in which these characteristics are reflected in---and affected by---the architectural design decisions adopted by current peer-to-peer {systems.we} study current peer-to-peer systems and infrastructure technologies in terms of their distributed object location and routing mechanisms, their approach to content replication, caching and migration, their support for encryption, access control, authentication and identity, anonymity, deniability, accountability and reputation, and their use of resource trading and management schemes."
333029,article,rev. mod. phys.,,,american physical society,50,74,1,2002,jan,2005-09-27 16:01:26,,statistical mechanics of complex networks,"complex networks describe a wide range of systems in nature and society. frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the internet, a network of routers and computers connected by physical links. while traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. this article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. after reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network\&\#39;s robustness against failures and attacks."
1603667,article,bioinformatics,,,oxford university press,10,23,19,2007,oct,2007-08-29 06:56:48,"department of plant systems biology, vib, b-9052 ghent, belgium and bioinformatics and evolutionary genomics group, department of molecular genetics, ghent university, b-9052 ghent, belgium.",a review of feature selection techniques in bioinformatics,"feature selection techniques have become an apparent need in many bioinformatics applications. in addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques."
877,article,,,,,,,,-1,,2004-11-21 20:59:19,,{referral web}: combining social networks and collaborative filtering,
2678830,article,nature,,,nature publishing group,5,452,7189,2008,apr,2008-04-16 20:45:23,,evolvability and hierarchy in rewired bacterial gene networks,
117642,book,,,,scribner,,,,2002,aug,2005-03-09 00:17:04,,"emergence: the connected lives of ants, brains, cities, and software",
4170553,article,science,,,american association for the advancement of science,3,324,5925,2009,apr,2009-03-16 11:30:53,,local {dna} topography correlates with functional noncoding regions of the human genome,"the three-dimensional molecular structure of {dna}, specifically the shape of the backbone and grooves of genomic {dna}, can be dramatically affected by nucleotide changes, which can cause differences in protein-binding affinity and phenotype. we developed an algorithm to measure constraint on the basis of similarity of {dna} topography among multiple species, using hydroxyl radical cleavage patterns to interrogate the solvent-accessible surface area of {dna}. this algorithm found that 12\% of bases in the human genome are evolutionarily constrained—double the number detected by nucleotide sequence–based algorithms. topography-informed constrained regions correlated with functional noncoding elements, including enhancers, better than did regions identified solely on the basis of nucleotide sequence. these results support the idea that the molecular shape of {dna} is under selection and can identify evolutionary history."
1121661,article,mach. learn.,,,kluwer academic publishers,27,45,1,2001,oct,2007-05-22 17:21:44,"hingham, ma, usa",random forests,"random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. the generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. the generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. using a random selection of features to split each node yields error rates that compare favorably to adaboost (y. freund \& r. schapire, machine learning: proceedings of the thirteenth international conference, \&ast;\&ast;\&ast;, 148–156), but are more robust with respect to noise. internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. internal estimates are also used to measure variable importance. these ideas are also applicable to regression."
1877660,book,,,,wiley-interscience,,,,2006,jul,2007-11-07 13:44:10,,elements of information theory 2nd edition (wiley series in telecommunications and signal processing),"the latest edition of this classic is updated with new problem sets and material<br> <br> the second edition of this fundamental textbook maintains the book's tradition of clear, thought-provoking instruction. readers are provided once again with an instructive mix of mathematics, physics, statistics, and information theory.<br> <br> all the essential topics in information theory are covered in detail, including entropy, data compression, channel capacity, rate distortion, network information theory, and hypothesis testing. the authors provide readers with a solid understanding of the underlying theory and applications. problem sets and a telegraphic summary at the end of each chapter further assist readers. the historical notes that follow each chapter recap the main points.<br> <br> the second edition features:<br> * chapters reorganized to improve teaching<br> * 200 new problems<br> * new material on source coding, portfolio theory, and feedback capacity<br> * updated references<br> <br> now current and enhanced, the second edition of elements of information theory remains the ideal textbook for upper-level undergraduate and graduate courses in electrical engineering, statistics, and telecommunications. <p> an instructor's manual presenting detailed solutions to all the problems in the book is available from the wiley editorial department."
1087189,article,proceedings of the national academy of sciences,,,national academy of sciences,5,104,1,2007,jan,2007-02-04 14:45:07,,resolution limit in community detection,"detecting community structure is fundamental for uncovering the links between structure and function in complex networks and for practical applications in many disciplines such as biology and sociology. a popular method now widely used relies on the optimization of a quantity called modularity, which is a quality index for a partition of a network into communities. we find that modularity optimization may fail to identify modules smaller than a scale which depends on the total size of the network and on the degree of interconnectedness of the modules, even in cases where modules are unambiguously defined. this finding is confirmed through several examples, both in artificial and in real social, biological, and technological networks, where we show that modularity optimization indeed does not resolve a large number of modules. a check of the modules obtained through modularity optimization is thus necessary, and we provide here key elements for the assessment of the reliability of this community detection method."
7515828,article,genome research,,,cold spring harbor laboratory press,6,20,9,2010,sep,2010-07-20 07:45:31,,the genome analysis toolkit: a {mapreduce} framework for analyzing next-generation {dna} sequencing data,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
587762,book,,,,yale university press,,,,2006,may,2006-04-15 17:42:59,,the wealth of networks: how social production transforms markets and freedom,
8525342,article,plos comput biol,,,public library of science,,7,1,2011,jan,2011-01-07 18:07:53,,ten simple rules for getting ahead as a computational biologist in academia,
491,inproceedings,,proceedings of the 13th international conference on world wide web,www,acm,10,,,2004,,2004-11-15 16:58:37,"new york, ny, usa",information diffusion through blogspace,"we study the dynamics of information propagation in environments of low-overhead personal publishing, using a large collection of weblogs over time as our example domain. we characterize and model this collection at two levels. first, we present a macroscopic characterization of topic propagation through our corpus, formalizing the notion of long-running ""chatter"" topics consisting recursively of ""spike"" topics generated by outside world events, or more rarely, by resonances within the community. second, we present a microscopic characterization of propagation from individual to individual, drawing on the theory of infectious diseases to model the flow. we propose, validate, and employ an algorithm to induce the underlying propagation network from a sequence of posts, and report on the results."
307461,article,nature genetics,,,nature publishing group,4,31,1,2002,apr,2005-08-30 19:25:14,,network motifs in the transcriptional regulation network of escherichia coli,"little is known about the design principles1, 2, 3, 4, 5, 6, 7, 8, 9, 10 of transcriptional regulation networks that control gene expression in cells. recent advances in data collection and analysis2, 11, 12, however, are generating unprecedented amounts of information about gene regulation networks. to understand these complex wiring diagrams1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, we sought to break down such networks into basic building blocks2. we generalize the notion of motifs, widely used for sequence analysis, to the level of networks. we define 'network motifs' as patterns of interconnections that recur in many different parts of a network at frequencies much higher than those found in randomized networks. we applied new algorithms for systematically detecting network motifs to one of the best-characterized regulation networks, that of direct transcriptional interactions in escherichia coli 3, 6. we find that much of the network is composed of repeated appearances of three highly significant motifs. each network motif has a specific function in determining gene expression, such as generating temporal expression programs and governing the responses to fluctuating external signals. the motif structure also allows an easily interpretable view of the entire known transcriptional network of the organism. this approach may help define the basic computational elements of other biological networks."
6758502,article,nature,,,nature publishing group,8,464,7285,2010,mar,2010-03-03 21:23:53,,quantum computers,"over the past several decades, quantum information science has emerged to seek answers to the question: can we gain some advantage by storing, transmitting and processing information encoded in systems that exhibit unique quantum properties? today it is understood that the answer is yes, and many research groups around the world are working towards the highly ambitious technological goal of building a quantum computer, which would dramatically improve computational power for particular tasks. a number of physical systems, spanning much of modern physics, are being developed for quantum computation. however, it remains unclear which technology, if any, will ultimately prove successful. here we describe the latest developments for each of the leading approaches and explain the major challenges for the future."
2322651,article,j. chem. theory comput.,journal of chemical theory and computation,,american chemical society,12,4,3,2008,mar,2008-02-02 10:28:22,"stockholm center for biomembrane research, stockholm university, se-10691 stockholm, sweden","{gromacs} 4:  algorithms for highly efficient, {load-balanced}, and scalable molecular simulation","molecular simulation is an extremely useful, but computationally very expensive tool for studies of chemical and biomolecular systems. here, we present a new implementation of our molecular simulation toolkit {gromacs} which now both achieves extremely high performance on single processors from algorithmic optimizations and hand-coded routines and simultaneously scales very well on parallel machines. the code encompasses a minimal-communication domain decomposition algorithm, full dynamic load balancing, a state-of-the-art parallel constraint solver, and efficient virtual site algorithms that allow removal of hydrogen atom degrees of freedom to enable integration time steps up to 5 fs for atomistic simulations also in parallel. to improve the scaling properties of the common particle mesh ewald electrostatics algorithms, we have in addition used a {multiple-program}, {multiple-data} approach, with separate node domains responsible for direct and reciprocal space interactions. not only does this combination of algorithms enable extremely long simulations of large systems but also it provides that simulation performance on quite modest numbers of standard cluster nodes."
126678,book,,,,addison-wesley professional,,,,1995,aug,2005-03-14 15:49:32,,"the mythical {man-month}: essays on software engineering, anniversary edition (2nd edition)","these essays draw from brooks' experience as project manager for the {ibm} system/360 computer family and then for {os}/360, its massive software system. now, 20 years after the initial publication of his book, brooks has revisited his original ideas and added new thoughts and advice. -- from publisher description"
6043555,article,nature methods,,,nature publishing group,7,6,11s,2009,oct,2009-10-30 15:56:40,,computational methods for discovering structural variation with next-generation sequencing,"in the last several years, a number of studies have described large-scale structural variation in several genomes. traditionally, such methods have used whole-genome array comparative genome hybridization or single-nucleotide polymorphism arrays to detect large regions subject to copy-number variation. later techniques have been based on paired-end mapping of sanger sequencing data, providing better resolution and accuracy. with the advent of next-generation sequencing, a new generation of methods is being developed to tackle the challenges of short reads, while taking advantage of the high coverage the new sequencing technologies provide. in this survey, we describe these methods, including their strengths and their limitations, and future research directions."
197297,book,,,,simon \& schuster,,,,1997,sep,2005-05-11 21:48:04,,life on the screen: identity in the age of the internet,"{sherry turkle is rapidly becoming the sociologist of the internet, and that's beginning to seem like a good thing. while her first outing, <i>the second self: computers and the human spirit</i>, made groundless assertions and seemed to be carried along more by her affection for certain theories than by a careful look at our current situation, <i>life on the screen</i> is a balanced and nuanced look at some of the ways that cyberculture helps us comment upon real life (what the cybercrowd sometimes calls rl). instead of giving in to any one theory on construction of identity, turkle looks at the way various netizens have used the internet, and especially muds (multi-user dimensions), to learn more about the possibilities available in apprehending the world. one of the most interesting sections deals with gender, a topic prone to rash and partisan pronouncements. taking as her motto william james's maxim ""philosophy is the art of imagining alternatives,"" turkle shows how playing with gender in cyberspace can shape a person's real-life understanding of gender. especially telling are the examples of the man who finds it easier to be assertive when playing a woman, because he believes male assertiveness is now frowned upon while female assertiveness is considered hip, and the woman who has the opposite response, believing that it is easier to be aggressive when she plays a male, because as a woman she would be considered ""bitchy."" without taking sides, turkle points out how both have expanded their emotional range. other topics, such as artificial life, receive an equally calm and sage response, and the first-person accounts from many internet users provide compelling reading and good source material for readers to draw their own conclusions.  }"
1388250,article,nature,,,nature publishing group,17,447,7146,2007,jun,2007-06-13 21:14:50,,identification and analysis of functional elements in 1\% of the human genome by the {encode} pilot project,"we report the generation and analysis of functional data from multiple, diverse experiments performed on a targeted 1\% of the human genome as part of the pilot phase of the {encode} project. these data have been further integrated and augmented by a number of evolutionary and computational analyses. together, our results advance the collective knowledge about human genome function in several major areas. first, our studies provide convincing evidence that the genome is pervasively transcribed, such that the majority of its bases can be found in primary transcripts, including non-protein-coding transcripts, and those that extensively overlap one another. second, systematic examination of transcriptional regulation has yielded new understanding about transcription start sites, including their relationship to specific regulatory sequences and features of chromatin accessibility and histone modification. third, a more sophisticated view of chromatin structure has emerged, including its inter-relationship with {dna} replication and transcriptional regulation. finally, integration of these new sources of information, in particular with respect to mammalian evolution based on inter- and intra-species sequence comparisons, has yielded new mechanistic and evolutionary insights concerning the functional landscape of the human genome. together, these studies are defining a path for pursuit of a more comprehensive characterization of human genome function."
201583,book,,,,routledge,,,,1999,feb,2005-05-16 17:58:02,,communities in cyberspace,"editors smith and kollock have gathered contributors with a variety of viewpoints to examine both the ""legitimacy"" of community in cyberspace and to question how it operates. while the authors do conclude that communities in cyberspace are real communities, they explore the sometimes surprising ways in which cybercommunities differ from their geographically based counterparts.<p> there are four primary issues probed here: the question of online identity in an environment where individuals cannot be seen; the question of social order and control in what is, at least on the surface, a largely anarchic environment; the structure and dynamics of online communities; and the cybercommunity as a foundation for collective action.<p> there's much here to provoke long discussions both online and off, such as the argument that the screen doesn't eliminate the consideration of racial identity so much as it allows for the development of nonvisual criteria for people to judge (or misjudge) the races of others. this book was compiled to be used in the college classroom, although it's not jargon laden or difficult to read. it will appeal to anyone who is professionally or individually involved with virtual communities. <{i>--elizabeth} {lewis</i}>"
126676,book,,,,back bay books,,,,2002,jan,2005-03-14 15:48:45,,the tipping point: how little things can make a big difference,"{""why did crime in new york drop so suddenly in the mid-90s? how does an unknown novelist end up a bestselling author? why is teenage smoking out of control, when everyone knows smoking kills? what makes tv shows like sesame street so good at teaching kids how to read? why did paul revere succeed with his famous warning? in this brilliant and groundbreaking book, new yorker writer malcolm gladwell looks at why major changes in our society so often happen suddenly and unexpectedly. ideas, behavior, messages, and products, he argues, often spread like outbreaks of infectious disease. just as a single sick person can start an epidemic of the flu, so too can a few fare-beaters and graffiti artists fuel a subway crime wave, or a satisfied customer fill the empty tables of a new restaurant. these are social epidemics, and the moment when they take off, when they reach their critical mass, is the tipping point.   <p>in the tipping point, gladwell introduces us to the particular personality types who are natural pollinators of new ideas and trends, the people who create the phenomenon of word of mouth. he analyzes fashion trends, smoking, children's television, direct mail and the early days of the american revolution for clues about making ideas infectious, and visits a religious commune, a successful high-tech company, and one of the world's greatest salesmen to show how to start and sustain social epidemics. the tipping point is an intellectual adventure story written with an infectious enthusiasm for the power and joy of new ideas. most of all, it is a road map to change, with a profoundly hopeful message--that one imaginative person applying a well-placed lever can move the world.""}"
3381078,article,plos med,,,public library of science,,5,10,2008,oct,2008-10-07 05:53:54,,why current publication practices may distort science,john ioannidis and colleagues argue that the current system of publication in biomedical research provides a distorted view of the reality of scientific data.
2580227,inproceedings,,proceedings of the 9th webkdd and 1st sna-kdd 2007 workshop on web mining and social network analysis,webkdd/sna-kdd,acm,9,,,2007,,2008-03-24 10:27:15,"new york, ny, usa",why we twitter: understanding microblogging usage and communities,"microblogging is a new form of communication in which users can describe their current status in short posts distributed by instant messages, mobile phones, email or the web. twitter, a popular microblogging tool has seen a lot of growth since it launched in october, 2006. in this paper, we present our observations of the microblogging phenomena by studying the topological and geographical properties of twitter's social network. we find that people use microblogging to talk about their daily activities and to seek or share information. finally, we analyze the user intentions associated at a community level and show how users with similar intentions connect with each other."
159967,article,nucleic acids research,,,oxford university press,9,30,7,2002,apr,2005-04-13 17:58:32,"computational genomics group, the european bioinformatics institute, embl cambridge outstation, cambridge cb10 1sd, uk. anton@ebi.ac.uk",an efficient algorithm for large-scale detection of protein families.,"detection of protein families in large databases is one of the principal research objectives in structural and functional genomics. protein family classification can significantly contribute to the delineation of functional diversity of homologous proteins, the prediction of function based on domain architecture or the presence of sequence motifs as well as comparative genomics, providing valuable evolutionary insights. we present a novel approach called {tribe}-{mcl} for rapid and accurate clustering of protein sequences into families. the method relies on the markov cluster ({mcl}) algorithm for the assignment of proteins into families based on precomputed sequence similarity information. this novel approach does not suffer from the problems that normally hinder other protein sequence clustering algorithms, such as the presence of multi-domain proteins, promiscuous domains and fragmented proteins. the method has been rigorously tested and validated on a number of very large databases, including {swissprot}, {interpro}, {scop} and the draft human genome. our results indicate that the method is ideally suited to the rapid and accurate detection of protein families on a large scale. the method has been used to detect and categorise protein families within the draft human genome and the resulting families have been used to annotate a large proportion of human proteins."
252315,book,,,,the johns hopkins university press,,,,1996,oct,2005-07-12 19:58:52,,matrix computations,"<{p>revised} and updated, the third edition of golub and van loan's classic text in computer science provides essential information about the mathematical background and algorithmic skills required for the production of numerical software. this new edition includes thoroughly revised chapters on matrix multiplication problems and parallel matrix computations, expanded treatment of {cs} decomposition, an updated overview of floating point arithmetic, a more accurate rendition of the modified {gram-schmidt} process, and new material devoted to {gmres}, {qmr}, and other methods designed to handle the sparse unsymmetric linear system {problem.</p}>"
128,article,proceedings of the national academy of sciences,,,national academy of sciences,5,98,2,2001,jan,2004-11-08 17:14:49,"santa fe institute, 1399 hyde park road, santa fe, nm 87501, usa. mark@santafe.edu",the structure of scientific collaboration networks,"the structure of scientific collaboration networks is investigated. two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including {medline} (biomedical research), the los alamos {e-print} archive (physics), and {ncstrl} (computer science). i show that these collaboration networks form  ” small worlds,” in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. i further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied."
142938,techreport,,,,,,,,-1,,2005-03-30 14:30:28,"redmond, washington",a tutorial on learning with bayesian networks,"a bayesian network is a graphical model that encodes probabilistic relationships among variables of interest. when used in conjunction with statistical techniques, the graphical model has several advantages for data analysis. one, because the model encodes dependencies among all variables, it readily handles situations where some data entries are missing. two, a bayesian network can be used to learn causal relationships, and hence can be used to gain understanding about a problem domain and to..."
5841376,article,bmc bioinformatics,,,,,10,1,2009,,2009-09-25 21:58:18,,social tagging in the life sciences: characterizing a new metadata resource for bioinformatics.,"academic social tagging systems, such as connotea and {citeulike}, provide researchers with a means to organize personal collections of online references with keywords (tags) and to share these collections with others. one of the side-effects of the operation of these systems is the generation of large, publicly accessible metadata repositories describing the resources in the collections. in light of the well-known expansion of information in the life sciences and the need for metadata to enhance its value, these repositories present a potentially valuable new resource for application developers. here we characterize the current contents of two scientifically relevant metadata repositories created through social tagging. this investigation helps to establish how such socially constructed metadata might be used as it stands currently and to suggest ways that new social tagging systems might be designed that would yield better aggregate products. we assessed the metadata that users of {citeulike} and connotea associated with citations in {pubmed} with the following metrics: coverage of the document space, density of metadata (tags) per document, rates of inter-annotator agreement, and rates of agreement with {mesh} indexing. {citeulike} and connotea were very similar on all of the measurements. in comparison to {pubmed}, document coverage and per-document metadata density were much lower for the social tagging systems. inter-annotator agreement within the social tagging systems and the agreement between the aggregated social tagging metadata and {mesh} indexing was low though the latter could be increased through voting. the most promising uses of metadata from current academic social tagging repositories will be those that find ways to utilize the novel relationships between users, tags, and documents exposed through these systems. for more traditional kinds of indexing-based applications (such as keyword-based search) to benefit substantially from socially generated metadata in the life sciences, more documents need to be tagged and more tags are needed for each document. these issues may be addressed both by finding ways to attract more users to current systems and by creating new user interfaces that encourage more collectively useful individual tagging behaviour."
1154381,article,nat mater,,,nature publishing group,8,6,3,2007,mar,2007-03-11 21:07:03,,the rise of graphene,"graphene is a rapidly rising star on the horizon of materials science and condensed-matter physics. this strictly two-dimensional material exhibits exceptionally high crystal and electronic quality, and, despite its short history, has already revealed a cornucopia of new physics and potential applications, which are briefly discussed here. whereas one can be certain of the realness of applications only when commercial products appear, graphene no longer requires any further proof of its importance in terms of fundamental physics. owing to its unusual electronic spectrum, graphene has led to the emergence of a new paradigm of 'relativistic' condensed-matter physics, where quantum relativistic phenomena, some of which are unobservable in high-energy physics, can now be mimicked and tested in table-top experiments. more generally, graphene represents a conceptually new class of materials that are only one atom thick, and, on this basis, offers new inroads into low-dimensional physics that has never ceased to surprise and continues to provide a fertile ground for applications."
77265,article,commun. acm,,,acm,4,47,12,2004,dec,2005-01-13 11:15:53,"new york, ny, usa",structure and evolution of blogspace,"a critical look at more than one million bloggers and the individual entries of some 25,000 blogs reveals blogger demographics, friendships, and activity patterns over time."
1326856,inproceedings,,proceedings of the 16th international conference on world wide web,www,acm,9,,,2007,,2007-05-25 10:25:23,"new york, ny, usa",the complex dynamics of collaborative tagging,"the debate within the web community over the optimal means by which to organize information often pits formalized classifications against distributed collaborative tagging systems. a number of questions remain unanswered, however, regarding the nature of collaborative tagging systems including whether coherent categorization schemes can emerge from unsupervised tagging by users. this paper uses data from the social bookmarking site delicio. us to examine the dynamics of collaborative tagging systems. in particular, we examine whether the distribution of the frequency of use of tags for ""popular"" sites with a long history (many tags and many users) can be described by a power law distribution, often characteristic of what are considered complex systems. we produce a generative model of collaborative tagging in order to understand the basic dynamics behind tagging, including how a power law distribution of tags could arise. we empirically examine the tagging history of sites in order to determine how this distribution arises over time and to determine the patterns prior to a stable distribution. lastly, by focusing on the high-frequency tags of a site where the distribution of tags is a stabilized power law, we show how tag co-occurrence networks for a sample domain of tags can be used to analyze the meaning of particular tags given their relationship to other tags."
137147,electronic,,,,,,,,2004,nov,2005-03-23 09:43:35,,how to search a social network,
5687044,article,nature genetics,,,nature publishing group,6,41,10,2009,oct,2009-08-31 04:23:22,,personalized copy number and segmental duplication maps using next-generation sequencing.,"despite their importance in gene innovation and phenotypic variation, duplicated regions have remained largely intractable owing to difficulties in accurately resolving their structure, copy number and sequence content. we present an algorithm ({mrfast}) to comprehensively map next-generation sequence reads, which allows for the prediction of absolute copy-number variation of duplicated segments and genes. we examine three human genomes and experimentally validate genome-wide copy number differences. we estimate that, on average, 73-87 genes vary in copy number between any two individuals and find that these genic differences overwhelmingly correspond to segmental duplications (odds ratio = 135; p < 2.2 x 10(-16)). our method can distinguish between different copies of highly identical genes, providing a more accurate assessment of gene content and insight into functional constraint without the limitations of array-based technology."
272,article,nature,,,nature publishing group,4,431,7006,2004,sep,2004-11-12 20:08:57,"department of molecular biophysics and biochemistry, yale university, po box 208114, new haven, connecticut 06520-8114, usa. sandy@bioinfo.mbb.yale.edu",genomic analysis of regulatory network dynamics reveals large topological changes,"network analysis has been applied widely, providing a unifying language to describe disparate systems ranging from social interactions to power grids. it has recently been used in molecular biology, but so far the resulting networks have only been analysed statically1, 2, 3, 4, 5, 6, 7, 8. here we present the dynamics of a biological network on a genomic scale, by integrating transcriptional regulatory information9, 10, 11 and gene-expression data12, 13, 14, 15, 16 for multiple conditions in saccharomyces cerevisiae. we develop an approach for the statistical analysis of network dynamics, called {sandy}, combining well-known global topological measures, local motifs and newly derived statistics. we uncover large changes in underlying network architecture that are unexpected given current viewpoints and random simulations. in response to diverse stimuli, transcription factors alter their interactions to varying degrees, thereby rewiring the network. a few transcription factors serve as permanent hubs, but most act transiently only during certain conditions. by studying sub-network structures, we show that environmental responses facilitate fast signal propagation (for example, with short regulatory cascades), whereas the cell cycle and sporulation direct temporal progression through multiple stages (for example, with highly inter-connected transcription factors). indeed, to drive the latter processes forward, phase-specific transcription factors inter-regulate serially, and ubiquitously active transcription factors layer above them in a two-tiered hierarchy. we anticipate that many of the concepts presented here—particularly the large-scale topological changes and hub transience—will apply to other biological networks, including complex sub-systems in higher eukaryotes."
620778,article,the american journal of sociology,,,,32,94,3,1988,,2006-05-10 00:41:12,,social networks and collective action: a theory of the critical mass. {iii},"most analyses of collective action agree that overcoming the freerider problem requires organizing potential contributors, thus making their decisions interdependent. the potential for organizing depends on the social ties in the group, particularly on the overall density or frequency of ties, on the extent to which they are centralized in a few individuals, and on the costs of communicating and coordinating actions through these ties. mathematical analysis and computer simulations extend a formal microsocial theory of interdependent collective action to treat social networks and organization costs. as expected, the overall density of social ties in a group improves its prospects for collective action. more significant, because less expected, are the findings that show that the centralization of network ties always has a positive effect on collective action and that the negative effect of costs on collective action declines as the group's resource or interest heterogeneity increases. these nonobvious results are due to the powerful effects of selectivity, the organizer's ability to concentrate organizing efforts on those individuals whose potential contributions are the largest."
2102204,article,nucleic acids research,,,oxford university press,4,36,suppl 1,2008,jan,2007-12-13 06:10:35,,{kegg} for linking genomes to life and the environment,"{kegg} (http://www.genome.jp/kegg/) is a database of biological systems that integrates genomic, chemical and systemic functional information. {kegg} provides a reference knowledge base for linking genomes to life through the process of {pathway} mapping, which is to map, for example, a genomic or transcriptomic content of genes to {kegg} reference pathways to infer systemic behaviors of the cell or the organism. in addition, {kegg} provides a reference knowledge base for linking genomes to the environment, such as for the analysis of drug-target relationships, through the process of {brite} mapping. {kegg} {brite} is an ontology database representing functional hierarchies of various biological objects, including molecules, cells, organisms, diseases and drugs, as well as relationships among them. {kegg} {pathway} is now supplemented with a new global map of metabolic pathways, which is essentially a combined map of about 120 existing pathway maps. in addition, smaller pathway modules are defined and stored in {kegg} {module} that also contains other functional units and complexes. the {kegg} resource is being expanded to suit the needs for practical applications. {kegg} {drug} contains all approved drugs in the {us} and japan, and {kegg} {disease} is a new database linking disease genes, pathways, drugs and diagnostic markers."
687885,article,proceedings of the national academy of sciences,,,,5,103,23,2006,jun,2006-06-07 06:41:01,,modularity and community structure in networks,"many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. the problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. one highly effective approach is the optimization of the quality function known as  ” modularity” over the possible divisions of a network. here i show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which i call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. i illustrate the method with applications to several published network data sets."
168648,inproceedings,,proceedings of the nineteenth acm symposium on operating systems principles,sosp,acm,13,,,2003,,2005-04-24 04:22:23,"new york, ny, usa",xen and the art of virtualization,"numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. some require specialized hardware, or cannot support commodity operating systems. some target 100\% binary compatibility at the expense of performance. others sacrifice security or functionality for speed. few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of {service.this} paper presents xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. this is achieved by providing an idealized virtual machine abstraction to which operating systems such as linux, {bsd} and windows {xp}, can be ported with minimal {effort.our} design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. the virtualization approach taken by xen is extremely efficient: we allow operating systems such as linux and windows {xp} to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. we considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests."
114719,book,,,,cambridge university press,,,,2000,mar,2005-03-05 09:49:31,,an introduction to support vector machines and other kernel-based learning methods,"this is the first comprehensive introduction to support vector machines ({svms}), a new generation learning system based on recent advances in statistical learning theory. students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. the concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. pointers to relevant literature and web sites containing software make it an ideal starting point for further study."
595771,inproceedings,,proceedings of the twelfth international conference on information and knowledge management,cikm,acm,3,,,2003,,2006-04-23 03:24:40,"new york, ny, usa",the link prediction problem for social networks,"given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? we formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the ""proximity"" of nodes in a network. experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures."
2739858,article,nature,,,nature publishing group,8,453,7191,2008,may,2008-05-01 09:25:30,,mapping and sequencing of structural variation from eight human genomes,
1880603,article,nature,,,nature publishing group,15,450,7167,2007,nov,2007-11-07 19:26:09,,evolution of genes and genomes on the drosophila phylogeny,"comparative analysis of multiple genomes in a phylogenetic framework dramatically improves the precision and sensitivity of evolutionary inference, producing more robust results than single-genome analyses can provide. the genomes of 12 drosophila species, ten of which are presented here for the first time (sechellia, simulans, yakuba, erecta, ananassae, persimilis, willistoni, mojavensis, virilis and grimshawi), illustrate how rates and patterns of sequence divergence across taxa can illuminate evolutionary processes on a genomic scale. these genome sequences augment the formidable genetic tools that have made drosophila melanogaster a pre-eminent model for animal genetics, and will further catalyse fundamental research on mechanisms of development, cell biology, genetics, disease, neurobiology, behaviour, physiology and evolution. despite remarkable similarities among these drosophila species, we identified many putatively non-neutral changes in protein-coding genes, non-coding {rna} genes, and cis-regulatory regions. these may prove to underlie differences in the ecology and behaviour of these diverse species."
5445743,article,nature,,,macmillan publishers limited. all rights reserved,4,461,7261,2009,sep,2009-08-16 21:28:43,,targeted capture and massively parallel sequencing of 12 human exomes.,"genome-wide association studies suggest that common genetic variants explain only a modest fraction of heritable risk for common diseases, raising the question of whether rare variants account for a significant fraction of unexplained heritability. although {dna} sequencing costs have fallen markedly, they remain far from what is necessary for rare and novel variants to be routinely identified at a genome-wide scale in large cohorts. we have therefore sought to develop second-generation methods for targeted sequencing of all protein-coding regions ('exomes'), to reduce costs while enriching for discovery of highly penetrant variants. here we report on the targeted capture and massively parallel sequencing of the exomes of 12 humans. these include eight {hapmap} individuals representing three populations, and four unrelated individuals with a rare dominantly inherited disorder, {freeman-sheldon} syndrome ({fss}). we demonstrate the sensitive and specific identification of rare and common variants in over 300 megabases of coding sequence. using {fss} as a proof-of-concept, we show that candidate genes for mendelian disorders can be identified by exome sequencing of a small number of unrelated, affected individuals. this strategy may be extendable to diseases with more complex genetics through larger sample sizes and appropriate weighting of non-synonymous variants by predicted functional impact."
1777140,article,molecular systems biology,,,nature publishing group,,3,1,2007,oct,2007-10-17 01:53:38,,network-based classification of breast cancer metastasis.,"mapping the pathways that give rise to metastasis is one of the key challenges of breast cancer research. recently, several large-scale studies have shed light on this problem through analysis of gene expression profiles to identify markers correlated with metastasis. here, we apply a protein-network-based approach that identifies markers not as individual genes but as subnetworks extracted from protein interaction databases. the resulting subnetworks provide novel hypotheses for pathways involved in tumor progression. although genes with known breast cancer mutations are typically not detected through analysis of differential expression, they play a central role in the protein network by interconnecting many differentially expressed genes. we find that the subnetwork markers are more reproducible than individual marker genes selected without network information, and that they achieve higher accuracy in the classification of metastatic versus non-metastatic tumors."
5251453,article,bmj,,,british medical journal publishing group,,339,jul20\_3,2009,jul,2009-07-24 16:03:56,,how citation distortions create unfounded authority: analysis of a citation network,"{abstractobjective} to understand belief in a specific scientific claim by studying the pattern of citations among papers stating {it.design} a complete citation network was constructed from all {pubmed} indexed english literature papers addressing the belief that β amyloid, a protein accumulated in the brain in alzheimer's disease, is produced by and injures skeletal muscle of patients with inclusion body myositis. social network theory and graph theory were used to analyse this {network.main} outcome measures citation bias, amplification, and invention, and their effects on determining {authority.results} the network contained 242 papers and 675 citations addressing the belief, with 220 553 citation paths supporting it. unfounded authority was established by citation bias against papers that refuted or weakened the belief; amplification, the marked expansion of the belief system by papers presenting no data addressing it; and forms of invention such as the conversion of hypothesis into fact through citation alone. extension of this network into text within grants funded by the national institutes of health and obtained through the freedom of information act showed the same phenomena present and sometimes used to justify requests for {funding.conclusion} citation is both an impartial scholarly method and a powerful form of social communication. through distortions in its social use that include bias, amplification, and invention, citation can be used to generate information cascades resulting in unfounded authority of claims. construction and analysis of a claim specific citation network may clarify the nature of a published belief system and expose distorted methods of social citation."
1332540,article,plos comput biol,,,public library of science,,3,5,2007,may,2007-05-25 16:27:31,,ten simple rules for a good poster presentation,
8958158,article,cell,,,elsevier,28,144,5,2011,mar,2011-03-11 00:56:33,,hallmarks of cancer: the next generation.,"main text {introductionwe} have proposed that six hallmarks of cancer together constitute an organizing principle that provides a logical framework for understanding the remarkable diversity of neoplastic diseases (hanahan and weinberg, 2000). implicit in our discussion was the notion that as normal cells evolve progressively to a neoplastic state, they acquire a succession of these hallmark capabilities, and that the multistep process of human tumor pathogenesis could be rationalized by the need of incipient cancer cells to acquire the traits that enable them to become tumorigenic and ultimately malignant."
2887105,incollection,computational intelligence in automotive applications,,,,9,,,2008,,2008-06-12 12:43:55,,application of graphical models in the automotive industry,"the production pipeline of present day's automobile manufacturers consists of a highly heterogeneous and intricate assembly workflow that is driven by a considerable degree of interdependencies between the participating instances as there are suppliers, manufacturing engineers, marketing analysts and development researchers. therefore, it is of paramount importance to enable all production experts to quickly respond to potential on-time delivery failures, ordering peaks or other disturbances that may interfere with the ideal assembly process. moreover, the fast moving evolvement of new vehicle models require well-designed investigations regarding the collection and analysis of vehicle maintenance data. it is crucial to track down complicated interactions between car components or external failure causes in the shortest time possible to meet customer-requested quality claims. to summarize these requirements, let us turn to an example which reveals some of the dependencies mentioned in this chapter. as we will see later, a normal car model can be described by hundreds of variables each of which representing a feature or technical property. since only a small number of combinations (compared to all possible ones) will represent a valid car configuration, we will present a means of reducing the model space by imposing restrictions. these restrictions enter the mathematical treatment in the form of dependencies since a restriction may cancel out some options, thus rendering two attributes (more) dependent. this early step produces qualitative dependencies like  ” engine type and transmission type are dependent.” to quantify these dependencies some uncertainty calculus is necessary to establish the dependence strengths. in our cases probability theory is used to augment the model, e.g.,  ” whenever engine type 1 is ordered, the probability is 56\% of having transmission type 2 ordered as well.” there is a multitude of sources to estimate or extract this information from. when ordering peaks occur like an increased demand of convertibles during the spring, or some supply shortages arise due to a strike in the transport industry, the model is used to predict vehicle configurations that may run into delivery delays in order to forestall such a scenario by, e.g., acquiring alternative supply chains or temporarily shifting production load. another part of the model may contain similar information for the aftercare, e.g.,  ” whenever a warranty claim contained battery type 3, there is a 30\% chance of having radio type 1 in the car.” in this case dependencies are contained in the quality assessment data and are not known beforehand but are extracted to reveal possible hidden design flaws."
7496675,article,displays,,,,7,29,1,2008,jan,2010-07-16 01:48:28,,development and comparison of a full-scale car display and communication system by applying augmented reality,"by adopting augmented reality ({ar}) and integrating the functions of wireless communication of a personal digital assistant ({pda}) and a head-mounted displays ({hmd}), we built a design evaluation environment that combines a full-scale car display and a visual evaluation system. the image of a car is transmitted via wireless communication onto the {pda}, which provides functions for measuring distances and changing parameters of the virtual car using graphical user interfaces ({gui}). the updated car image is constructed on the fly on a {pc} server and sent back to the {hmd} and the {pda}. multiple users can look at a virtual car simultaneously and discuss its various aspects, enabling better evaluation of the car design."
9563857,article,transportation research part a: policy and practice,,,,,,,2011,jul,2011-09-27 15:06:54,,"walking frequency, cars, dogs, and the built environment","to explain walking propensity or frequency, empirical studies have generally used two sets of explanatory variables, namely, socio-demographic variables and built environment variables. they have generally shown that both socio-demographic characteristics and built environment characteristics are associated with walking propensity. we examine the traditional walkability variables that encompass density, mix of uses, and network connectivity in new jersey, using a statewide sample including an oversample of jersey city. we estimate a two-stage least squares model using a conditional mixed process that combines an ordered probit model of walking frequency in the second stage based on a truncated regression of car ownership in the first stage. our results show that built environment variables have some small effects, mainly from better network connectivity associated with increased walking frequency. one of our key findings is that built environment features also work indirectly via how they influence car ownership. in general, we find sufficient evidence that suggests fewer cars are owned in areas with more walkable built environment features. the other key variable that we control for is whether a household owns a dog. this also proved to be strongly associated with walking suggesting that dog ownership is a necessary control variable to understand the frequency of walking."
9534873,article,fuel cells bulletin,,,,2,2011,6,2011,jun,2011-09-10 22:44:26,,clean energy partnership develops fuel of the future for hydrogen mobility in germany,"the clean energy partnership ({cep}) – a german alliance of currently 15 leading companies – has set itself the goal of establishing hydrogen as the 'fuel of the future'. with air liquide, berliner verkehrsbetriebe ({bvg}), {bmw}, daimler, ford, general {motors/opel}, hamburger hochbahn, honda, linde, shell, statoil, total, toyota, vattenfall europe, and volkswagen, the ground-breaking futuristic project includes technology, oil and utility companies, as well as most of the major car manufacturers and two leading public transport companies. the {cep} is devoted to testing hydrogen and fuel cell technology for everyday use in transport and traffic."
8336239,article,transport policy,,,,,,,2010,nov,2011-04-19 15:51:46,,"automobile use, fuel economy and {co2} emissions in industrialized countries: encouraging trends through 2008?","car use and fuel economy are factors that determine oil demand and carbon dioxide ({co2}) emissions. recent data on automobile utilization and fuel economy reveal surprising trends that point to changes in oil demand and {co2} emissions. new vehicle and on-road fleet fuel economy have risen in europe and japan since the mid 1990s, and in the {us} since 2003. combined with a plateau in per capita vehicle use in all countries analyzed, these trends indicate that per capita fuel use and resultant tail-pipe {co2} emissions have stagnated or even declined. fuel economy technology, while important, is not the only factor that explains changes in tested and on-road fuel economy, vehicle efficiency and transport emissions across countries. vehicle size and performance choices by car producers and buyers, and driving distances have also played significant roles in total fuel consumption, and explain most of the differences among countries. technology applied to new vehicles managed to drive down the fuel use per unit of horsepower or weight by 50\%, yet most of the potential fuel savings were negated by overall increased power and weight, particularly in the {us}. similarly, the promise of savings from dieselization of the fleet has revealed itself as a minor element of the overall improvement in new vehicle or on-road fuel economy. and the fact that diesels are driven so much more than gasoline cars, a difference that has increased since 1990, argues that those savings are minimal. this latter point is a reminder that car use, not just efficiency or fuel choice, is an important determinant of total fuel use and {co2} emissions. we speculate that if the upward spiral of car weight and power slows or even reverses (as has been observed in europe and japan) and the now mandatory standards in many countries have the intended effect that fuel use will remain flat or only grow weakly for some time. if real fuel prices of 2008, which rivaled their peaks of the early 1980s, fell back somewhat but still remain well above their early 2000 values. if the prices remain high, this, combined with the strengthened fuel economy standards, may finally lead to new patterns of car ownership, use and fuel economy. however, if fuel prices continue their own stagnation or even decline after the peaks of 2008 and car use starts upward, fuel use will increase again, albeit more slowly."
2526216,book,,,,wiley,,,,2007,nov,2008-03-13 13:18:04,,sustainable urbanism: urban design with nature,
7010764,article,"resources, conservation and recycling",,,,,,,2010,apr,2011-09-25 13:01:26,,assessment of ecodesign potential in reaching new recycling targets,"every year, in europe, {end-of-life} vehicles ({elvs}) constitute about 8–9 million tonnes of waste, that must be properly managed. directive {2000/53/ec} fixed new european targets for vehicle recovery (i.e., recycling plus energy recovery): 85\% of recovery, of which 80\% recycled or reused, by 2006, rising to 95\% and 85\% respectively by 2015. in order to comply with this directive, both car producers and {elvs} treatment plants must promptly tackle this issue. in this paper, a study on the impact that pre-shredder treatment could have in achieving 85\% recyclability rate in 2015 has been carried out. to do this, a design for recycling ({dfr}) software has been used, named {prodtect} ® , that integrates real recycling market data, market feedback and development experience to provide an overall evaluation of products {end-of-life} performance. an experimental disassembly and composition analysis of a commercial model of a car seat and a simulation of new ecodesigned joining techniques applied to it, have been performed, in order to investigate both the economics and the feasibility of this step in the future {elvs} treatment chain. in order to achieve and, if possible, go beyond 85\% of recyclability in 2015, car seats are found to play an important role: by dismantling them, 86.2\% of recyclability may be achieved by recovering {pur}, textile and belts. another important result is that by pre-treating and dismantling bumpers, fuel tanks, tyres, glass and car seats it is possible to reduce {asr} mass disposed in landfill by 42\%. moreover, design for dismantling techniques may reduce dismantling time to a third by simply innovating joinings."
7164691,article,transport policy,,,,10,17,6,2010,nov,2010-09-01 13:55:47,,how can our cars become less polluting? an assessment of the environmental improvement potential of cars,"this paper presents a systematic overview of the environmental impacts of new average diesel and petrol cars from a life cycle perspective. an analysis of different technical and non-technical improvement options that could be achieved at each stage of a car's life cycle was performed. the consequences of the adoption of these options on the environment were estimated. the results show that some of the options analysed could have a major positive impact on the vehicle efficiency and induce large improvements of the environmental profile of passenger cars. the highest improvements are achievable through more efficient power trains (including hybrid car), and through lightweight cars. for some options, burden shifts from one car life cycle phase to another, or from one environmental problem to another, can occur. the results show that besides the purely technological options, those that imply behavioural changes by the driver may also reduce the environmental burden substantially."
1363828,misc,,,,,,,,-1,,2007-06-04 22:28:25,,using software-based attestation for verifying embedded systems in cars,"with advances in automobile electronics, we find a rapid proliferation of embedded systems in cars, both in safety-critical applications and for passenger comfort. these embedded systems are increasingly networked for their operation and enhanced functionality. however, the increased connectivity of embedded systems also greatly complicates design, increases the number of failure modes, and introduces the risk of remote malicious attacks, such as worms and viruses. moreover, car owners may..."
3467077,article,plos computational biology,,,public library of science,,4,10,2008,oct,2008-10-30 23:02:02,,defrosting the digital library: bibliographic tools for the next generation web.,"many scientists now manage the bulk of their bibliographic information electronically, thereby organizing their publications and citation material from digital libraries. however, a library has been described as ""thought in cold storage,"" and unfortunately many digital libraries can be cold, impersonal, isolated, and inaccessible places. in this review, we discuss the current chilly state of digital libraries for the computational biologist, including {pubmed}, {ieee} xplore, the {acm} digital library, {isi} web of knowledge, scopus, citeseer, {arxiv}, {dblp}, and google scholar. we illustrate the current process of using these libraries with a typical workflow, and highlight problems with managing data and metadata using {uris}. we then examine a range of new applications such as zotero, mendeley, mekentosj papers, {myncbi}, {citeulike}, connotea, and {hubmed} that exploit the web to make these digital libraries more personal, sociable, integrated, and accessible places. we conclude with how these applications may begin to help achieve a digital defrost, and discuss some of the issues that will help or hinder this in terms of making libraries on the web warmer places in the future, becoming resources that are considerably more useful to both humans and machines."
873540,book,,,,springer,,,,2006,oct,2006-09-26 18:44:17,,pattern recognition and machine learning,"the field of pattern recognition has undergone substantial development over the years. this book reflects these developments while providing a grounding in the basic concepts of pattern recognition and machine learning. it is aimed at advanced undergraduates or first year {phd} students, as well as researchers and practitioners."
4265782,article,science,,,american association for the advancement of science,4,324,5923,2009,apr,2009-04-03 03:48:42,,the automation of science,"the basis of science is the hypothetico-deductive method and the recording of experiments in sufficient detail to enable reproducibility. we report the development of robot scientist  ” adam,” which advances the automation of both. adam has autonomously generated functional genomics hypotheses about the yeast saccharomyces cerevisiae and experimentally tested these hypotheses by using laboratory automation. we have confirmed adam's conclusions through manual experiments. to describe adam's research, we have developed an ontology and logical language. the resulting formalization involves over 10,000 different research units in a nested treelike structure, 10 levels deep, that relates the 6.6 million biomass measurements to their logical description. this formalization describes how a machine contributed to scientific knowledge."
481248,article,physics reports,,,,133,424,4-5,2006,feb,2006-01-26 05:04:14,,complex networks: structure and dynamics,"coupled biological and chemical systems, neural networks, social interacting species, the internet and the world wide web, are only a few examples of systems composed by a large number of highly interconnected dynamical units. the first approach to capture the global properties of such systems is to model them as graphs whose nodes represent the dynamical units, and whose links stand for the interactions between them. on the one hand, scientists have to cope with structural issues, such as characterizing the topology of a complex wiring architecture, revealing the unifying principles that are at the basis of real networks, and developing models to mimic the growth of a network and reproduce its structural properties. on the other hand, many relevant questions arise when studying complex networks' dynamics, such as learning how a large ensemble of dynamical systems that interact through a complex wiring topology can behave collectively. we review the major concepts and results recently achieved in the study of the structure and dynamics of complex networks, and summarize the relevant applications of these ideas in many different disciplines, ranging from nonlinear science to biology, from statistical mechanics to medicine and engineering."
965334,inproceedings,,proceedings of the 2006 20th anniversary conference on computer supported cooperative work,cscw,acm,9,,,2006,,2006-11-28 14:56:29,"new york, ny, usa","tagging, communities, vocabulary, evolution","a tagging community's vocabulary of tags forms the basis for social navigation and shared {expression.we} present a user-centric model of vocabulary evolution in tagging communities based on community influence and personal tendency. we evaluate our model in an emergent tagging system by introducing tagging features into the {movielens} recommender {system.we} explore four tag selection algorithms for displaying tags applied by other community members. we analyze the algorithms 'effect on vocabulary evolution, tag utility, tag adoption, and user satisfaction."
172550,article,acm trans. inf. syst.,,,acm,48,22,1,2004,jan,2005-04-27 18:41:15,"new york, ny, usa",evaluating collaborative filtering recommender systems,"recommender systems have been evaluated in many, often incomparable, ways. in this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. in addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated."
165117,inproceedings,,proceedings of the 2004 acm conference on computer supported cooperative work,cscw,acm,9,,,2004,,2005-04-19 19:59:44,"new york, ny, usa",using social psychology to motivate contributions to online communities,"under-contribution is a problem for many online communities. social psychology theories of social loafing and goal-setting can provide mid-level design principles to address this problem. we tested the design principles in two field experiments. in one, members of an online movie recommender community were reminded of the uniqueness of their contributions and the benefits that follow from them. in the second, they were given a range of individual or group goals for contribution. as predicted by theory, individuals contributed when they were reminded of their uniqueness and when they were given specific and challenging goals, but other predictions were not borne out. the paper ends with suggestions and challenges for mining social science theories as well as implications for design."
244827,book,,,,{sage publications},,,,2000,jan,2005-07-04 18:17:47,,social network analysis: a handbook,"{the revised and updated edition of this bestselling text provides an accessible introduction to the theory and practice of network analysis in the social sciences. it gives a clear and authoritative guide to the general framework of network analysis, explaining the basic concepts, technical measures and reviewing the available computer programs.<p></p><p>the book outlines both the theoretical basis of network analysis and the key techniques for using it as a research tool. building upon definitions of points, lines and paths, john scott demonstrates their use in clarifying such measures as density, fragmentation and centralization. he identifies the various cliques, components and circles into which networks are formed, and outlines an approach to the study of socially structured positions. he also discusses the use of multidimensional methods for investigating social networks.</p><p></p><p><b>social network analysis</b> is an invaluable resource for researchers across the social sciences and for students of social theory and research methods.</p>}"
1279898,inproceedings,,proceedings of the sigchi conference on human factors in computing systems,chi,acm,9,,,2007,,2007-05-05 20:33:20,"new york, ny, usa",why we tag: motivations for annotation in mobile and online media,"why do people tag? users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. we investigate the incentives for annotation in flickr, a popular web-based photo-sharing system, and {zonetag}, a cameraphone photo capture and annotation tool that uploads images to flickr. in flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. {zonetag}, in turn, makes it easier to tag cameraphone photos that are uploaded to flickr by allowing annotation and suggesting relevant tags immediately after capture. a qualitative study of {zonetag}/flickr users exposed various tagging patterns and emerging motivations for photo annotation. we offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation."
3746363,article,microbiology and molecular biology reviews,,,american society for microbiology,21,72,4,2008,dec,2008-12-04 12:34:48,,a bioinformatician's guide to metagenomics,"summary: as random shotgun metagenomic projects proliferate and become the dominant source of publicly available sequence data, procedures for the best practices in their execution and analysis become increasingly important. based on our experience at the joint genome institute, we describe the chain of decisions accompanying a metagenomic project from the viewpoint of the bioinformatic analysis step by step. we guide the reader through a standard workflow for a metagenomic project beginning with presequencing considerations such as community composition and sequence data type that will greatly influence downstream analyses. we proceed with recommendations for sampling and data generation including sample and metadata collection, community profiling, construction of shotgun libraries, and sequencing strategies. we then discuss the application of generic sequence processing steps (read preprocessing, assembly, and gene prediction and annotation) to metagenomic data sets in contrast to genome projects. different types of data analyses particular to metagenomes are then presented, including binning, dominant population analysis, and gene-centric analysis. finally, data management issues are presented and discussed. we hope that this review will assist bioinformaticians and biologists in making better-informed decisions on their journey during a metagenomic project."
574938,inproceedings,,icdcs,,ieee computer society,9,,,2005,,2006-04-03 23:59:10,"washington, dc, usa",comparison of approaches to service deployment,
698714,article,the journal of academic librarianship,,,,,,,-1,,2006-06-16 22:50:06,,revisioning information literacy for lifelong meaning,"information literacy is a broader capacity than current practices would suggest. in addition to critical thinking, information literacy includes information processes that explicitly address meaning, motivation, and the quality of life. a more robust notion of the concept delivers significant opportunities for libraries and instructional programs."
3860194,inproceedings,,proceedings of the 9th acm conference on computer and communications security,ccs,acm,9,,,2002,,2009-01-08 14:59:13,"new york, ny, usa",design and implementation of the <i>idemix</i> anonymous credential system,"anonymous credential systems [8, 9, 12, 24] allow anonymous yet authenticated and accountable transactions between users and service providers. as such, they represent a powerful technique for protecting users' privacy when conducting internet transactions. in this paper, we describe the design and implementation of an anonymous credential system based on the protocols developed by [6]. the system is based on new high-level primitives and interfaces allowing for easy integration into access control systems. the prototype was realized in java. we demonstrate its use and some deployment issues with the description of an operational demonstration scenario."
1687409,proceedings,"service-oriented system engineering, 2005. sose 2005. ieee international workshop","service-oriented system engineering, 2005. sose 2005. ieee international workshop",,,3,,,2005,dec,2007-09-23 16:25:13,,service-oriented system engineering: a new paradigm,"in the past a few years, we witnessed a rapid progress in service-oriented computing ({soc}), which represents a paradigm shift from the current mainstream object-oriented computing ({ooc}) paradigm to the {soc} paradigm. this paradigm shift is changing the way we develop and use software and hardware. conferences, journals, books, research, experimentation, tools, and products in {soc}, service-oriented architecture ({soa}), service-oriented enterprise ({soe}), service-oriented infrastructure ({soi}), web services ({ws}), and associated protocols and standards have emerged and a solid foundation for the new paradigm is being grounded. this paper focuses on the system engineering issues in the new paradigm."
375429,article,college english,,,,18,57,7,1995,,2005-11-01 18:11:12,,"plagiarisms, authorships, and the academic death penalty",
10107082,article,pattern analysis \& applications,,,springer london,12,,,2011,dec,2011-12-08 14:32:04,,expectation-maximization algorithms for inference in dirichlet processes mixture,"mixture models are ubiquitous in applied science. in many real-world applications, the number of mixture components needs to be estimated from the data. a popular approach consists of using information criteria to perform model selection. another approach which has become very popular over the past few years consists of using dirichlet processes mixture ({dpm}) models. both approaches are computationally intensive. the use of information criteria requires computing the maximum likelihood parameter estimates for each candidate model whereas {dpm} are usually trained using markov chain monte carlo ({mcmc}) or variational bayes ({vb}) methods. we propose here original batch and recursive expectation-maximization algorithms to estimate the parameters of {dpm}. the performance of our algorithms is demonstrated on several applications including image segmentation and image classification tasks. our algorithms are computationally much more efficient than {mcmc} and {vb} and outperform {vb} on an example."
12478098,article,nature,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",3,499,7457,2013,jul,2013-07-14 22:30:20,,observation of trapped light within the radiation continuum,"the ability to confine light is important both scientifically and technologically. many light confinement methods exist, but they all achieve confinement with materials or systems that forbid outgoing waves. these systems can be implemented by metallic mirrors, by photonic band-gap materials, by highly disordered media (anderson localization) and, for a subset of outgoing waves, by translational symmetry (total internal reflection) or by rotational or reflection symmetry. exceptions to these examples exist only in theoretical proposals. here we predict and show experimentally that light can be perfectly confined in a patterned dielectric slab, even though outgoing waves are allowed in the surrounding medium. technically, this is an observation of an \&\#24;embedded eigenvalue\&\#25;\&\#20;namely, a bound state in a continuum of radiation modes\&\#20;that is not due to symmetry incompatibility. such a bound state can exist stably in a general class of geometries in which all of its radiation amplitudes vanish simultaneously as a result of destructive interference. this method to trap electromagnetic waves is also applicable to electronic and mechanical waves."
10518521,article,physics reports,,,,83,519,4-5,2012,mar,2015-02-21 16:18:20,,nonperturbative quantum gravity,
1527590,article,trends in molecular medicine,,,,7,13,4,2007,apr,2007-08-01 14:28:53,"the babraham institute, babraham, cambridge, uk.","aβ, tau and {apoe4} in alzheimer's disease: the axonal connection","mutations in amyloid precursor protein ({app}), tau and apolipoprotein e4 ({apoe4}) lead to alzheimer's disease ({ad}) or related pathologies. pathogenesis and interactions between these pathways have been studied in mouse models. here, we highlight the fact that axons are important sites of cellular pathology in each pathway and propose that pathway convergence at the molecular level might occur in axons. recent developments suggest that axonal transport of {app} influences beta-amyloid deposition and that tau regulates axonal transport. {apoe4} influences both axonal tau phosphorylation and amyloid-induced neurite pathology. thus, a better understanding of axonal events in {ad} might help connect the pathogenic mechanisms of beta-amyloid, {apoe4} and tau, indicating the most important steps for therapeutic targeting."
7364971,article,international journal of multiphase flow,,,,19,10,1,1983,oct,2010-06-29 09:45:39,,a theoretical model for core-annular flow of a very viscous oil core and a water annulus through a horizontal pipe,"a theoretical model has been developed for core-annular flow of a very viscous oil core and a water annulus through a horizontal pipe. special attention was paid to understanding how the buoyancy force on the core, resulting from any density difference between the oil and water, is counterbalanced. this problem was simplified by assuming the oil viscosity to be so high that any flow inside the core may be neglected and hence that there is no variation of the profile of the oil-water interface with time. in the model the core is assumed to be solid and the interface to be a solid/liquid interface. by means of the hydrodynamic lubrication theory it has been shown that the ripples on the interface moving with respect to the pipe wall can generate pressure variations in the annular layer. these result in a force acting perpendicularly on the core, which can counterbalance the buoyancy effect. to check the validity of the model, oil-water core-annular flow experiments have been carried out in a 5.08 cm and an 20.32-cm pipeline. pressure drops measured have been compared with those calculated with the aid of the model. the agreement is satisfactory."
5778911,article,proceedings of the national academy of sciences,,,,,106,36,2009,sep,2009-09-13 08:04:52,,in defense of statistical methods for detecting positive selection,10.1073/pnas.0904550106
10423909,article,proceedings of the national academy of sciences,,,national academy of sciences,3,109,10,2012,mar,2012-03-07 10:58:10,,critical perspectives on historical collapse,"historical collapse of ancient states or civilizations has raised new awareness about its possible relevance to current issues of sustainability, in the context of global change. this special feature examines 12 case studies of societies under stress, of which seven suffered severe transformation. outcomes were complex and unpredictable. five others overcame breakdown through environmental, political, or socio-cultural resilience, which deserves as much attention as the identification of stressors. response to environmental crises of the last millennium varied greatly according to place and time but drew from traditional knowledge to evaluate new information or experiment with increasing flexibility, even if modernization or intensification were decentralized and protracted. longer-term diachronic experience offers insight into how societies have dealt with acute stress, a more instructive perspective for the future than is offered by apocalyptic scenarios."
7042061,article,new phytologist,,,blackwell publishing ltd,15,186,3,2010,,2010-05-06 18:23:20,"the rowland institute at harvard, cambridge, ma, usa;  institute of forest genetics, pacific southwest research station, usda forest service, davis, ca, usa",evolution of development of vascular cambia and secondary growth,"contents {summary577i}.{introduction577ii}.generalized function of vascular cambia and their developmental and evolutionary {origins578iii}.variation in secondary vascular growth in {angiosperms581iv}.genes and mechanisms regulating secondary vascular growth and their evolutionary {origins584v}.evolution of development approaches for the study of secondary vascular {growth587vi}.{conclusions589acknowledgements589references589} summary secondary growth from vascular cambia results in radial, woody growth of stems. the innovation of secondary vascular development during plant evolution allowed the production of novel plant forms ranging from massive forest trees to flexible, woody lianas. we present examples of the extensive phylogenetic variation in secondary vascular growth and discuss current knowledge of genes that regulate the development of vascular cambia and woody tissues. from these foundations, we propose strategies for genomics-based research in the evolution of development, which is a next logical step in the study of secondary growth."
2601798,article,proteins,,,"wiley subscription services, inc., a wiley company",12,59,2,2005,,2008-03-27 13:04:48,"department of chemistry and chemical biology, northeastern university, boston, massachusetts; college of computer and information sciences, northeastern university, boston, massachusetts; institute for complex scientific software, northeastern university, boston, massachusetts",statistical criteria for the identification of protein active sites using theoretical microscopic titration curves,"theoretical microscopic titration curves ({thematics}) may be used to identify chemically important residues in active sites of enzymes by characteristic deviations from the normal, sigmoidal {henderson–hasselbalch} titration behavior. clusters of such deviant residues in physical proximity constitute reliable predictors of the location of the active site. originally the residues with deviant predicted behavior were identified by human observation of the computed titration curves. however, it is preferable to select the unusual residues by mathematically well-defined criteria, in order to reduce the chance of error, eliminate any possible biases, and substantially speed up the selection process. here we present some simple statistical tests that constitute such selection criteria. the first derivatives of the predicted titration curves resemble distribution functions and are normalized. the moments of these first derivative functions are computed. it is shown that the third and fourth moments, measures of asymmetry and kurtosis, respectively, are good measures of the deviations from normal behavior. results are presented for 44 different enzymes. detailed results are given for 4 enzymes with 4 different types of chemistry: arginine kinase from limulus polyphemus (horseshoe crab); β-lactamase from escherichia coli; glutamate racemase from aquifex pyrophilus; and 3-isopropylmalate dehydrogenase from thiobacillus ferrooxidans. the relationship between the statistical measures of nonsigmoidal behavior in the predicted titration curves and the catalytic activity of the residue is discussed. proteins 2005. {\copyright} 2005 {wiley-liss}, inc."
11187279,article,british journal of educational technology,,,,14,43,5,2012,,2012-09-04 19:26:13,,online people tagging: social (mobile) network(ing) services and work-based learning,"social and mobile technologies offer users unprecedented opportunities for communicating, interacting, sharing, meaning-making, content and context generation. and, these affordances are in constant flux driven by a powerful interplay between technological innovation and emerging cultural practices. significantly, also, they are starting to transcend the everyday lifeworlds of users and permeate the workplace and its practices. however, given the emergent nature of this area, the literature on the use of social and mobile technologies in workplace practices is still small. indeed, social media are increasingly being accessed via mobile devices. our main focus, therefore, here is on the question of what, if any, potential there is for the use of social media in informal, professional, work-based learning. the paper provides a critical overview of key issues from the literature on work-based learning, face-to-face and technology-supported, as well as social (mobile) networking services, with particular attention being paid to people tagging. it then introduces an initial typology of informal workplace learning in order to provide a frame for understanding social (mobile) network(ing) services in work-based learning. finally, a case study (taken from the literature) of people tagging tool use in digital social networks in the european commission-funded {mature} project is used to illustrate aspects of our typology. practitioner notes what is already known about this topic * the importance of social networks and associated technologies in everyday life and commerce. * some conceptualisations of learning through and at work exist, but they tend to be based on the empirical study of professionals and graduate employees. * the concept of tagging in relation to digital resources is well established. what this paper adds * a consideration of the use of social networks in learning in informal and work-based context. * an exploration of some of the affordances of social media for work-located learning. * a widening of the concept of tagging to the classification of knowledge embodied in users and their social networks. * a typology of factors in social network(ing) services and work-based learning. * an analysis of a case study of people tagging in relation to the typology of factors. implications for practice * a conceptualisation of aspects of technology-enhanced and enabled learning through and at work. * an understanding of the potential of social media for work-located learning. * a realisation of some of the potential of the use of social media in informal, professional work-based learning."
156321,article,the information society,,,,14,,3,-1,,2005-04-09 02:14:51,,the world summit on the information society and civil society participation,"this article offers a descriptive analysis of the united nations world summit on the information society ({wsis}) and the involvement of civil society organizations in it. theoretical and empirical literature on global civil society, a \&\#147;third sector\&\#148; distinct from government and business, makes it clear that its changing role in international governance processes raises important political issues. this article examines what {wsis} tells us about how this dynamic is playing out in communication and information policy."
6729129,article,j. phys. chem. b,,,american chemical society,8,114,8,2010,feb,2010-02-26 13:37:36,,on the antibacterial action of cyclic peptides: insights from {coarse-grained} {md} simulations,"[{rrkwlwlw}] cyclic peptides have been shown to exhibit remarkable in vitro and in vivo antibacterial activity. peptides alike seem to be promising for the development of new compounds to combat microbial pathogens, yet the molecular level understanding of their mechanism of action remains unclear. here, we use coarse-grained ({cg}) molecular dynamics ({md}) simulations of these cyclic peptides interacting with antibacterial cytoplasmic membrane models composed of a mixture of palmitoyl-oleoyl-phosphatidyl-ethanolamine ({pope}) and palmitoyl-oleoyl-phosphatidylglycerol ({popg}) lipid bilayers to provide a better understanding of their mode of action. in particular, the {md} simulations performed at various concentrations of membrane-bound cyclic peptides reveal a novel type of mechanism in which the peptides first self-assemble at the membrane interface into amphipathic nanotubes. at high enough concentrations, coating of the membrane causes extrusion of lipids from the exposed bilayer leaflet, leading ultimately to a release of phospholipid micellar aggregates. furthermore, the cyclic peptides also induce a drastic change in the lateral pressure profiles of the exposed leaflet, indicating a direct effect on the mechanical properties of the bilayer. [{rrkwlwlw}] cyclic peptides have been shown to exhibit remarkable in vitro and in vivo antibacterial activity. peptides alike seem to be promising for the development of new compounds to combat microbial pathogens, yet the molecular level understanding of their mechanism of action remains unclear. here, we use coarse-grained ({cg}) molecular dynamics ({md}) simulations of these cyclic peptides interacting with antibacterial cytoplasmic membrane models composed of a mixture of palmitoyl-oleoyl-phosphatidyl-ethanolamine ({pope}) and palmitoyl-oleoyl-phosphatidylglycerol ({popg}) lipid bilayers to provide a better understanding of their mode of action. in particular, the {md} simulations performed at various concentrations of membrane-bound cyclic peptides reveal a novel type of mechanism in which the peptides first self-assemble at the membrane interface into amphipathic nanotubes. at high enough concentrations, coating of the membrane causes extrusion of lipids from the exposed bilayer leaflet, leading ultimately to a release of phospholipid micellar aggregates. furthermore, the cyclic peptides also induce a drastic change in the lateral pressure profiles of the exposed leaflet, indicating a direct effect on the mechanical properties of the bilayer."
3470214,article,annals of botany,,,,21,100,5,2007,oct,2008-10-31 16:25:01,,contrasting patterns in crop domestication and domestication rates: recent archaeobotanical insights from the old world,"10.1093/aob/mcm048 background archaeobotany, the study of plant remains from sites of ancient human activity, provides data for studying the initial evolution of domesticated plants. an important background to this is defining the domestication syndrome, those traits by which domesticated plants differ from wild relatives. these traits include features that have been selected under the conditions of cultivation. from archaeological remains the easiest traits to study are seed size and in cereal crops the loss of natural seed {dispersal.scope} the rate at which these features evolved and the ordering in which they evolved can now be documented for a few crops of asia and africa. this paper explores this in einkorn wheat (triticum monococcum) and barley (hordeum vulgare) from the near east, rice (oryza sativa) from china, mung (vigna radiata) and urd (vigna mungo) beans from india, and pearl millet (pennisetum glaucum) from west africa. brief reference is made to similar data on lentils (lens culinaris), peas (pisum sativum), soybean (glycine max) and adzuki bean (vigna angularis). available quantitative data from archaeological finds are compiled to explore changes with domestication. the disjunction in cereals between seed size increase and dispersal is explored, and rates at which these features evolved are estimated from archaeobotanical data. contrasts between crops, especially between cereals and pulses, are {examined.conclusions} these data suggest that in domesticated grasses, changes in grain size and shape evolved prior to non-shattering ears or panicles. initial grain size increases may have evolved during the first centuries of cultivation, within perhaps 500\^{a}1000 years. non-shattering infructescences were much slower, becoming fixed about 1000\^{a}2000 years later. this suggests a need to reconsider the role of sickle harvesting in domestication. pulses, by contrast, do not show evidence for seed size increase in relation to the earliest cultivation, and seed size increase may be delayed by 2000\^{a}4000 years. this implies that conditions that were sufficient to select for larger seed size in poaceae were not sufficient in fabaceae. it is proposed that animal-drawn ploughs (or ards) provided the selection pressure for larger seeds in legumes. this implies different thresholds of selective pressure, for example in relation to differing seed ontogenetics and underlying genetic architecture in these families. pearl millet (pennisetum glaucum) may show some similarities to the pulses in terms of a lag-time before truly larger-grained forms evolved."
6210267,article,language learning,,,blackwell publishing inc,25,59,s1,2009,,2009-11-25 14:54:13,university of new mexico;  university of edinburgh;  university of new mexico;  cornell university;  university of new mexico;  university of michigan;  santa fe institute; university of michigan;  university of michigan;  university of michigan;  indiana university,language is a complex adaptive system: position paper,"language has a fundamentally social function. processes of human interaction along with domain-general cognitive processes shape the structure and knowledge of language. recent research in the cognitive sciences has demonstrated that patterns of use strongly affect how language is acquired, is used, and changes. these processes are not independent of one another but are facets of the same complex adaptive system ({cas}). language as a {cas} involves the following key features: the system consists of multiple agents (the speakers in the speech community) interacting with one another. the system is adaptive; that is, speakers' behavior is based on their past interactions, and current and past interactions together feed forward into future behavior. a speaker's behavior is the consequence of competing factors ranging from perceptual constraints to social motivations. the structures of language emerge from interrelated patterns of experience, social interaction, and cognitive mechanisms. the {cas} approach reveals commonalities in many areas of language research, including first and second language acquisition, historical linguistics, psycholinguistics, language evolution, and computational modeling."
6556748,article,medical hypotheses,,,,4,47,5,1996,nov,2010-01-18 15:27:20,,"autism, asperger's syndrome and the crick-mitchison theory of the biological function of {rem} sleep","autism, asperger's syndrome and other autistic syndromes are developmental brain disorders that cause serious impairments in communication, social interaction, empathy, mood and play. in addition to such deficits, the autistic syndromes involve pathologically high levels of repetitive, stereotypic, ritualistic, compulsive or obsessive behavior, together with extreme resistance to change. according to the {crick-mitchison} theory of the biological function of rapid eye movement sleep, normal brain development in the fetus and infant depends on undisrupted function of a 'reverse learning' mechanism during rapid eye movement sleep. could abnormalities in this hypothetical reverse learning during rapid eye movement sleep in the fetus explain some aspects of the autistic syndromes? does the {crick-mitchison} theory suggest if a drug could interfere with rapid eye movement sleep and cross the placental barrier, then that drug might cause developmental brain disorders in the fetus? should all pregnant women completely avoid caffeine or any agent that might disrupt serotonergic or cholinergic systems?"
11598325,article,nature genetics,,,nature research,7,44,12,2012,oct,2012-11-01 13:26:50,,bayesian refinement of association signals for 14 loci in 3 common diseases,
5816110,article,bull. amer. meteor. soc.,bulletin of the american meteorological society,,american meteorological society,12,90,8,2009,aug,2009-09-21 21:51:12,,the potential to narrow uncertainty in regional climate predictions,"abstract faced by the realities of a changing climate, decision makers in a wide variety of organizations are increasingly seeking quantitative predictions of regional and local climate. an important issue for these decision makers, and for organizations that fund climate research, is what is the potential for climate science to deliver improvements?especially reductions in uncertainty?in such predictions? uncertainty in climate predictions arises from three distinct sources: internal variability, model uncertainty, and scenario uncertainty. using data from a suite of climate models, we separate and quantify these sources. for predictions of changes in surface air temperature on decadal timescales and regional spatial scales, we show that uncertainty for the next few decades is dominated by sources (model uncertainty and internal variability) that are potentially reducible through progress in climate science. furthermore, we find that model uncertainty is of greater importance than internal variability. our findings have implications for managing adaptation to a changing climate. because the costs of adaptation are very large, and greater uncertainty about future climate is likely to be associated with more expensive adaptation, reducing uncertainty in climate predictions is potentially of enormous economic value. we highlight the need for much more work to compare (a) the cost of various degrees of adaptation, given current levels of uncertainty and (b) the cost of new investments in climate science to reduce current levels of uncertainty. our study also highlights the importance of targeting climate science investments on the most promising opportunities to reduce prediction uncertainty."
11112808,misc,,,,,,,,2012,aug,2012-09-17 10:29:06,,{wilson-loop} characterization of {inversion-symmetric} topological insulators,
1511388,article,computers and composition,,,,26,19,4,2002,dec,2007-07-29 14:31:12,,annotation technologies: a software and research review,"this article describes a range of currently available and developing technologies for creating and presenting annotations, glosses, and other comments on digital documents. the potential applications of these tools for providing feedback to student writers, supporting extended group discussions around digital texts, and facilitating research and reading-to-write tasks are discussed. different software programs are compared and evaluated and composition researchers are urged to engage in research that will influence the design of future annotation technologies."
3800659,article,"pervasive computing, ieee",,,ieee,6,7,4,2008,oct,2008-12-17 07:59:39,"los alamitos, ca, usa",{openstreetmap}: {user-generated} street maps,"the activity of mapping our environment used to be the preserve of highly trained and well-equipped surveyors and cartographers. the increase in the availability of computing in the wider environment through laptops, hand-held computers, and mobile phones, in combination with the free access to location information from {gps} satellites, provided new opportunities for a wider range of people to be part of mapping activities and to create a bottom-up map, generated by users. in this article, we describe the open geodata project {openstreetmap}. we provide an overview of the project, the techniques used to collect, organize, and deliver mapping information, and conclude with an analysis of the opportunities and challenges that the project faces."
6540236,article,physical review letters,,,american physical society,,93,15,2004,oct,2010-01-14 13:16:47,,four-unit-cell superstructure in the optimally doped \$yba\_{2}cu\_{3}o\_{6.92}\$ superconductor,"diffuse x-ray scattering measurements reveal that the optimally doped {yba2cu3o6}.92 superconductor is intrinsically modulated due to the formation of a kinetically limited 4-unit-cell superlattice, q0=(1/4,0,0), along the shorter {cu-cu} bonds. the superlattice consists of large anisotropic displacements of cu, ba, and o atoms, respectively, which are correlated over ∼3–6 unit cells in the ab plane, and appears to be consistent with the presence of an o-ordered  ” {ortho-iv}” phase. long-range strains emanating from these modulated regions generate an inhomogeneous lattice which may play a fundamentally important role in the electronic properties of yttrium-barium-copper-oxides."
4371564,article,,,,the royal society,23,367,1895,2009,may,2009-06-15 11:58:30,,chaste: incorporating a novel multi-scale spatial and temporal algorithm into a large-scale open source library,"recent work has described the software engineering and computational infrastructure that has been set up as part of the cancer, heart and soft tissue environment (chaste) project. chaste is an open source software package that currently has heart and cancer modelling functionality. this software has been written using a programming paradigm imported from the commercial sector and has resulted in a code that has been subject to a far more rigorous testing procedure than that is usual in this field. in this paper, we explain how new functionality may be incorporated into chaste. whiteley has developed a numerical algorithm for solving the bidomain equations that uses the multi-scale ({ms}) nature of the physiology modelled to enhance computational efficiency. using a simple geometry in two dimensions and a purpose-built code, this algorithm was reported to give an increase in computational efficiency of more than two orders of magnitude. in this paper, we begin by reviewing numerical methods currently in use for solving the bidomain equations, explaining how these methods may be developed to use the {ms} algorithm discussed above. we then demonstrate the use of this algorithm within the chaste framework for solving the monodomain and bidomain equations in a three-dimensional realistic heart geometry. finally, we discuss how chaste may be developed to include new physiological functionality—such as modelling a beating heart and fluid flow in the heart—and how new algorithms aimed at increasing the efficiency of the code may be incorporated."
1068939,article,future generation computer systems,,,,4,22,8,2006,oct,2007-01-26 09:21:12,,the network infrastructure at {igrid2005}: lambda networking in action,"{igrid2005}'s goal was to demonstrate the potential of hybrid networks showing applications that require the use of these high-performance multi-gigabit networks. in this article we describe the network infrastructure in place during the workshop, we focus on the innovative and original aspects of the set-up, and we show that the infrastructure was a clear example of lambda networking."
2305580,inbook,progress in brain research,visual perception - fundamentals of vision: low and mid-level processes in perception,progress in brain research,elsevier,15,154,,2006,,2008-01-30 00:54:31,"computational neuroscience, department of psychology, university of potsdam, po box 601553, 14415 potsdam, germany. engbert@rz.uni-pstdam.de","microsaccades: a microcosm for research on oculomotor control, attention, and visual perception","miniature eye movements occur involuntarily during visual fixation. the most prominent contribution to these fixational eye movements is generated by microsaccades, which are rapid small-amplitude saccades with a rate of about one per second. recent work demonstrates that microsaccades are optimized to counteract perceptual fading during perception of a stationary scene. furthermore, microsaccades are modulated by visual attention and turned out to generate rich spatio-temporal dynamics. we conclude that the investigation of microsaccades will evolve into a new research field contributing to many facets of oculomotor control, visual perception, and the allocation of attention."
6398687,article,the journal of physical chemistry b,,,,8,113,51,2009,dec,2010-01-21 03:21:26,,fluorine in protein environments: a {qm} and {md} study,"{pmid}: 19947631 noncanonical amino acids with newly designed side-chain functionalities represent powerful tools to improve structural, biological, and pharmacological properties of peptides and proteins. in this context, fluorinated amino acids have increasingly gained importance. despite the current wide use of fluorination in protein engineering, the basic properties of fluorine in protein environments are still not completely understood. our aim has been to characterize the physicochemical properties of fluorinated amino acids by using quantum mechanics ({qm}) and molecular dynamics ({md}) approaches. we have analyzed geometry, charges, and hydrogen bonding abilities of several ethane fluorinated derivatives at different {qm} theory levels and have used them as simplified models for fluorinated amino acid side chains. we have parametrized four fluorinated l-amino acids for the {amber} ff94/99 force field: 4-monofluoroethylglycine ({mfegly}), 4,4-difluoroethylglycine ({dfegly}), 4,4,4-trifluoroethylglycine ({tfegly}), and 4,4-difluoropropylglycine ({dfpgly}). we have characterized them in terms of molecular volumes, conformational preferences, and hydration properties. the obtained results illustrate that fluorine and hydrogen atoms of fluoromethyl groups could be potential acceptors or donors of weak hydrogen bonds in protein environments. hydration of the studied fluorinated amino acids was found to be more favorable than for their nonfluorinated analogues, and hydrophobicity was observed to increase with the number of fluorine atoms, which is in accordance with the experimental retention times we obtain for these amino acids. this study broadens our understanding of the properties of fluorine within protein environments, which is important to exploit the full potential of fluorine's unique properties for applications in the field of protein engineering."
3057670,article,physical review b,,,american physical society,,74,12,2006,sep,2008-07-29 20:54:55,,comparison of screened hybrid density functional theory to diffusion monte carlo in calculations of total energies of silicon phases and defects,"nearly quantitative agreement between density functional theory ({dft}) and diffusion monte carlo ({dmc}) calculations is shown for the prediction of defect properties using the {heyd-scuseria}-ernzerhof ({hse}) screened-exchange hybrid functional. the {hse} functional enables accurate computations on complex systems, such as defects, where traditional {dft} may be inadequate and {dmc} calculation computationally unfeasible. the screened-exchange hybrid functional retains the benefits of earlier hybrid functionals in terms of treating strongly correlated insulators but unlike them it can be applied to metallic phases. this study concentrates on the {dft} energetic predictions of point defects in silicon and on phase energy differences between the diamond and metallic  β -tin phases."
6652978,article,genetics,,,,10,150,1,1998,sep,2010-02-11 09:59:20,,wolbachia transfer from drosophila melanogaster into d. simulans: host effect and cytoplasmic incompatibility relationships,"wolbachia are maternally transmitted endocellular bacteria causing a reproductive incompatibility called cytoplasmic incompatibility ({ci}) in several arthropod species, including drosophila. {ci} results in embryonic mortality in incompatible crosses. the only bacterial strain known to infect drosophila melanogaster ({wdm}) was transferred from a d. melanogaster isofemale line into uninfected d. simulans isofemale lines by embryo microinjections. males from the resulting transinfected lines induce >98\% embryonic mortality when crossed with uninfected d. simulans females. in contrast, males from the donor d. melanogaster line induce only 18-32\% {ci} on average when crossed with uninfected d. melanogaster females. transinfected d. simulans lines do not differ from the d. melanogaster donor line in the wolbachia load found in the embryo or in the total bacterial load of young males. however, >80\% of cysts are infected by wolbachia in the testes of young transinfected males, whereas only 8\% of cysts are infected in young males from the d. melanogaster donor isofemale line. this difference might be caused by physiological differences between hosts, but it might also involve tissue-specific control of wolbachia density by d. melanogaster. the {wdm}-transinfected d. simulans lines are unidirectionally incompatible with strains infected by the {non-ci} expressor wolbachia strains {wki}, {wmau}, or {wau}, and they are bidirectionally incompatible with strains infected by the {ci}-expressor wolbachia strains {wha} or {wno}. however, {wdm}-infected males do not induce {ci} toward females infected by the {ci}-expressor strain {wri}, which is found in d. simulans continental populations, while {wri}-infected males induce partial {ci} toward {wdm}-infected females. this peculiar asymmetrical pattern could reflect an ongoing divergence between the {ci} mechanisms of {wri} and {wdm}. it would also confirm other results indicating that the factor responsible for {ci} induction in males is distinct from the factor responsible for {ci} rescue in females."
436980,article,current biology : cb,,,,9,15,11,2005,jun,2005-12-13 15:22:05,"section of microbiology, division of biological sciences, university of california, davis, davis, california 95616, usa.",{wsh3/tea4} is a novel cell-end factor essential for bipolar distribution of tea1 and protects cell polarity under environmental stress in s. pombe.,"{background}: the fission yeast schizosaccharomyces pombe has a cylindrical cell shape, for which growth is strictly limited to both ends, and serves as an excellent model system for genetic analysis of cell-polarity determination. previous studies identified a cell-end marker protein, tea1, that is transported by cytoplasmic microtubules to cell tips and recruits other cell-end factors, including the dyrk-family pom1 kinase. the deltatea1 mutant cells cannot grow in a bipolar fashion and show t-shaped morphology after heat shock. {results}: we identified {wsh3/tea4} as a novel protein that interacts with win1 {map} kinase kinase kinase ({mapkkk}) of the stress-activated {map} kinase cascade. wsh3 forms a complex with tea1 and is transported to cell tips by growing microtubules. the deltawsh3 mutant shows monopolar growth with abnormal tea1 aggregate at the non-growing cell end; this abnormal aggregate fails to recruit pom1 kinase. consistent with the observed interaction between win1 and wsh3, cells lacking wsh3 or tea1 show more severe cell-polarity defects under osmolarity and heat-stress stimuli that are known to activate the stress {mapk} cascade. furthermore, mutants of the stress {mapk} also exhibit cell-polarity defects when exposed to the same stress. {conclusions}: {wsh3/tea4} is an essential component of the tea1 cell-end complex. in addition to its role in bipolar growth during the normal cell cycle, the {wsh3-tea1} complex, together with the stress-signaling {mapk} cascade, contributes to cell-polarity maintenance under stress conditions."
7175823,article,proteins,,,,11,78,10,2010,aug,2010-05-16 17:44:20,"center for computational biology and bioinformatics and college of engineering, koc university, istanbul, turkey",analysis and network representation of hotspots in protein interfaces using minimum cut trees.,"we propose a novel approach to analyze and visualize residue contact networks of protein interfaces by graph-based algorithms using a minimum cut tree (mincut tree). edges in the network are weighted according to an energy function derived from knowledge-based potentials. the mincut tree, which is constructed from the weighted residue network, simplifies and summarizes the complex structure of the contact network by an efficient and informative representation. this representation offers a comprehensible view of critical residues and facilitates the inspection of their organization. we observed, on a nonredundant data set of 38 protein complexes with experimental hotspots that the highest degree node in the mincut tree usually corresponds to an experimental hotspot. further, hotspots are found in a few paths in the mincut tree. in addition, we examine the organization of hotspots (hot regions) using an iterative clustering algorithm on two different case studies. we find that distinct hot regions are located on specific sites of the mincut tree and some critical residues hold these clusters together. clustering of the interface residues provides information about the relation of hot regions with each other. our new approach is useful at the molecular level for both identification of critical paths in the protein interfaces and extraction of hot regions by clustering of the interface residues."
4111414,article,patient education and counseling,,,,5,74,2,2009,feb,2009-02-27 15:28:10,,"paternalism, participation and partnership - the evolution of patient centeredness in the consultation.","the structure and aims of the consultation must be re-visited in the light of the rapid pace of change in service delivery. as such, healthcare professionals may need to advocate for the continuing role of the patient-centered consultation."
13510385,book,,,,society for industrial and applied mathematics,,,,2012,sep,2015-02-06 11:38:38,,assignment problems,"assignment problems is a useful tool for researchers, practitioners, and graduate students. it provides a comprehensive treatment of assignment problems from their conceptual beginnings in the 1920s through present-day theoretical, algorithmic, and practical developments. the authors have organised the book into 10 self-contained chapters to make it easy for readers to use the specific chapters without having to read the book linearly. the topics covered include bipartite matching algorithms, linear assignment problems, quadratic assignment problems, multi-index assignment problems, and many variations of these problems. researchers will benefit from the detailed exposition of theory and algorithms related to assignment problems, including the basic linear sum assignment problem and its variations. practitioners will learn about practical applications of the methods, the performance of exact and heuristic algorithms, and software options. this book also can serve as a text for advanced courses in discrete mathematics, integer programming, combinatorial optimization, and algorithmic computer science."
3063605,article,international journal of educational research,,,,19,39,1-2,2003,jan,2008-07-30 16:29:02,,toward a social pedagogy of classroom group work,"in any classroom, pupils will be drawn together for many purposes and we can refer to such within classroom contexts as 'groupings'. the teacher often creates these, and the way that they are set up, and how they are used for particular learning purposes. if the relationships between grouping size, interaction type and learning tasks in groups are planned strategically then learning experiences will be more effective. however, research suggests that the relationships between these elements are often unplanned and the 'social pedagogic' potential of classroom learning is therefore unrealised. in this paper we explore the notion of social pedagogy in relation to group work. it is argued that research and theory relevant to group work in classrooms is limited, and that a new approach, sensitive to group work under everyday classroom conditions is required. this paper identifies key features of a social pedagogy of classroom group work, which can inform effective group work in classrooms. it also describes the background to a current large scale {uk} project which has been set up to design with teachers a programme of high quality group work in classrooms at both primary and secondary phases."
4164658,article,proc. vldb endow.,,,vldb endowment,11,1,1,2008,aug,2009-03-11 06:44:11,,{ed-join}: an efficient algorithm for similarity joins with edit distance constraints,"there has been considerable interest in similarity join in the research community recently. similarity join is a fundamental operation in many application areas, such as data integration and cleaning, bioinformatics, and pattern recognition. we focus on efficient algorithms for similarity join with edit distance constraints. existing approaches are mainly based on converting the edit distance constraint to a weaker constraint on the number of matching q-grams between pair of strings. in this paper, we propose the novel perspective of investigating mismatching q-grams. technically, we derive two new edit distance lower bounds by analyzing the locations and contents of mismatching q-grams. a new algorithm, {ed-join}, is proposed that exploits the new mismatch-based filtering methods; it achieves substantial reduction of the candidate sizes and hence saves computation time. we demonstrate experimentally that the new algorithm outperforms alternative methods on large-scale real datasets under a wide range of parameter settings."
6283954,article,physical review e,,,american physical society,,74,2,2006,aug,2009-12-02 13:00:20,,numerical study of a microscopic artificial swimmer,"we present a detailed numerical study of a microscopic artificial swimmer realized recently by dreyfus et al. in experiments [dreyfus et al., nature 437, 862 (2005)]. it consists of an elastic filament composed of superparamagnetic particles that are linked together by {dna} strands. attached to a load particle, the resulting swimmer is actuated by an oscillating external magnetic field so that it performs a nonreciprocal motion in order to move forward. we model the superparamagnetic filament by a bead-spring configuration that resists bending like a rigid rod and whose beads experience friction with the surrounding fluid and hydrodynamic interactions with each other. we show that, aside from finite-size effects, its dynamics is governed by the dimensionless sperm number, the magnitude of the magnetic field, and the angular amplitude of the field's oscillating direction. then we study the mean velocity and the efficiency of the swimmer as a function of these parameters and the size of the load particle. in particular, we clarify that the real velocity of the swimmer is influenced by two main factors, namely the shape of the beating filament (determined by the sperm number and the magnetic-field strength) and the oscillation frequency. furthermore, the load size influences the performance of the swimmer and has to be chosen as a compromise between the largest swimming velocity and the best efficiency. finally, we demonstrate that the direction of the swimming velocity changes in a symmetry-breaking transition when the angular amplitude of the field's oscillating direction is increased, in agreement with experiments."
2733205,article,bmc genomics,,,,,9,1,2008,apr,2008-05-01 15:51:18,,phylogenetic and comparative gene expression analysis of barley (hordeum vulgare) {wrky} transcription factor family reveals putatively retained functions between monocots and dicots,"{background}:{wrky} proteins belong to the {wrky}-{gcm1} superfamily of zinc finger transcription factors that have been subject to a large plant-specific diversification. for the cereal crop barley (hordeum vulgare), three different {wrky} proteins have been characterized so far as regulators in sucrose signaling, pathogen defense, and in response to cold and drought. however, their phylogenetic relationship remained {unresolved.results}:in this study, we used available sequence information to identify a minimum number of 45 barley {wrky} transcription factor ({hvwrky}) genes. according to their structural features, the {hvwrky} factors were classified into the previously defined polyphyletic {wrky} subgroups 1 to 3. furthermore, we could assign putative orthologs of the {hvwrky} proteins in arabidopsis and rice. while in most cases clades of orthologous proteins were formed within each group or subgroup, other clades were composed of paralogous proteins for the grasses and arabidopsis only, which is indicative of specific gene radiation events. to gain insight into their putative functions, we examined expression profiles of {wrky} genes from publicly available microarray data resources and found group specific expression patterns. while putative orthologs of the {hvwrky} transcription factors have been inferred from phylogenetic sequence analysis, we performed a comparative expression analysis of {wrky} genes in arabidopsis and barley. indeed, highly correlative expression profiles were found between some of the putative {orthologs.conclusion}:{hvwrky} genes have not only undergone radiation in monocot or dicot species, but exhibit evolutionary traits specific to grasses. {hvwrky} proteins exhibited not only sequence similarities between orthologs with arabidopsis, but also relatedness in their expression patterns. this correlative expression is indicative for a putative conserved function of related {wrky} proteins in monocot and dicot species."
2427239,misc,,,,,,,,2004,,2008-02-25 21:57:27,,the semantic webscape: a view of the semantic web,
5793945,article,hypertension,,,,6,40,5,2002,nov,2009-09-17 04:37:20,,"results of the diet, exercise, and weight loss intervention trial ({dew}-{it})","national guidelines for the prevention and treatment of hypertension recommend sodium reduction, weight loss, the dietary approach to stop hypertension ({dash}) diet, and regular aerobic exercise. however, no trial has assessed the efficacy of simultaneously implementing all of these recommendations. the objective of this study was to determine the effects on blood pressure and other cardiovascular disease risk factors of a comprehensive lifestyle intervention. we conducted a randomized controlled trial of 44 hypertensive, overweight adults on a single blood pressure medication. participants were randomized to a lifestyle or control group. for 9 weeks, the lifestyle group was fed a hypocaloric version of the {dash} diet that provided 100 mmol/d of sodium. this group also participated in a supervised, moderate-intensity exercise program 3 times per week. the control group received no intervention. outcomes were ambulatory blood pressure, serum lipids, weight, and fitness. at the end of the intervention, mean weight loss in the lifestyle group, net of control, was 4.9 kilograms. in the lifestyle group mean net reductions in 24-hour ambulatory systolic and diastolic blood pressures were 9.5 mm hg (p<0.001) and 5.3 mm hg (p<0.002), respectively. corresponding changes in daytime systolic and diastolic blood pressures were 12.1 mm hg (p<0.001) and 6.6 mm hg (p<0.001). the lifestyle group experienced mean reductions in total cholesterol (-25 {mg/dl}, p<0.001), low-density lipoprotein cholesterol (-18 {mg/dl}, p=0.005), high-density lipoprotein cholesterol (-5 {mg/dl}, p<0.001), net of control. in conclusion, among hypertensive overweight adults already on antihypertensive medication, a comprehensive lifestyle intervention can substantially lower blood pressure and improve blood pressure control. {10.1161/01.hyp}.{0000037217.96002.8e}"
6003901,article,pain,,,,11,147,1-3,2009,dec,2009-12-15 11:23:13,,absence of pain with hyperhidrosis: a new syndrome where vascular afferents may mediate cutaneous sensation.,"congenital absence of pain perception is a rare phenotype. here we report two unrelated adult individuals who have a previously unreported neuropathy consisting of congenital absence of pain with hyperhidrosis ({caph}). both subjects had normal intelligence and productive lives despite failure to experience pain due to broken bones, severe cold or burns. functional assessments revealed that both are generally hypesthetic with thresholds greater than two standard deviations above normal for a several of modalities in addition to noxious stimuli. sweating was 3 to 8-fold greater than normal. sural nerve biopsy showed that all types of myelinated and unmyelinated fibers were severely reduced. extensive multi-antibody immunofluorescence analyses were conducted on several skin biopsies from the hands and back of one {caph} subject and two normal subjects. the {caph} subject had all normal types of immunochemically and morphologically distinct sensory and autonomic innervation to the vasculature and sweat glands, including a previously unknown cholinergic arterial innervation. virtually all other types of normal cutaneous c, adelta and abeta-fiber endings were absent. this subject had no mutations in the genes {scn9a}, {scn10a}, {scn11a}, {ngfb}, {trka}, {nrtn} and {gfra2}. our findings suggest three hypotheses: (1) that development or maintenance of sensory innervation to cutaneous vasculature and sweat glands may be under separate genetic control from that of all other cutaneous sensory innervation, (2) the latter innervation is preferentially vulnerable to some environmental factor, and (3) vascular and sweat gland afferents may contribute to conscious cutaneous perception."
600742,inproceedings,,popl,,acm press,11,,,1992,,2006-04-25 22:28:36,"new york, ny, usa",a compilation method for {ml}-style polymorphic record calculi,
7877240,article,transport policy,,,,,,,2010,sep,2011-04-20 10:15:44,,enhancing park and ride with access control: a case study of southampton,"implementing and promoting more sustainable forms of urban transport are key policies of local authorities throughout the {uk}. park and ride ({p\&r}) is one such system implemented widely in the {uk}, especially in historic towns and cities with limited road and parking space in the centre. some cities (e.g. rome and london) have also implemented forms of 'access control' to reduce congestion and/or pollution in central areas. this paper describes a feasibility analysis of a unique application studied for potential implementation in southampton—the integration of {p\&r} with access control on a key corridor in eastern southampton where traffic demand is likely to increase significantly in the coming years because of new housing developments. the system concept is a {p\&r} facility with express buses to the city centre, keeping the corridor free-flowing for these buses (and other traffic) using a combination of bus lanes and access control. following an outline of the policy context and system design, this paper then describes the corridor and network modelling undertaken to predict the impacts of the scheme and alternatives of it. this has been based mainly on the {contram} dynamic traffic assignment model, which covers the whole of southampton and its surrounding motorway network. the assessment of the benefits of the various options in this scheme showed that the combination of {p\&r} with signalised access control was the best option to improve the movement of people on the corridor. the paper concludes with a discussion of potential issues for implementation, including the need for complimentary measures and a consistent policy framework."
3429347,article,,,,,,,,2009,jul,2008-10-19 17:23:16,,{tev} gamma rays from geminga and the origin of the {gev} positron excess,
3394152,article,plos genetics,,,public library of science,,4,10,2008,oct,2008-10-10 18:08:29,,a position effect on the heritability of epigenetic silencing.,"in animals and yeast, position effects have been well documented. in animals, the best example of this process is position effect variegation ({pev}) in drosophila melanogaster. in {pev}, when genes are moved into close proximity to constitutive heterochromatin, their expression can become unstable, resulting in variegated patches of gene expression. this process is regulated by a variety of proteins implicated in both chromatin remodeling and {rnai}-based silencing. a similar phenomenon is observed when transgenes are inserted into heterochromatic regions in fission yeast. in contrast, there are few examples of position effects in plants, and there are no documented examples in either plants or animals for positions that are associated with the reversal of previously established silenced states. {mudr} transposons in maize can be heritably silenced by a naturally occurring rearranged version of {mudr}. this element, muk, produces a long hairpin {rna} molecule that can trigger {dna} methylation and heritable silencing of one or many {mudr} elements. in most cases, {mudr} elements remain inactive even after muk segregates away. thus, muk-induced silencing involves a directed and heritable change in gene activity in the absence of changes in {dna} sequence. using classical genetic analysis, we have identified an exceptional position at which {mudr} element silencing is unstable. muk effectively silences the {mudr} element at this position. however, after muk is segregated away, element activity is restored. this restoration is accompanied by a reversal of {dna} methylation. to our knowledge, this is the first documented example of a position effect that is associated with the reversal of epigenetic silencing. this observation suggests that there are cis-acting sequences that alter the propensity of an epigenetically silenced gene to remain inactive. this raises the interesting possibility that an important feature of local chromatin environments may be the capacity to erase previously established epigenetic marks."
6843195,article,library hi tech,,,emerald group publishing limited,12,28,1,2010,mar,2010-06-24 18:01:51,,” power tags” in information retrieval,"\&\#{60;b}\&\#{62;purpose}\&\#{60;/b}\&\#62; - many web 2.0 services (including library 2.0 catalogs) make use of folksonomies. the purpose of this paper is to cut off all tags in the long tail of a document-specific tag distribution. the remaining tags at the beginning of a tag distribution are considered power tags and form a new, additional search option in information retrieval systems. \&\#{60;b}\&\#{62;design}/{methodology/approach\&\#60;/b}\&\#62; - in a theoretical approach the paper discusses document-specific tag distributions (power law and inverse-logistic shape), the development of such distributions ({yule-simon} process and shuffling theory) and introduces search tags (besides the well-known index tags) as a possibility for generating tag distributions. \&\#{60;b}\&\#{62;findings}\&\#{60;/b}\&\#62; - search tags are compatible with broad and narrow folksonomies and with all knowledge organization systems (e.g. classification systems and thesauri), while index tags are only applicable in broad folksonomies. based on these findings, the paper presents a sketch of an algorithm for mining and processing power tags in information retrieval systems. \&\#{60;b}\&\#{62;research} {limitations/implications\&\#60;/b}\&\#62; - this conceptual approach is in need of empirical evaluation in a concrete retrieval system. \&\#{60;b}\&\#{62;practical} {implications\&\#60;/b}\&\#62; - power tags are a new search option for retrieval systems to limit the amount of hits. \&\#{60;b}\&\#{62;originality}/{value\&\#60;/b}\&\#62; - the paper introduces power tags as a means for enhancing the precision of search results in information retrieval systems that apply folksonomies, e.g. catalogs in library 2.0 environments."
7386118,article,journal of real-time image processing,,,springer berlin / heidelberg,13,,,2010,jun,2011-02-08 23:35:01,,the {eisp} low-power and tiny silicon footprint programmable video architecture,"{cmos} sensors are now more and more frequently integrated into popular consumer products. images from these sensors thus need to be digitally processed for display purposes. to do so, {cmos} sensors are associated with dedicated components that keep power consumption low. however, use of dedicated components limits hardware flexibility and prevents updating of image processing algorithms. this paper describes the {eisp}, a programmable processing architecture that combines enough computational efficiency for 1080p {hd} video with silicon area and power characteristics suitable for the next generation of mobile phones (lower than 1 mm2 and 500 {mw} in {tsmc} 65 nm)."
7657488,article,social science research network working paper series,,,ssrn,,,,2009,dec,2010-08-16 17:41:13,,"social transmission, emotion, and the virality of online content","why are certain pieces of online content more viral than others?  this article takes a psychological approach to understanding diffusion. using a unique dataset of all the new york times articles published over a three month period, the authors examine the link between integral affect (i.e., the emotion evoked) and whether content is highly shared. results suggest a strong relationship between emotion and virality, but indicate that this link is more complex than mere valence alone.  positive content is more viral (than negative content), as is content that inspires awe. but while sad content is less viral, anger or anxiety inducing articles are both more likely to make the paper's most emailed list. these results hold controlling for how surprising, interesting, or practically useful content is (all of which are positively linked to virality), as well as external drivers of attention (e.g., how prominently articles were featured). the findings shed light on why people share online content, provide insight into how to design effective viral marketing campaigns, and underscore the importance of individual-level psychological processes in shaping collective outcomes."
8994081,article,the journal of applied psychology,,,,24,88,5,2003,oct,2011-03-15 12:06:51,,common method biases in behavioral research: a critical review of the literature and recommended remedies.,
2464873,article,system,,,,2,34,2,2006,jun,2008-03-04 13:43:23,,"bogaards, p., laufer, b. (eds.), 2004, vocabulary in a second language, john benjamins, amsterdam. xiv + 233 pp.",
1579135,article,"journal of child psychology and psychiatry, and allied disciplines",,,blackwell publishing,8,48,9,2007,sep,2010-05-07 20:01:33,,between a {roc} and a hard place: decision making and making decisions about using the {scq}.,"{background}: the social communication questionnaire ({scq}), formerly the autism screening questionnaire ({asq}), is based on a well-validated parent interview, the autism diagnostic interview ({adi}). it has shown promise as a screening measure for autism spectrum disorders ({asds}) in a research-referred older sample, though recent studies with younger children reported lower sensitivities when using the suggested cutoff of > or = 15 to differentiate {asds} from children with nonspectrum disorders ({ns}). {methods}: diagnostic discrimination of the {scq} was evaluated alone and in combination with the {ados} (autism diagnostic observation schedule) in a clinical and research-referred sample of 590 children and adolescents (2 to 16 years), with best estimate consensus diagnoses of autism, pervasive developmental disorder, not otherwise specified ({pdd}-{nos}) and {non-asd} disorders. the {scq} was completed before the evaluation in most cases. performance of the {scq} was also compared with the autism diagnostic interview - revised ({adi}-r). {results}: absolute scores and sensitivity in the younger children and specificity for all groups were lower than reported in the original study. using receiver operating curves ({roc}) to examine the area under the curve ({auc}), the {scq} was more similar to the {adi}-r total score in differentiating {asd} from {ns} disorders in the older (8-10, >11) than younger age groups (<5, 5-7). lowering the cutoff score in the 2 younger groups improved sensitivity, with specificity remaining relatively low in all groups. using the {scq} in combination with the {ados} resulted in improved specificity. diagnostic discrimination was best using the {adi}-r and {ados} in combination. {conclusions}: those interested in using the {scq} should consider adjusting cutoff scores according to age and purpose, and using it in combination with another measure. sensitivity or specificity may be prioritized for research or screening depending on goals."
4794930,article,proceedings of the national academy of sciences,proceedings of the national academy of sciences of the united states of america,,,5,97,18,2000,aug,2009-06-10 08:52:41,,dynamical principles in biological processes: a model of charge migration in proteins and {dna},"the generalized master equations ({gmes}) that contain multiple time scales have been derived quantum mechanically. the {gme} method has then been applied to a model of charge migration in proteins that invokes the hole hopping between local amino acid sites driven by the torsional motions of the floppy backbones. this model is then applied to analyze the experimental results for sequence-dependent long-range hole transport in {dna} reported by meggers et al. [meggers, e., {michel-beyerle}, m. e., \& giese, b. (1998) j. am. chem. soc. 120, 12950–12955]. the model has also been applied to analyze the experimental results of femtosecond dynamics of {dna}-mediated electron transfer reported by zewail and co-workers [wan, c., fiebig, t., kelley, s. o., treadway, c. r., barton, j. k. \& zewail, a. h. (1999) proc. natl. acad. sci. {usa} 96, 6014–6019]. the initial events in the dynamics of protein folding have begun to attract attention. the {gme} obtained in this paper will be applicable to this problem."
1282427,misc,,,,,,,,-1,,2007-05-07 23:34:35,,{context-awareness} for the mobile environment,
86946,article,journal of computational neuroscience,,,,26,14,3,2003,,2005-02-02 00:42:40,"center for neural science and courant institute for mathematical science, new york university, 4 washington place, rm 809, ny 10003, usa. tim.lewis@nyu.edu",dynamics of spiking neurons connected by both inhibitory and electrical coupling.,"we study the dynamics of a pair of intrinsically oscillating leaky integrate-and-fire neurons (identical and noise-free) connected by combinations of electrical and inhibitory coupling. we use the theory of weakly coupled oscillators to examine how synchronization patterns are influenced by cellular properties (intrinsic frequency and the strength of spikes) and coupling parameters (speed of synapses and coupling strengths). we find that, when inhibitory synapses are fast and the electrotonic effect of the suprathreshold portion of the spike is large, increasing the strength of weak electrical coupling promotes synchrony. conversely, when inhibitory synapses are slow and the electrotonic effect of the suprathreshold portion of the spike is small, increasing the strength of weak electrical coupling promotes antisynchrony (see fig. 10). furthermore, our results indicate that, given a fixed total coupling strength, either electrical coupling alone or inhibition alone is better at enhancing neural synchrony than a combination of electrical and inhibitory coupling. we also show that these results extend to moderate coupling strengths."
1874924,techreport,,,,,,,MSR-TR-94-17,1994,nov,2007-11-06 18:39:53,,learning bayesian networks is {np}-hard,"algorithms for learning bayesian networks from data have two components: a scoring metric and a search procedure. the scoring metric computes a score reflecting the goodness-of-fit of the structure to the data. the search procedure tries to identify network structures with high scores. heckerman et al. (1994) introduced a bayesian metric, called the {bde} metric, that computes the relative posterior probability of a network structure given data. they show that the metric has a property ..."
8797432,article,,,,,,,,2011,feb,2011-02-10 06:51:06,,molecular gas and star formation in local {early-type} galaxies,
2553430,inproceedings,,proceedings of the twenty-first international conference on machine learning,icml,acm,,,,2004,,2008-03-19 01:44:24,"new york, ny, usa",online and batch learning of pseudo-metrics,"we describe and analyze an online algorithm for supervised learning of pseudo-metrics. the algorithm receives pairs of instances and predicts their similarity according to a pseudo-metric. the pseudo-metrics we use are quadratic forms parameterized by positive semi-definite matrices. the core of the algorithm is an update rule that is based on successive projections onto the positive semi-definite cone and onto half-space constraints imposed by the examples. we describe an efficient procedure for performing these projections, derive a worst case mistake bound on the similarity predictions, and discuss a dual version of the algorithm in which it is simple to incorporate kernel operators. the online algorithm also serves as a building block for deriving a large-margin batch algorithm. we demonstrate the merits of the proposed approach by conducting experiments on {mnist} dataset and on document filtering."
5935571,incollection,ecscw 2007,ecscw 2007,,springer london,19,,,2007,,2009-10-13 10:37:54,london,gifts from friends and strangers: a study of mobile music sharing {ecscw} 2007,"mobile technology has turned the traditionally collective activity of enjoying music into an often private one. new technologies such as wireless ad hoc networks have the potential to re-connect listeners who are now separated by headphones. we report on a field study of {push!music}, a novel mobile music sharing system. {push!music} allows both manual and automatic sharing of music between users through ad hoc wireless networking, and also provides a social awareness of other users nearby. the system was used by 13 subjects for three weeks. in post-study interviews, we identified four categories of results: social awareness, sharing music with friends, sharing music with strangers, and sharing automatically. based on this, we present implications for design that can be applied not only to mobile music sharing systems, but to mobile media sharing in general: allow division into active and passive use; enhance the awareness of who, where and when; support reciprocity; and finally, support identity and impression management."
2720318,article,nat neurosci,,,nature publishing group,7,11,5,2008,may,2008-05-02 11:17:05,,functional identification of sensory mechanisms required for developmental song learning,"a young male zebra finch (taeniopygia guttata) learns to sing by copying the vocalizations of an older tutor in a process that parallels human speech acquisition. brain pathways that control song production are well defined, but little is known about the sites and mechanisms of tutor song memorization. here we test the hypothesis that molecular signaling in a sensory brain area outside of the song system is required for developmental song learning. using controlled tutoring and a pharmacological inhibitor, we transiently suppressed the extracellular signal–regulated kinase signaling pathway in a portion of the auditory forebrain specifically during tutor song exposure. on maturation, treated birds produced poor copies of tutor song, whereas controls copied the tutor song effectively. thus the foundation of normal song learning, the formation of a sensory memory of tutor song, requires a conserved molecular pathway in a brain area that is distinct from the circuit for song motor control."
530779,electronic,,,,,,,,-1,,2006-03-04 03:39:49,,connotea: guide,
4779374,article,proceedings of the national academy of science,,,national academy of sciences,5,15,3,1929,mar,2009-06-08 17:33:01,,a relation between distance and radial velocity among {extra-galactic} nebulae,
853208,article,the journal of neuroscience,,,,2,26,38,2006,sep,2006-09-21 16:47:36,,as we may read,10.1523/jneurosci.3161-06.2006
5894729,article,philosophical transactions of the royal society b: biological sciences,,,,7,364,1533,2009,nov,2011-02-20 19:07:13,,culture and the evolution of human cooperation,"the scale of human cooperation is an evolutionary puzzle. all of the available evidence suggests that the societies of our pliocene ancestors were like those of other social primates, and this means that human psychology has changed in ways that support larger, more cooperative societies that characterize modern humans. in this paper, we argue that cultural adaptation is a key factor in these changes. over the last million years or so, people evolved the ability to learn from each other, creating the possibility of cumulative, cultural evolution. rapid cultural adaptation also leads to persistent differences between local social groups, and then competition between groups leads to the spread of behaviours that enhance their competitive ability. then, in such culturally evolved cooperative social environments, natural selection within groups favoured genes that gave rise to new, more pro-social motives. moral systems enforced by systems of sanctions and rewards increased the reproductive success of individuals who functioned well in such environments, and this in turn led to the evolution of other regarding motives like empathy and social emotions like shame."
3839609,article,applied mathematical modelling,,,,,,,2008,dec,2009-01-01 00:15:15,,computational aero-acoustic analysis of a passenger car with a rear spoiler,"this study proposes an effective numerical model based on the computational fluid dynamics ({cfd}) approach to obtain the flow structure around a passenger car with wing type rear spoiler. the topology of the test vehicle and grid system is constructed by a commercial package, {icem}/{cfd}. {fluent} is the {cfd} solver employed in this study. after numerical iterations are completed, the aerodynamic data and detailed complicated flow structure are visualized using commercial packages, field view and tecplot. the wind effect on the aerodynamic behavior of a passenger car with and without a rear spoiler and endplate is numerically investigated in the present study. it is found that the installation of a spoiler with an appropriate angle of attack can reduce the aerodynamic lift coefficient. furthermore, the installation of an endplate can reduce the noise behind the car. it is clear that the vertical stability of a passenger car and its noise elimination can be improved. finally, the aerodynamics and aero-acoustics of the most suitable design of spoiler is introduced and analyzed."
1048775,article,"journal of applied physiology (bethesda, md. : 1985)",,,,4,68,4,1990,apr,2007-01-18 10:32:27,"university laboratory of physiology, oxford, united kingdom.",a comparison of indirect methods for continuous estimation of arterial {pco2} in men.,
2236171,article,journal of the american medical informatics association,,,,11,13,3,2006,may,2008-01-15 19:45:52,"department of biomedical informatics, school of nursing, vanderbilt university, and department of veterans affairs, nashville, tn, usa. trent.rosenbloom@vanderbilt.edu",interface terminologies: facilitating direct entry of clinical data into electronic health record systems,"previous investigators have defined clinical interface terminology as a systematic collection of health care–related phrases (terms) that supports clinicians' entry of patient-related information into computer programs, such as clinical  ” note capture” and decision support tools. interface terminologies also can facilitate display of computer-stored patient information to clinician-users. interface terminologies  ” interface” between clinicians' own unfettered, colloquial conceptualizations of patient descriptors and the more structured, coded internal data elements used by specific health care application programs. the intended uses of a terminology determine its conceptual underpinnings, structure, and content. as a result, the desiderata for interface terminologies differ from desiderata for health care–related terminologies used for storage (e.g., {snomed}-{ct}®), information retrieval (e.g., {mesh}), and classification (e.g., {icd9}-{cm}®). necessary but not sufficient attributes for an interface terminology include adequate synonym coverage, presence of relevant assertional knowledge, and a balance between pre- and post-coordination. to place interface terminologies in context, this article reviews historical goals and challenges of clinical terminology development in general and then focuses on the unique features of interface terminologies."
469677,book,,,,{international reading association},,,,1994,jan,2006-01-18 20:10:04,,theoretical models and processes of reading,"{the reading reference of the decade, now in a special hardcover  limited edition!  over 80\% of the articles are new or revised.  the volume includes four sections: historical changes in reading, processes of reading and literacy, models of reading and literacy processes, and new paradigms.  introductions to each section provide a brief overview of the articles within, share insights into the rationale for selection of those articles, and provide ideas for guiding discussion and for further reading.  research exemplars throughout the process section will assist graduate students in understanding and visualizing the exploration of important research questions.  the models section includes new, revised, and classic models from some of the most prominent members of the reading profession.} {here are the texts of the experts, rich with questions for researchers and an important resource for professors and their students.  they tell us where the reading field has been, is now, and might be going.  the earlier editions of ""theoretical models and processes of reading"" are known to many of us and readers of this edition will be eager to see what is new and to ponder the criteria for selection of what  is old.  <p>the collection testifies to the existence of diverse approaches to reading, encourages productive discussion, and expands the knowledge base from which we all work.  the editors balance new ideas with classic articles that remind us not to reinvent the wheel through ignorance f ideas that have stood the test of time, and they present this comprehensive and diverse material in an open and nondirective format.  <p>i find it hard to set aside my usual role of integrating the best of what i read into a new synthesis, but, following the lead of the excellent  editors, i will resist the temptation to predict new directions.  it is for each reader to discover these for him-- or herself-- one of the rewards of being a reader. marie m. clay (from the foreword)}"
1104076,article,australian occupational therapy journal,,,,9,51,1,2004,mar,2007-02-13 03:48:40,,understanding play: the implications for play assessment,"this article reviews the current literature on play and play assessment in occupational therapy. the concept of play and play theories are examined and reasons are investigated for the low use of play assessment in paediatric occupational therapy practice. within contemporary occupational therapy practice, the concept of play is being readdressed and play behaviour is understood to be important in child development. available assessments of play in occupational therapy assess the child in a familiar environment to the child. since many paediatric occupational therapists work in clinical settings, it is concluded that a clinically viable assessment of observation of play behaviour is required within occupational therapy. parameters for such an assessment are proposed. [{abstract} {from} {author}]"
26208,article,library hi tech,,,emerald group publishing limited,,,4,-1,,2005-03-15 22:36:43,,digital content management: the search for a content management system,
5249696,article,ieee pervasive computing,,,ieee computer society,,5,3,2006,jul,2009-07-24 11:22:42,"los alamitos, ca, usa",{soda}: service oriented device architecture,"leveraging existing and emerging standards from both the embedded device and the {it} domains, within a service oriented device architecture ({soda}) can eliminate much of the ""accidental"" complexity and cost associated with integrating devices into highly distributed enterprise systems."
8906324,article,physical review b,,,american physical society,,83,7,2011,feb,2011-03-01 10:24:21,,adiabatic-connection-fluctuation-dissipation approach to long-range behavior of exchange-correlation energy at metal surfaces: a numerical study for jellium slabs,"a still open issue in many-body theory is the asymptotic behavior of the exchange-correlation energy and potential in the vacuum region of a metal surface. here we report a numerical study of the position-dependent exchange-correlation energy for jellium slabs, as obtained by combining the formally exact adiabatic-connection-fluctuation-dissipation theorem with either time-dependent density-functional theory or an inhomogeneous {singwi-tosi}-{land-sj\""{o}lander} approach. we find that the inclusion of correlation allows us to obtain well-converged semi-infinite-jellium results (independent of the slab thickness) that exhibit an image-like asymptotic behavior close to the classical image potential vim(z)=-e2/4z."
6414101,article,nature cell biology,,,nature publishing group,5,12,1,2009,dec,2009-12-20 19:53:57,,maintenance of a constitutive heterochromatin domain in vertebrates by a dicer-dependent mechanism,"the 16 kilobase (kb) heterochromatin domain between the chicken β-globin locus and the folate receptor gene is used here to study the roles of {rna}-dependent mechanisms and histone modifications in the maintenance of a constitutive heterochromatic structure. inhibition of histone deacetylase ({hdac}) activity is shown to both increase intergenic transcription and render the heterochromatin more accessible to {mspi} digestion. we show that short interfering {rna} ({sirna})-mediated downregulation of the enzyme dicer has similar effects: histone acetylation is increased, transcript levels rise and the compact chromatin structure becomes more accessible to restriction endonucleases. we also show that the chicken argonaute 2 homologue binds the 16 kb region in a dicer-dependent manner and is necessary for a condensed chromatin structure. heterochromatic domains of this kind, which are widely distributed in vertebrate genomes, thus seem to be maintained in their condensed form by highly conserved mechanisms."
4723462,article,cold spring harbor protocols,,,,,2009,6,2009,jun,2009-06-25 17:08:14,,native chromatin preparation and {illumina/solexa} library construction,"high-throughput whole-genome analysis has become a practical and important technique to understand nuclear processes, such as transcription, replication, and genome structure. though microarrays have been the preferred genome-scale analysis method for over a decade, new technologies, referred to as next-generation sequencing, offer distinct advantages over microarrays in both sensitivity and scale. several next-generation sequencing platforms are currently available, including the genome analyzer ({solexa/illumina}), 454 (roche), and {abi}-{solid} (applied biosystems). this protocol describes sample preparation for sequencing of chromatin-immunoprecipitated {dna} ({chip}-seq) to analyze histone modification patterns using native chromatin and the genome analyzer. one advantage of using native chromatin as compared to cross-linked chromatin is that it provides single-nucleosome-level resolution and avoids nonspecific modification signals from different nucleosomes carried over through protein-protein interactions. the protocol includes purification of human {cd4}+ t cells from lymphocytes and chromatin fragmentation using micrococcal nuclease ({mnase}) digestion, followed by chromatin immunoprecipitation ({chip}) and construction of a library for sequencing. 10.1101/pdb.prot5237"
7801587,article,ethics in science and environmental politics,,,,3,8,,2008,jun,2010-09-08 23:35:08,,hidden dangers of a citation culture,
975496,inproceedings,"autonomic computing, 2006. icac '06. ieee international conference on",,,,9,,,2006,,2006-12-05 17:45:39,,autonomic live adaptation of virtual computational environments in a {multi-domain} infrastructure,
575280,article,ieee transactions on information theory,,,,11,46,1,2000,jan,2006-04-04 08:54:03,,efficient decoding of {reed-solomon} codes beyond half the minimum distance,"a list decoding algorithm is presented for [n,k] {reed-solomon} ({rs}) codes over {gf}(q), which is capable of correcting more than [(n-k)/2] errors. based on a previous work of sudan (see j. compl., vol.13, p.180-93, 1997), an extended key equation ({eke}) is derived for {rs} codes, which reduces to the classical key equation when the number of errors is limited to [(n-k)/2]. generalizing massey's (1969) algorithm that finds the shortest recurrence that generates a given sequence, an algorithm is obtained for solving the {eke} in time complexity o(l·(n-k)<sup>2 </sup>), where l is a design parameter, typically a small constant, which s an upper bound on the size of the list of decoded codewords. (the case l=1 corresponds to classical decoding of up to [(n-k)/2] errors where the decoding ends with at most one codeword.) this improves on the time complexity o(n<sup>3</sup>) needed for solving the equations of sudan's algorithm by a naive gaussian elimination. the polynomials found by solving the {eke} are then used for reconstructing the codewords in time complexity o((llog<sup>2</sup>l)k(n+llogq)) using root-finders of degree-l univariate polynomials"
3883905,article,thin solid films,,,,7,516,2-4,2007,dec,2009-01-13 23:27:58,,transparent conducting oxide films for thin film silicon photovoltaics,
3958748,inproceedings,,fossgis 2008,,,,,,2008,apr,2009-01-27 12:43:25,,"open source sensor web technologien f\""{u}r die wasserwirtschaft",
8716749,article,"development (cambridge, england)",,,,12,136,12,2009,jun,2011-01-31 15:41:22,,selective plane illumination microscopy techniques in developmental biology.,"selective plane illumination microscopy ({spim}) and other fluorescence microscopy techniques in which a focused sheet of light serves to illuminate the sample have become increasingly popular in developmental studies. fluorescence light-sheet microscopy bridges the gap in image quality between fluorescence stereomicroscopy and high-resolution imaging of fixed tissue sections. in addition, high depth penetration, low bleaching and high acquisition speeds make light-sheet microscopy ideally suited for extended time-lapse experiments in live embryos. this review compares the benefits and challenges of light-sheet microscopy with established fluorescence microscopy techniques such as confocal microscopy and discusses the different implementations and applications of this easily adaptable technology."
6107963,inproceedings,,proceedings of the 2nd acm workshop on information credibility on the web,wicow,acm,7,,,2008,,2009-11-13 08:04:52,"new york, ny, usa",reasonable tag-based collaborative filtering for social tagging systems,"in this paper, we present a tag-based collaborative filtering recommendation method for use with recently popular online social tagging systems. combining the information provided by tagging systems with the effective recommendation abilities given by collaborative filtering, we provide a website recommendation system which provides relevant, credible recommendations that match the user's changing interests as well as the user's bookmarking profile. based upon user testing, our system provides a higher level of relevant recommendations over other commonly used search and recommendation methods. we describe this system as well as the relevant user testing results and its implication towards use in online social tagging systems."
636006,article,the american economic review,,,american economic association,4,96,2,2006,may,2006-05-23 15:30:07,,"colorism, complexion homogamy, and household wealth: some historical evidence",
6971846,article,journal of sex research,,,,4,39,3,2002,aug,2010-04-07 17:26:57,,how common is intersex? a response to anne {fausto-sterling}.,"anne {fausto-sterling} s suggestion that the prevalence of intersex might be as high as 1.7\% has attracted wide attention in both the scholarly press and the popular media. many reviewers are not aware that this figure includes conditions which most clinicians do not recognize as intersex, such as klinefelter syndrome, turner syndrome, and late-onset adrenal hyperplasia. if the term intersex is to retain any meaning, the term should be restricted to those conditions in which chromosomal sex is inconsistent with phenotypic sex, or in which the phenotype is not classifiable as either male or female. applying this more precise definition, the true prevalence of intersex is seen to be about 0.018\%, almost 100 times lower than {fausto-sterling} s estimate of 1.7\%."
1273212,article,science of computer programming,special issue on program transformation,,,28,52,1-3,2004,aug,2007-05-03 06:43:06,,monadification of functional programs,"the structure of monadic functional programs allows the integration of many different features by just changing the definition of the monad and not the rest of the program, which is a desirable feature from a software engineering and software maintenance point of view. we describe an algorithm for the automatic transformation of a group of functions into such a monadic form. we identify two correctness criteria and argue that the proposed transformation is at least correct in the sense that transformed programs yield the same results as the original programs modulo monad constructors. the translation of a set of functions into monadic form is in most cases only a first step toward an extension of a program by adding new features. the extended behavior can be realized by choosing an appropriate monad type and by inserting monadic actions into the functions that have been transformed into monadic form. we demonstrate an approach to the integration of monadic actions that is based on the idea of specifying context-dependent rewritings."
11870958,article,chaos: an interdisciplinary journal of nonlinear science,,,aip,,19,4,2009,,2013-01-09 11:23:23,,force network ensemble for the triangular lattice: a tale of tiles,view this record in web of science
13372125,article,j. of applied polymer science,,,,17,30,1,1985,jan,2014-09-23 19:14:14,,{pvc} calendering: a simplified prediction technique,"a simplified technique for prediction of pressure distribution, velocity profiles, torque, and power requirements for the calendering of power-law fluids is presented. the technique assumes isothermal conditions, is based on the lubrication approximation and gaskell's analysis, and uses melt flow index as the only temperature-dependent resin parameter for the prediction. the predictions are found to compare favorably with those made by vlachopoulos and hrymak for rigid {pvc}"
8989943,article,computers in human behavior,,,,6,27,5,2011,sep,2011-08-26 02:18:10,,"who uses facebook? an investigation into the relationship between the big five, shyness, narcissism, loneliness, and facebook usage","the unprecedented popularity of the social networking site facebook raises a number of important questions regarding the impact it has on sociality. however, as facebook is a very recent social phenomenon, there is a distinct lack of psychological theory relating to its use. while research has begun to identify the types of people who use facebook, this line of investigation has been limited to student populations. the current study aimed to investigate how personality influences usage or non-usage of facebook. the sample consisted of 1324 self-selected australian internet users (1158 facebook users and 166 facebook nonusers), between the ages of 18 and 44. participants were required to complete an online questionnaire package comprising the big five inventory ({bfi}), the narcissistic personality inventory – 29-item version ({npi}-29), the revised cheek and buss shyness scale ({rcbs}), and the social and emotional loneliness scale for adults – short version ({selsa}-s). facebook users also completed a facebook usage questionnaire. the results showed that facebook users tend to be more extraverted and narcissistic, but less conscientious and socially lonely, than nonusers. furthermore, frequency of facebook use and preferences for specific features were also shown to vary as a result of certain characteristics, such as neuroticism, loneliness, shyness and narcissism. it is hoped that research in this area continues, and leads to the development of theory regarding the implications and gratifications of facebook use. \^{a}º we investigated how personality influences usage or non-usage of facebook. \^{a}º facebook users were more extraverted and narcissistic than nonusers. \^{a}º facebook nonusers were more conscientious and socially lonely than users. \^{a}º facebook usage habits varied as a result of certain personality traits."
9351166,article,magn. reson. med.,,,"wiley subscription services, inc., a wiley company",24,65,6,2011,jun,2011-05-31 00:37:42,,diffusion tensor imaging and beyond,
248978,article,statistics in medicine,,,,7,14,,1995,,2005-07-07 18:05:25,,probabilistic linkage of large public health data files,
10562615,article,journal of the royal statistical society: series b (statistical methodology),,,blackwell publishing ltd,56,74,3,2012,,2012-04-13 18:52:37,,catching up faster by switching sooner: a predictive approach to adaptive estimation with an application to the {aic}–{bic} dilemma,"summary.  prediction and estimation based on bayesian model selection and model averaging, and derived methods such as the bayesian information criterion {bic}, do not always converge at the fastest possible rate. we identify the catch-up phenomenon as a novel explanation for the slow convergence of bayesian methods, which inspires a modification of the bayesian predictive distribution, called the switch distribution. when used as an adaptive estimator, the switch distribution does achieve optimal cumulative risk convergence rates in non-parametric density estimation and gaussian regression problems. we show that the minimax cumulative risk is obtained under very weak conditions and without knowledge of the underlying degree of smoothness. unlike other adaptive model selection procedures such as the akaike information criterion {aic} and leave-one-out cross-validation, {bic} and bayes factor model selection are typically statistically consistent. we show that this property is retained by the switch distribution, which thus solves the {aic}–{bic} dilemma for cumulative risk. the switch distribution has an efficient implementation. we compare its performance with {aic}, {bic} and bayesian model selection and averaging on a regression problem with simulated data."
8567151,article,journal of college student personnel,,,,-192,23,3,1982,may,2011-01-11 19:30:24,,predictors of academic success with high risk college students.,"considered the effectiveness of the {myers-brigg} type indicator, the effective study test results, the scholastic aptitude test, and high school class rank to predict success among high-risk college freshmen (n=658). found the predictability of success reached the same level as that normally achieved for nonrisk students. ({author/rc})"
3813119,incollection,mobile data management,mobile data management,lecture notes in computer science,springer berlin / heidelberg,14,2574,,2003,dec,2008-12-20 08:58:11,"berlin, heidelberg",experiences in using {cc}/{pp} in {context-aware} systems mobile data management,"future pervasive systems will be based on ubiquitous, often mobile, interconnected devices supporting mobile users in their computing tasks. these systems need to be context-aware in order to cope with highly dynamic environments. in this paper, we present a context model and a context management system able to support a pervasive system infrastructure. this context model is based on the {cc}/{pp} standard proposed to support content negotiation between web browsers and servers. we have defined a set of {cc}/{pp} components and attributes that allow to express a variety of context information types and relationships between context descriptions. the paper discusses pros and cons of using {cc}/{pp} as a basis for a context model and a context management system."
12306559,article,genome biology,genome biology,,biomed central,17,14,4,2013,apr,2013-05-02 16:04:01,,"interactions between immunity, proliferation and molecular subtype in breast cancer prognosis","{background}: gene expression signatures indicative of tumor proliferative capacity and tumor-immune cell interactions have emerged as principal biology-driven predictors of breast cancer outcomes. how these signatures relate to one another in biological and prognostic contexts remains to be clarified. {results}: to investigate the relationship between proliferation and immune gene signatures, we analyzed an integrated dataset of 1,954 clinically-annotated breast tumor expression profiles randomized into training and test sets to allow two-way discovery and validation of gene-survival associations. hierarchical clustering revealed a large cluster of distant metastasis-free survival-associated genes with known immunological functions that further partitioned into three distinct immune metagenes likely reflecting: b-cells and/or plasma cells;, t-cells and natural killer cells,;and monocytes and dendritic cells. a proliferation metagene allowed stratification of cases into proliferation tertiles. the prognostic strength of these metagenes was largely restricted to tumors within the highest proliferation tertile, though intrinsic subtype-specific differences were observed in the intermediate and low proliferation tertiles. in highly proliferative tumors, high-tertile immune metagene expression equated with reduced risk of metastasis while tumors with low-tertile expression of any one of the three immune metagenes were associated with poor outcome despite higher expression of the other two metagenes. {conclusions}: these findings suggest that a productive interplay among multiple immune cell types at the tumor site promotes long-term anti-metastatic immunity in a proliferation-dependent manner. the emergence of a subset of effective immune responders among highly proliferative tumors has novel prognostic ramifications."
4051233,book,,,,vintage,,,,1998,jan,2009-02-14 14:25:42,,culture and imperialism,
1044912,article,radiology,,,,8,239,3,2006,jun,2007-01-16 23:49:52,,"transition zone prostate cancers: features, detection, localization, and staging at endorectal {mr} imaging","purpose: to retrospectively evaluate the accuracy of endorectal magnetic resonance (mr) imaging in the detection and local staging of transition zone prostate cancers, with pathologic analysis serving as the reference standard, and to assess mr imaging features of these cancers.  materials and methods: the institutional review board approved this hipaa-compliant retrospective study and waived the informed consent requirement. an institutional database of 986 patients who underwent mr imaging before radical prostatectomy yielded 148 consecutive patients with at least one transition zone cancer at step-section pathologic analysis. an additional 46 patients without transition zone cancer were randomly selected as a control group. two readers independently reviewed mr studies to identify patients with transition zone cancers and determine the location and local extent of these cancers. imaging features that helped in the identification of transition zone cancers were recorded. descriptive and {kappa} statistics, as well as receiver operating characteristic and multivariate logistic regression analyses, were used.  results: for identification of patients with transition zone cancers, sensitivity and specificity were 75\% and 87\%, respectively, for reader 1 and 80\% and 78\%, respectively, for reader 2. interreader agreement was fair. for detection of the location of transition zone cancer, the area under the receiver operating characteristic curve was 0.75 for reader 1 and 0.73 for reader 2. interreader agreement was fair. the readers' accuracy in detecting transition zone cancer foci increased significantly (p = .001) as tumor volume increased. in the detection of extraprostatic extension of transition zone cancers, sensitivity and specificity were 56\% and 94\%, respectively, for reader 1 and 28\% and 93\%, respectively, for reader 2. homogeneous low t2 signal intensity (p = .001 for reader 1, p < .001 for reader 2) and lenticular shape (p = .017 for reader 1) were significantly associated with the presence of transition zone cancer.  conclusion: mr imaging can be used to detect, localize, and stage transition zone prostate cancers.  (c) rsna, 2006 10.1148/radiol.2392050949"
6644188,article,journal of translational medicine,,,,,8,1,2010,feb,2010-10-26 17:55:20,,translational medicine--doing it backwards.,"in recent years the concept of ""translational medicine"" has been advanced in an attempt to catalyze the medical applications of basic biomedical research. however, there has been little discussion about the readiness of scientists themselves to respond to what we believe is a required new approach to scientific discovery if this new concept is to bear fruit. the present paradigm of hypothesis-driven research poorly suits the needs of biomedical research unless efforts are spent in identifying clinically relevant hypotheses. the dominant funding system favors hypotheses born from model systems and not humans, bypassing the baconian principle of relevant observations and experimentation before hypotheses. here, we argue that that this attitude has born two unfortunate results: lack of sufficient rigor in selecting hypotheses relevant to human disease and limitations of most clinical studies to certain outcome parameters rather than expanding knowledge of human pathophysiology; an illogical approach to translational medicine. if we wish to remain true to our responsibility and duty of performing research relevant to human disease, we must begin to think about fundamental new {approaches.nih} is the nation's medical research agency--making important medical discoveries that improve health and save lives. {nih} is the steward of medical and behavioral research for the nation. its mission is science in pursuit of fundamental knowledge about the nature and behavior of living systems and the application of that knowledge to extend healthy life and reduce the burdens of illness and disability 1."
71803,article,bioinformatics,,,,8,17,9,2001,sep,2005-01-03 04:24:13,"human genome center, institute of medical science, university of tokyo, 4-6-1 shirokanedai, minato-ku, tokyo 108-8639, japan. fukuda-cbrc@aist.go.jp",knowledge representation of signal transduction pathways,"motivations: signal transduction is the common term used to define a diverse topic that encompasses a large body of knowledge about the biochemical mechanisms. since most of the knowledge of signal transduction resides in scientific articles and is represented by texts in natural language or by diagrams, there is the need of a knowledge representation model for signal transduction pathways that can be as readily processed by a computer as it is easily understood by {humans.results}: a signal transduction pathway representation model is presented. it is based on a compound graph structure and is designed to handle the diversity and hierarchical structure of pathways. a prototype knowledge base was implemented on a deductive database and a number of biological queries are demonstrated on {it.contact}: fukuda-cbrc@aist.go.jp; ichiro@ims.u-tokyo.ac.jp"
248346,article,journal of environmental management,,,,2,72,1-2,2004,aug,2005-07-07 10:06:13,,modelling land use change and environmental impact,"land use change models are tools for understanding and explaining the causes and consequences of land use dynamics. recently, new models, combining knowledge and tools from biophysical and socio-economic sciences, have become available. this has resulted in spatially explicit models focussed on patterns of change as well as agent-based models focused on the underlying decision processes. these developments improve the use of land use change models in environmental impact studies. this special issue documents these developments: (i) analysing the system properties in a biophysical and socio-economic context at multiple scales; (ii) integrating spatially explicit land use change models in integrated assessment models; (iii) visualising and quantifying the potential effects of land use change in trade-off curves, to support land users and policy makers in their decisions; and (iv) modelling of the actual decision making process with agent-based modelling. a new promising future development is the incorporation of dynamic feedbacks between changing land use and changing environmental conditions and vice versa. unfortunately such dynamic feedbacks between the socio-economic and biophysical model components are still not or only partially operational in current models and are therefore the most important challenge for land use and environmental modellers."
4518488,article,j. am. chem. soc.,,,american chemical society,9,109,12,1987,jun,2009-05-14 16:22:30,,"spontaneously organized molecular assemblies. 4. structural characterization of n-alkyl thiol monolayers on gold by optical ellipsometry, infrared spectroscopy, and electrochemistry",
2859748,article,journal of computer-mediated communication,,,blackwell publishing inc,18,13,3,2008,,2008-06-03 19:52:41,"department of communication;  departments of communication and telecommunication, information studies \& mediamichigan state university",too much of a good thing? the relationship between number of friends and interpersonal impressions on facebook,"a central feature of the online social networking system, facebook, is the connection to and links among friends. the sum of the number of one's friends is a feature displayed on users' profiles as a vestige of the friend connections a user has accrued. in contrast to offline social networks, individuals in online network systems frequently accrue friends numbering several hundred. the uncertain meaning of friend status in these systems raises questions about whether and how sociometric popularity conveys attractiveness in non-traditional, non-linear ways. an experiment examined the relationship between the number of friends a facebook profile featured and observers' ratings of attractiveness and extraversion. a curvilinear effect of sociometric popularity and social attractiveness emerged, as did a quartic relationship between friend count and perceived extraversion. these results suggest that an overabundance of friend connections raises doubts about facebook users' popularity and desirability. too much of a good thing? the relationship between number of friends and interpersonal impressions on facebook a central feature of the online social networking system, facebook, is the connection to and links among friends. the sum of the number of one's friends is a feature displayed on users' profiles as a vestige of the friend connections a user has accrued. in contrast to offline social networks, individuals in online network systems frequently accrue friends numbering several hundred. the uncertain meaning of friend status in these systems raises questions about whether and how sociometric popularity conveys attractiveness in non-traditional, non-linear ways. an experiment examined the relationship between the number of friends a facebook profile featured and observers' ratings of attractiveness and extraversion. a curvilinear effect of sociometric popularity and social attractiveness emerged, as did a quartic relationship between friend count and perceived extraversion. these results suggest that an overabundance of friend connections raises doubts about facebook users' popularity and desirability. zu viel des guten? zur beziehung zwischen der anzahl der freunde und interpersonalen eindr\""{u}cken bei facebook eine zentrale eigenschaft des sozialen {online-netzwerks} facebook ist die verbindung von freunden. die gesamtanzahl der freunde eines nutzers wird als merkmal im benutzerprofil angezeigt und dient als eine statistik der freundeverbindungen, die ein nutzer gesammelt hat. im gegensatz zu {offline-netzwerken}, haben personen in {online-netzwerken} oft mehrere hundert freunde. die unklare bedeutung des freundestatus in diesem system wirft die frage auf, ob und wie soziometrische popularit\""{a}t die attraktivit\""{a}t auf nicht-traditionelle, nichtlineare weise ausdr\""{u}ckt. in einem experiment wurde die beziehung zwischen der anzahl der freunde im {facebook-profil} und der einsch\""{a}tzung von attraktivit\""{a}t und extraversion durch den beobachter untersucht. es zeigten sich ein kurvilinearer effekt von soziometrischer popularit\""{a}t und sozialer attraktivit\""{a}t, sowie eine biquatratische beziehung zwischen der anzahl der freunde und wahrgenommener extraversion. diese ergebnisse deuten an, dass eine \""{u}berm\""{a}{\ss}ig hohe zahl an freunden zweifel an der popularit\""{a}t und attraktivit\""{a}t des {facebook-nutzers} aufkommen l\""{a}sst. ¿una cosa demasiada buena? la relaci\'{o}n entre el n\'{u}mero de amigos y las impresiones interpersonales en facebook una caracter\'{\i}stica central del sistema de red social online, facebook, es la conexi\'{o}n entre los amigos. la suma del n\'{u}mero de amigos de una persona es una caracter\'{\i}stica manifestada en los perfiles de los usuarios como un vestigio de las conexiones de amistad que un usuario ha acumulado. en contraste con las redes sociales fuera de l\'{\i}nea, los individuos en los sistemas de redes online acumulan frecuentemente amigos hasta llegar a varios cientos. el significado incierto del estatus del amigo en estos sistemas genera preguntas si, y c\'{o}mo, la popularidad sociom\'{e}trica comunica atracci\'{o}n en formas no tradicionales y no lineares. un experimento examin\'{o} la relaci\'{o}n entre el n\'{u}mero de amigos que aparecen en el perfil de facebook y la clasificaci\'{o}n del atractivo y la extraversi\'{o}n por parte de los observadores. un efecto curvil\'{\i}neo de popularidad sociom\'{e}trica y atractivo social emergi\'{o}, as\'{\i} como tambi\'{e}n una relaci\'{o}n entre el conteo de amigos y la extroversi\'{o}n percibida. los resultados sugieren que una sobreabundancia de conexiones de amigos genera dudas sobre la popularidad y el atractivo de los usuarios de facebook."
1557084,book,,,,"john wiley \& sons, inc.",,,,2002,,2007-08-13 08:30:12,"new york, ny, usa",towards the semantic web: ontology-driven knowledge management,
1282232,inproceedings,,acm symposium on parallel algorithms and architectures,,,9,,,1997,,2007-05-07 19:44:33,,accessing nearby copies of replicated objects in a distributed environment,"consider a set of shared objects in a distributed network, where several copies of each object may exist at any given time. to ensure both fast access to the objects as well as efficient utilization of network resources, it is desirable that each access request be satisfied by a copy ""close"" to the requesting node. unfortunately, it is not clear how to efficiently achieve this goal in a dynamic, distributed environment in which large numbers of objects are continuously being created,..."
3936100,incollection,conceptual structures: knowledge architectures for smart applications,conceptual structures: knowledge architectures for smart applications,lecture notes in computer science,springer berlin / heidelberg,12,4604,,2007,,2009-02-09 17:39:45,"berlin, heidelberg",analysis of the publication sharing behaviour in {bibsonomy},"{bibsonomy} is a web-based social resource sharing system which allows users to organise and share bookmarks and publications in a collaborative manner. in this paper we present the system, followed by a description of the insights in the structure of its bibliographic data that we gained by applying techniques we developed in the area of formal concept analysis."
6860614,article,international journal of antimicrobial agents,,,,10,35,4,2010,apr,2011-01-15 02:32:42,,antibiotic resistance of bacterial biofilms,"a biofilm is a structured consortium of bacteria embedded in a self-produced polymer matrix consisting of polysaccharide, protein and {dna}. bacterial biofilms cause chronic infections because they show increased tolerance to antibiotics and disinfectant chemicals as well as resisting phagocytosis and other components of the body's defence system. the persistence of, for example, staphylococcal infections related to foreign bodies is due to biofilm formation. likewise, chronic pseudomonas aeruginosa lung infection in cystic fibrosis patients is caused by biofilm-growing mucoid strains. characteristically, gradients of nutrients and oxygen exist from the top to the bottom of biofilms and these gradients are associated with decreased bacterial metabolic activity and increased doubling times of the bacterial cells; it is these more or less dormant cells that are responsible for some of the tolerance to antibiotics. biofilm growth is associated with an increased level of mutations as well as with quorum-sensing-regulated mechanisms. conventional resistance mechanisms such as chromosomal β-lactamase, upregulated efflux pumps and mutations in antibiotic target molecules in bacteria also contribute to the survival of biofilms. biofilms can be prevented by early aggressive antibiotic prophylaxis or therapy and they can be treated by chronic suppressive therapy. a promising strategy may be the use of enzymes that can dissolve the biofilm matrix (e.g. {dnase} and alginate lyase) as well as quorum-sensing inhibitors that increase biofilm susceptibility to antibiotics."
403927,article,nature reviews. cancer,,,,11,2,5,2002,may,2005-11-22 04:13:00,,"gli and hedgehog in cancer: tumours, embryos and stem cells.",
882507,article,bmj,,,british medical journal publishing group,,313,7049,1996,jul,2006-10-03 10:27:40,,statistics notes: measurement error proportional to the mean,"reference 1.↵ bland {jm}, altman {dg} .measurement error and correlation coefficients. {bmj} 1996;313: 41–2. 2.↵ bland {jm}, altman {dg} .transforming data. {bmj} 1996;312: 770. 3.↵ bland {jm}, altman {dg} .logarithms. {bmj} 1996;312: 700."
14095349,article,nature,,,nature research,4,535,7612,2016,jul,2016-07-26 04:46:04,,unexpected role of interferon-γ in regulating neuronal connectivity and social behaviour,
787919,article,new phytologist,,,blackwell publishing ltd,11,171,4,2006,sep,2007-03-06 16:01:57,,molecular evidence for multiple polyploidization and lineage recombination in the chrysanthemum indicum polyploid complex (asteraceae),"* • the chrysanthemum indicum polyploid complex comprises morphologically differentiated diploids, tetraploids and hybrids between c. indicum and c. lavandulifolium. the relationships between species and cytotypes within this complex remain poorly understood. * • random amplified polymorphic {dnas} ({rapds}), intersimple sequence repeats ({issrs}) and chloroplast {ssr} markers were used to elucidate the genetic diversity and relationships of the c. indicum polyploid complex. * • molecular analysis of three diploid and nine tetraploid populations provided strong evidence for recurrent origins and lineage recombination in the c. indicum polyploid complex. the high similarity in molecular marker profiles and {cpdna} haplotypes between the diploids and tetraploids distributed in the {shen-nong}-jia mountain area of china suggested an autopolyploid origin of the tetraploids, while the tetraploids from other populations may have originated via allopolyploidization. lineage recombination was revealed by the extensive sharing of chloroplast haplotypes and genetic markers among the tetraploid populations with different origins. * • multiple differentiation and hybridization/polyploidization cycles have led to an evolutionary reticulation in the c. indicum polyploid complex, and resulted in the difficulties in systematic classification."
10457316,article,nature,,,nature research,6,484,7392,2012,mar,2012-03-29 12:58:29,,choice-specific sequences in parietal cortex during a virtual-navigation decision task,"the posterior parietal cortex ({ppc}) has an important role in many cognitive behaviours; however, the neural circuit dynamics underlying {ppc} function are not well understood. here we optically imaged the spatial and temporal activity patterns of neuronal populations in mice performing a {ppc}-dependent task that combined a perceptual decision and memory-guided navigation in a virtual environment. individual neurons had transient activation staggered relative to one another in time, forming a sequence of neuronal activation spanning the entire length of a task trial. distinct sequences of neurons were triggered on trials with opposite behavioural choices and defined divergent, choice-specific trajectories through a state space of neuronal population activity. cells participating in the different sequences and at distinct time points in the task were anatomically intermixed over microcircuit length scales (<100 micrometres). during working memory decision tasks, the {ppc} may therefore perform computations through sequence-based circuit dynamics, rather than long-lived stable states, implemented using anatomically intermingled microcircuits."
669566,book,,,,verso,,,,2006,mar,2006-05-25 10:57:25,,planet of slums,"{<b>celebrated urban theorist lifts the lid on the effects of a global explosion of disenfranchised slum-dwellers.</b><br><br>according to the united nations, more than one billion people now live in the slums of the cities of the south. in this brilliant and ambitious book, mike davis explores the future of a radically unequal and explosively unstable urban world. <br><br>from the sprawling <i>barricadas</i> of lima to the garbage hills of manila, urbanization has been disconnected from industrialization, even economic growth. davis portrays a vast humanity warehoused in shantytowns and exiled from the formal world economy. he argues that the rise of this informal urban proletariat is a wholly original development unforeseen by either classical marxism or neoliberal theory.<br><br>are the great slums, as a terrified victorian middle class once imagined, volcanoes waiting to erupt? davis provides the first global overview of the diverse religious, ethnic, and political movements competing for the souls of the new urban poor. he surveys hindu fundamentalism in bombay, the islamist resistance in casablanca and cairo, street gangs in cape town and san salvador, pentecostalism in kinshasa and rio de janeiro, and revolutionary populism in caracas and la paz.<i>planet of slums</i> ends with a provocative meditation on the ""war on terrorism"" as an incipient world war between the american empire and the slum poor.}"
4371452,article,,,,,,,,2009,apr,2009-04-21 09:58:42,,opinion dynamics and communication networks,"this paper examines the interplay of opinion exchange dynamics andcommunication network formation. an opinion formation procedure is introducedwhich is based on an abstract representation of opinions as \$k\$--dimensionalbit--strings. individuals interact if the difference in the opinion strings isbelow a defined similarity threshold \${d\_i}\$. depending on \${d\_i}\$, differentbehaviour of the population is observed: low values result in a state of highlyfragmented opinions and higher values yield consensus. the first contributionof this research is to identify the values of parameters \${d\_i}\$ and \$k\$, suchthat the transition between fragmented opinions and homogeneity takes {place.then}, we look at this transition from two perspectives: first by studying thegroup size distribution and second by analysing the communication network thatis formed by the interactions that take place during the simulation. theemerging networks are classified by statistical means and we find thatnon--trivial social structures emerge from simple rules for individualcommunication. generating networks allows to compare model outcomes withreal--world communication patterns."
10258302,incollection,,,,,,,,2011,dec,2012-01-23 23:33:11,,los conflictos fronterizos en iberoam\'{e}rica y la integraci\'{o}n en materia de seguridad y defensa (iii),
1693316,incollection,"information context: nature, impact, and role",,,,15,,,2005,,2007-09-25 16:53:54,,annotations as context for searching documents,"this paper discusses how to exploit annotations as a useful context in order to search and retrieve relevant documents for a user query. this paper provides a formal framework which can be useful in facing this problem and shows how this framework can be employed, by using techniques which come from the hypertext information retrieval and data fusion fields."
1987535,article,n engl j med,new england journal of medicine,,massachusetts medical society,5,357,21,2007,nov,2007-11-26 17:08:25,,statistics in medicine — reporting of subgroup analyses in clinical trials,{10.1056/nejmsr077003}
4926680,article,statistical science,,,,25,23,4,2009,jun,2009-06-22 22:40:57,,the statistical analysis of {fmri} data,
739799,proceedings,"pervasive computing and communications, 2006. percom 2006. fourth annual ieee international conference on",,,,5,,,2006,,2006-07-05 07:18:13,,analysis of appropriate timing for information notification based on indoor user's location transition,"the purpose of this study was to explore the convenient timing for information notification of the users in their daily life. using the location and the time interval since a location change, we have examined the features of the user's response to information notification. for a period of three weeks, four subjects carried mobile terminals which randomly notified them about daily information. the obtained results showed that the responsiveness is high just before and after change of subject\&\#146;s location. the responsiveness decreased with the increase of the time interval since a location change. the change of the responsiveness differed with the subject location and its change through time was symmetric for the time intervals before and after the location change. an effective control of the notification timing could be obtained using the information about the user's location and the time interval since the change of user's location."
4935353,inproceedings,,persuasive,,acm,7,,,2009,,2009-06-23 18:40:04,"new york, ny, usa",understanding user cognitions to guide the tailoring of persuasive technology-based physical activity interventions,"the growing number of people with an inactive lifestyle emphasizes the need for highly persuasive physical activity interventions. modern technological developments bring great promise for the realization of such large-scale persuasive behavior change interventions because they allow for user tailored interaction. for the effective tailoring of technology-based interventions, a profound understanding of the main variables underlying physical activity behavior is required. in this paper, we focus on three cognitive variables that have shown to be crucial for the adoption and maintenance of health behaviors: behavioral regulation, types of motives, and self-efficacy. in particular, we explore the relationship of these cognitive variables with actual levels of daily-life physical activity. our study differs from related studies in two important ways. first, we consider the entire range of physical activities performed throughout the day while many studies focused on sports and or dedicated exercise. second, we employ a wearable device for the objective measurement of daily physical activity levels rather than rely on self-report measures. our results show that active individuals feel higher levels of self-determined behavioral regulation, experience stronger motives to be active (in particular for health and well-being related motives), and have higher levels of self-efficacy for daily-life physical activity than inactive individuals. we argue that tailored technology-based activity interventions should accommodate these cognitive variables and for inactive individuals, aim to gradually induce and internalize the cognitions already experienced by active individuals."
1277949,article,ieee softw.,,,ieee computer society press,8,18,4,2001,jul,2007-05-04 21:31:37,"los alamitos, ca, usa",using simplicity to control complexity,
11877972,article,"methods in molecular biology (clifton, n.j.)",homology modeling,methods in molecular biology,humana press,21,857,,2012,,2013-01-10 11:48:34,,effective techniques for protein structure mining.,"retrieval and characterization of protein structure relationships are instrumental in a wide range of tasks in structural biology. the classification of protein structures ({cops}) is a web service that provides efficient access to structure and sequence similarities for all currently available protein structures. here, we focus on the application of {cops} to the problem of template selection in homology modeling."
4186576,article,,,,,,,,2008,,2009-03-17 14:46:41,,,
3173868,article,j. am. chem. soc.,,,,1,124,31,2002,aug,2008-08-29 19:59:49,"department of chemistry and the skaggs institute for chemical biology, the scripps research institute, 10550 north torrey pines road, la jolla, california 92037, and howard hughes medical institute, department of molecular and cell biology, university of california, berkeley, california 94720-1406",addition of {p-azido}-l-phenylalanine to the genetic code of escherichia coli,"abstract: we report the selection of a new orthogonal aminoacyl {trna} {synthetase/trna} pair for the in vivo incorporation of a photocrosslinker, {p-azido-l}-phenylalanine, into proteins in response to the amber codon, {tag}. the amino acid is incorporated in good yield with high fidelity and can be used to crosslink interacting proteins."
1884784,article,neurosci res,,,,10,36,1,2000,jan,2007-11-08 13:27:48,"institut f\""{u}r neuroinformatik, ethz/unizh, z\""{u}rich, switzerland. ruedi@ini.phys.ethz.ch","when pyramidal neurons lock, when they respond chaotically, and when they like to synchronize.","we give an overview on the locking properties of perturbed regularly firing pyramidal neurons, as a function of perturbation strength, self-spiking frequency and perturbation frequency. for inhibitory perturbations, instead of locking chaotic response emerges for a whole range of parameters. this suggests that global synchronization on the set of inhibitory connections may easily be achieved."
1745239,book,,,,princeton univ. press,,,,1998,aug,2007-10-09 11:32:44,,linear programming and extensions,"{<p>in real-world problems related to finance, business, and management, mathematicians and economists frequently encounter optimization problems. in this classic book, george dantzig looks at a wealth of examples and develops linear programming methods for their solutions. he begins by introducing the basic theory of linear inequalities and describes the powerful simplex method used to solve them. treatments of the price concept, the transportation problem, and matrix methods are also given, and key mathematical concepts such as the properties of convex sets and linear vector spaces are covered. </p><p>george dantzig is properly acclaimed as the ""father of linear programming."" linear programming is a mathematical technique used to optimize a situation. it can be used to minimize traffic congestion or to maximize the scheduling of airline flights. he formulated its basic theoretical model and discovered its underlying computational algorithm, the ""simplex method,"" in a pathbreaking memorandum published by the united states air force in early 1948. <i>linear programming and extensions</i> provides an extraordinary account of the subsequent development of his subject, including research in mathematical theory, computation, economic analysis, and applications to industrial problems.</p><p> dantzig first achieved success as a statistics graduate student at the university of california, berkeley. one day he arrived for a class after it had begun, and assumed the two problems on the board were assigned for homework. when he handed in the solutions, he apologized to his professor, jerzy neyman, for their being late but explained that he had found the problems harder than usual. about six weeks later, neyman excitedly told dantzig, ""i've just written an introduction to one of your papers. read it so i can send it out right away for publication."" dantzig had no idea what he was talking about. he later learned that the ""homework"" problems had in fact been two famous unsolved problems in statistics.</p>}"
1220295,article,mamm genome,,,,9,16,9,2005,sep,2007-04-11 12:08:14,"laboratory of molecular biology of domestic animals, and cellular and molecular evolution, kunming institute of zoology, kunming, 650223, china.",evolutionary implications of multiple {sine} insertions in an intronic region from diverse mammals.,"an analysis of the nuclear beta-fibrinogen intron 7 locus from 30 taxa representing 12 placental orders of mammals reveals the enriched occurrences of short interspersed element ({sine}) insertion events. mammalian-wide interspersed repeats ({mirs}) are present at orthologous sites of all examined species except those in the order rodentia. the higher substitution rate in mouse and a rare {mir} deletion from rat account for the absence of {mir} in the rodents. a minimum of five lineage-specific {sine} sequences are also found to have independently inserted into this intron in carnivora, artiodactyla and lagomorpha. in the case of carnivora, the unique amplification pattern of order-specific {can} {sine} provides important evidence for the ""pan-carnivore"" hypothesis of this repeat element and reveals that the {can} {sine} family may still be active today. particularly interesting is the finding that all identified lineage-specific {sine} elements show a strong tendency to insert within or in very close proximity to the preexisting {mirs} for their efficient integrations, suggesting that the {mir} element is a hot spot for successive insertions of other {sines}. the unexpected {mir} excision as a result of a random deletion in the rat intron locus and the non-random site targeting detected by this study indicate that {sines} actually have a greater insertional flexibility and regional specificity than had previously been recognized. implications for {sine} sequence evolution upon and following integration, as well as the fascinating interactions between retroposons and the host genomes are discussed."
1295519,proceedings,"integration of knowledge intensive multi-agent systems, 2003. international conference on",,,,5,,,2003,,2007-05-14 17:48:14,,dynamic composition of process federations for context aware perception of human activity,"we describe a distributed software model for context-aware perception of human activity. the basic building blocks in this model are perceptual modules, composed of a data transformation component and a control component. modules are assembled into perceptual processes controlled by a reflexive process controller. process controllers regulate computation, and provide a reflexive description of their internal state and capabilities. explicit models of context are used to assemble federations of processes for observing and predicting activity. as context changes, the federation is restructured. restructuring the federation enables the system to adapt to a range of environmental conditions and to provide services that are appropriate over a range of activities."
6791268,article,american journal of human genetics,,,,13,73,2,2003,aug,2010-03-10 11:31:57,,"nuclear and mitochondrial {dna} analysis of a 2,000-year-old necropolis in the egyin gol valley of mongolia.","{dna} was extracted from the skeletal remains of 62 specimens excavated from the egyin gol necropolis, in northern mongolia. this burial site is linked to the xiongnu period and was used from the 3rd century b.c. to the 2nd century a.d. three types of genetic markers were used to determine the genetic relationships between individuals buried in the egyin gol necropolis. results from analyses of autosomal and y chromosome short tandem repeats, as well as mitochondrial {dna}, showed close relationships between several specimens and provided additional background information on the social organization within the necropolis as well as the funeral practices of the xiongnu people. to the best of our knowledge, this is the first study using biparental, paternal, and maternal genetic systems to reconstruct partial genealogies in a protohistoric necropolis."
3175151,article,qualitative social work,,,,22,3,2,2004,jun,2008-09-25 22:12:59,,doing narrative research,"this article seeks to contribute to discussions about how narrative analysis         might be undertaken. i do this by exploring one method of narrative approach         to analyse personal stories. before considering some of the issues associated         with narrative research, i comment on the rise of the \^{a}narrative         moment\^{a}. i then provide ways to conceptualize narrative research.         in the final part of the discussion, i discuss ways to conduct narrative         research. in so doing, i provide concrete details about how personal stories         might be analysed line by line."
1853105,article,bmc molecular biology,,,,,8,,2007,oct,2008-01-08 18:35:11,,translation initiation region sequence preferences in escherichia coli.,"{background}: the {mrna} translation initiation region ({tir}) comprises the initiator codon, {shine-dalgarno} ({sd}) sequence and translational enhancers. probably the most abundant class of enhancers contains {a/u}-rich sequences. we have tested the influence of {sd} sequence length and the presence of enhancers on the efficiency of translation initiation. {results}: we found that during bacterial growth at 37 degrees c, a six-nucleotide {sd} ({aggagg}) is more efficient than shorter or longer sequences. the {a/u}-rich enhancer contributes strongly to the efficiency of initiation, having the greatest stimulatory effect in the exponential growth phase of the bacteria. the {sd} sequences and the {a/u}-rich enhancer stimulate translation co-operatively: strong {sds} are stimulated by the enhancer much more than weak {sds}. the bacterial growth rate does not have a major influence on the {tir} selection pattern. on the other hand, temperature affects the {tir} preference pattern: shorter {sd} sequences are preferred at lower growth temperatures. we also performed an in silico analysis of the {tirs} in all e. coli {mrnas}. the base pairing potential of the {sd} sequences does not correlate with the codon adaptation index, which is used as an estimate of gene expression level. {conclusion}: in e. coli the {sd} selection preferences are influenced by the growth temperature and not influenced by the growth rate. the {a/u} rich enhancers stimulate translation considerably by acting co-operatively with the {sd} sequences."
8949063,inproceedings,,proceedings of the 12th international conference on human computer interaction with mobile devices and services,mobilehci,acm,9,,,2010,,2011-03-06 01:01:50,"new york, ny, usa",contextual queries express mobile information needs,"the users of mobile devices increasingly use networked services to address their information needs. questions asked by mobile users are strongly influenced by contextual factors such as location, conversation and activity. we report on a diary study performed to better understand mobile information needs. we find that the type of questions recorded by participants varies across their locations, with differences between home, shopping and in-car contexts. these variations occur both in the query terms and in the form of desired answers. both the location of queries and the participants' activities affected participants' questions. when information needs were affected by both location and activity, they tended to be strongly affected by both factors. the overall picture that emerges is one of multiple contextual influences interacting to shape mobile information needs. mobile devices that attempt to adapt to users' context will need to account for a rich variety of situational factors."
3317955,mastersthesis,,,,,,,,2008,,2008-09-22 21:47:02,,blogging music: indian musicians and online musical space,"music blogging is a new musical practice wherein the bloggers post recordings of their own music on personal weblogs. the members of the indian music blogging community discussed in this paper have produced four albums of original music entitled {blogswara} and posted them on the internet for listeners to download and share for free. this paper presents an ethnography of the indian music blogging community and a critical analysis of the historical and technological foundation for music blogging. the primary focus of this inquiry is to explore the significance of the online musical practices of the indian music blogging community, both as a virtual phenomenon and as one grounded in embodied experience, while contributing to the development of a global discourse on internet-based activities through a south asian-centric viewpoint."
5980303,article,journal of neuropsychiatry,,,,11,21,2,2009,jul,2009-10-21 12:46:27,,does cognitive behavioral therapy change the brain? a systematic review of neuroimaging in anxiety disorders,"this systematic review aims to investigate neurobiological changes related to cognitive-behavioral therapy ({cbt}) in anxiety disorders detected through neuroimaging techniques and to identify predictors of response to treatment. cognitive-behavioral therapy modified the neural circuits involved in the regulation of negative emotions and fear extinction in judged treatment responders. the only study on predictors of response to treatment was regarding obsessive-compulsive disorder and showed higher pretreatment regional metabolic activity in the left orbitofrontal cortex associated with a better response to behavioral therapy. despite methodological limitations, neuroimaging studies revealed that {cbt} was able to change dysfunctions of the nervous system."
2575445,techreport,,,,,,,TR-99-33,1999,,2008-03-23 22:05:48,,combining a monad and a comonad,
10041012,article,shakespeare quarterly,,,the johns hopkins university press,27,62,1,2011,,2011-11-18 14:53:41,,"black aeneas: race, english literary history, and the ""barbarous"" poetics of <{i>titus} andronicus</i>",
3273883,article,nature,,,,3,392,6679,1998,apr,2008-09-16 17:09:37,"department of cellular and molecular pharmacology, university of california, san francisco 94143-0450, usa. lefstin@stanford.edu",allosteric effects of {dna} on transcriptional regulators.,
8182506,article,harvard law review,,,the harvard law review association,,84,2,1970,dec,2010-11-03 01:38:43,,"the uneasy case for copyright: a study of copyright in books, photocopies, and computer programs","congress is currently considering the first major revision of the copyright act of 1909. professor breyer examines the moral and economic rationale for copyright in books. he goes on to consider proposals that would lengthen the term of protection and increase its scope in relation to photocopies and computer programs. on the basis of existing evidence he is unable to conclude that copyright should be abolished, but he argues that its extension is unnecessary and would be harmful."
4272079,article,the journal of biological chemistry,,,,8,284,11,2009,mar,2009-04-04 14:24:21,,in vitro interactions between the {pii} proteins and the nitrogenase regulatory enzymes dinitrogenase reductase {adp}-ribosyltransferase ({drat}) and dinitrogenase reductase-activating glycohydrolase ({drag}) in azospirillum brasilense.,"the activity of the nitrogenase enzyme in the diazotroph azospirillum brasilense is reversibly inactivated by ammonium through {adp}-ribosylation of the nitrogenase {nifh} subunit. this process is catalyzed by {drat} and is reversed by {drag}, and the activities of both enzymes are regulated according to the levels of ammonium through direct interactions with the {p(ii}) proteins {glnb} and {glnz}. we have previously shown that {drag} interacts with {glnz} both in vivo and in vitro and that {drat} interacts with {glnb} in vivo. we have now characterized the influence of {p(ii}) uridylylation status and the {p(ii}) effectors ({atp}, {adp}, and 2-oxoglutarate) on the in vitro formation of {drat}-{glnb} and {drag}-{glnz} complexes. we observed that both interactions are maximized when {p(ii}) proteins are de-uridylylated and when {adp} is present. the {drat}-{glnb} complex formed in vivo was purified to homogeneity in the presence of {adp}. the stoichiometry of the {drat}-{glnb} complex was determined by three independent approaches, all of which indicated a 1:1 stoichiometry ({drat} {monomer:glnb} trimer). our results suggest that the intracellular fluctuation of the {p(ii}) ligands {atp}, {adp}, and 2-oxoglutarate play a key role in the post-translational regulation of nitrogenase activity."
4158940,article,comparative studies in society and history,,,,26,45,02,2003,mar,2009-03-10 12:48:24,,"{self-interpretation}, agency, and the objects of anthropology: reflections on a genealogy","if there is anything that exemplifies a certain common style in ethnographically-oriented approaches to culture and society today, and sets them apart from other kinds of social science, it is the habit, irritating to colleagues in some other disciplines, frustrating to students, deemed perverse by potential funders, and bewildering to the public, of responding to explanations with the remark, {\^{a}we} need to complicate the story.\^{a} the words \^{a}reductionist\^{a} and \^{a}essentializing\^{a} are brandished with scorn. one important perspective is expressed by this remark by jean and john comaroff, two influential anthropologists with solid roots in longterm fieldwork, the sobriety of british social anthropology, and the tough-minded realism of the marxist tradition: ethnography \^{a}refuses to put its trust in techniques that give more scientific methods their illusory objectivity: their commitment to standardized, a priori units of analysis, for example, or their reliance on a depersonalizing gaze that separates subject from object\^{a} (1992:8). these words, offered almost in passing, take a host of important arguments as settled. one is that it is no longer in much dispute that cultural anthropology is not merely at an \^{a}immature\^{a} stage, en route to something more akin to natural science. most significant, perhaps, is the assumption that the separation of subject from object can be understood only in negative terms, that to say that a field of knowledge \^{a}depersonalizes\^{a} is ipso facto to discredit it. yet in their own ethnographic and historical work the comaroffs take their empirical materials very seriously and do not wholly reject the separation of subject from object\^{a}how could they? what is at issue, rather, is what kinds of \^{a}objects\^{a} and \^{a}subjects,\^{a} and what categories of analysis and comparison, are epistemologically appropriate and ethically legitimate for the study of social actions and self-understandings."
1094886,article,philosophy and rhetoric,,,,6,39,2,2006,,2007-02-08 14:27:57,,thinking in public with rhetoric,
5031991,article,genes \& development,,,,15,1,3,1987,may,2009-07-01 12:36:41,,novel transcripts from the ultrabithorax domain of the bithorax complex.,"10.1101/gad.1.3.307 we present a detailed analysis of the transcriptional products of the bithoraxoid (bxd) region of the ultrabithorax domain in the bithorax complex of drosophila melanogaster. this region is transcribed twice during development: between 3 and 6 hr of embryogenesis, a set of early transcripts, 1.1 to 1.3 kb in size, is synthesized; from the midthird larval instar through the adult stages, a late 0.8-kb transcript is synthesized. we have sequenced five cloned {cdnas} representing early transcripts and three {cdnas} representing the late transcript and have located their exons within the 40 kb of {dna} comprising the bxd region. s1 nuclease protection and primer extension of both the early and late transcripts were used to further elucidate their structure. the early {rnas} are produced by complex differential splicing of a series of exons derived from a 26-kb primary transcript. curiously, these {rnas} do not possess significant protein coding potential. the late bxd {rna} comprises a single exon transcribed from an intronic region of the early transcription unit. this {rna}, by contrast, possesses excellent coding potential and, if translated, would yield a 101-amino-acid polypeptide."
2754633,article,pattern recognition,kernel and subspace methods for computer vision,,,14,36,9,2003,sep,2008-05-05 00:20:55,,shape statistics in kernel space for variational image segmentation,"we present a variational integration of nonlinear shape statistics into a {mumford-shah} based segmentation process. the nonlinear statistics are derived from a set of training silhouettes by a novel method of density estimation which can be considered as an extension of kernel {pca} to a probabilistic framework. we assume that the training data forms a gaussian distribution after a nonlinear mapping to a higher-dimensional feature space. due to the strong nonlinearity, the corresponding density estimate in the original space is highly {non-gaussian}. applications of the nonlinear shape statistics in segmentation and tracking of {2d} and {3d} objects demonstrate that the segmentation process can incorporate knowledge on a large variety of complex real-world shapes. it makes the segmentation process robust against misleading information due to noise, clutter and occlusion."
2620116,article,journal of arid environments,"special issue on the ""greening"" of the sahel",,,10,63,3,2005,nov,2008-04-01 15:26:06,,"a recent greening of the sahel—trends, patterns and potential causes","for the last four decades there has been sustained scientific interest in contemporary environmental change in the sahel (the southern fringe of the sahara). it suffered several devastating droughts and famines between the late 1960s and early 1990s. speculation about the climatology of these droughts is unresolved, as is speculation about the effects of land clearance on rainfall and about land degradation in this zone. however, recent findings suggest a consistent trend of increasing vegetation greenness in much of the region. increasing rainfall over the last few years is certainly one reason, but does not fully explain the change. other factors, such as land use change and migration, may also contribute. this study investigates the nature of a secular vegetation trend across the sahel and discusses several potential causative factors."
4149287,electronic,,,,,,,,-1,,2009-03-08 16:37:29,,364 semiometrics: applying ontologies across {large-scale} digital libraries,"abstract. as large-scale digital libraries become more available and complete, not to mention more numerous, it is clear there is a need for services that can draw together and perform inference calculations on the metadata produced. however, the traditional relational database management system ({rdbms}) model, while efficiently constructed and optimised for many business structures, does not necessarily cope well with issues of concurrent data updates and retrieval at the scale of hundreds of thousands of papers. at the same time the growth of {rdf} and the increasing interest in semantic web technologies perhaps begins to present a viable alternative at a scalable, practical level. this paper considers a specific application of large-scale metadata analysis and conducts scalability tests using real-world data. it concludes that {rdf} technologies are both a scalable and performance-realistic alternative to traditional {rdbms} approaches. it also shows that for relationship-based queries on large-scale metadata stores, {rdf} technologies can significantly out-perform traditional {rdbms} approaches by allowing both retrieval and updating of data in a timely manner. 1"
7164616,article,journal of biomolecular nmr,,,springer netherlands,14,47,2,2010,jun,2010-05-13 15:39:43,,a probabilistic approach for validating protein {nmr} chemical shift assignments.,
8964441,article,drug discovery today,,,,12,16,7-8,2011,apr,2011-03-17 18:23:24,,in silico repositioning of approved drugs for rare and neglected diseases,"one approach to speed up drug discovery is to examine new uses for existing approved drugs, so-called 'drug repositioning' or 'drug repurposing', which has become increasingly popular in recent years. analysis of the literature reveals many examples of {us} food and drug administration-approved drugs that are active against multiple targets (also termed promiscuity) that can also be used to therapeutic advantage for repositioning for other neglected and rare diseases. using proof-of-principle examples, we suggest here that with current in silico technologies and databases of the structures and biological activities of chemical compounds (drugs) and related data, as well as close integration with in vitro screening data, improved opportunities for drug repurposing will emerge for neglected or rare/orphan diseases."
503583,misc,transcription of the bell communications research colloquium seminar,,,,,,,1986,mar,2006-02-13 08:48:45,,you and your research,
8400215,article,"ilar journal / national research council, institute of laboratory animal resources",,,,5,51,3,2010,jul,2010-12-09 16:28:09,,animals as sentinels: using comparative medicine to move beyond the laboratory.,"the comparative medicine approach, as applied to the study of laboratory animals for the betterment of human health, has resulted in important medical and scientific progress. much of what is known about the human health risks of many toxic and infectious hazards present in the environment derives from experimental studies in animals and observational (epidemiological) studies of exposed human populations. yet there is a third source of in vivo knowledge about host-environment interactions that may be underused and -explored: the study of diseases in naturally occurring animal populations that may signal potential human health threats. just as canaries warned coal miners of the risk of toxic gases, other nonhuman animals, due to their greater susceptibility, environmental exposure, or shorter life span, may serve as sentinels for human environmental health hazards. traditionally, communication between human and animal health professionals about cross-species sentinel events has been limited, but progress in comparative genomics, animal epidemiology, and bioinformatics can now provide an enhanced forum for such communication. the ""one health"" concept involves moving toward a comparative clinical approach that considers shared risks between humans and animals and promotes greater cooperation and collaboration between human and animal health professionals to identify and reduce such risks. in doing so, it also creates new opportunities for the field of comparative medicine that can supplement traditional laboratory animal research."
2808352,article,transactions of the institute of british geographers,,,,22,29,3,2004,,2008-05-17 23:38:51,,consuming narratives: the political ecology of 'alternative' consumption,this paper examines how political ecology themes of tropical conservation and social justice become representational practices underpinning 'alternative' consumption in the north. the notion of commodity culture is adopted to understand the ambiguous rationalities and ethical assumptions of two sets of consumption practices. the first case considers edenic myth-making used to assimilate concerns over tropical deforestation in the south to consumption-intensive if conservation-minded lifestyles in the north. the second case looks at fair trade and how concern about social injustice and unfair labour practices in the south is harnessed to solidarity-seeking consumption constitutive of 'radical' lifestyles. the paper suggests these contrasting commodity cultures broadly conform to divergent positions in red-green debates. it argues that both are weakened as a form of social and political 'caring at a distance' due to an uncritical acceptance of consumption as the primary basis of action.
988047,proceedings,"peer-to-peer computing, 2004. proceedings. proceedings. fourth international conference on",,,,1,,,2004,,2006-12-10 15:37:04,,latency model of a distributed hash table with big routing table,"in peer-to-peer research, one of the most popular areas is distributed hash table ({dht}). among many topics in the {dht} area, this paper focuses on {dht} latencies, which are mainly caused by its basic multi-hop lookup function. some {dhts} already have the capability of building big routing tables to reduce hop counts. however, none of them are explicitly trying to enlarge the routing table and lower the hop count. this paper provides a simple latency model of {dht} and discusses how big routing tables help reduce latency."
2722873,article,langmuir,,,american chemical society,13,13,17,1997,aug,2008-04-27 01:19:50,"johns hopkins university, department of chemical engineering, 221 maryland hall, 3400 n. charles saint, baltimore, maryland 21218, and centre de recherche paul pascal, ave. a. schweitzer, f-33600 pessac, france",shear rupturing of droplets in complex fluids,"we have experimentally studied the shear-induced rupturing of viscous droplets in viscoelastic complex fluids. remarkably, a premixed emulsion of large, polydisperse droplets can be ruptured into monodisperse emulsions of uniform colloidal droplets. the monodispersity becomes most pronounced when the premixed emulsion is viscoelastic and has a shear-thinning viscosity. since viscoelastic materials may fracture, we reduce the gap of our shear cell to ensure a spatially uniform strain rate for rupturing. we observe monodispersity whether the viscoelasticity arises from the suspending fluid (e.g., concentrated surfactant solution) or droplet deformation as in compressed emulsions. our observations suggest that the monodispersity results from droplet rupturing alone and that the capillary instability is inhibited by the partial elasticity of the complex fluid. we use the monodispersity to study how the droplet size depends upon the shear rate and composition."
1899138,inproceedings,,pods,,acm,11,,,2003,,2007-11-11 16:52:30,"new york, ny, usa",on the decidability and complexity of query answering over inconsistent and incomplete databases,"in databases with integrity constraints, data may not satisfy the constraints. in this paper, we address the problem of obtaining consistent answers in such a setting, when key and inclusion dependencies are expressed on the database schema. we establish decidability and complexity results for query answering under different assumptions on data (soundness and/or completeness). in particular, after showing that the problem is in general undecidable, we identify the maximal class of inclusion dependencies under which query answering is decidable in the presence of key dependencies. although obtained in a single database context, such results are directly applicable to data integration, where multiple information sources may provide data that are inconsistent with respect to the global view of the sources."
3983962,article,international journal of project management,,,,12,26,3,2008,apr,2009-01-30 16:15:32,,learning and acting in project situations through a meta-method ({map}) a case study: contextual and situational approach for project management governance in management education,"the paper introduces the underlying principles and the general features of a meta-method ({map} method) developed as part of and used in various research, education and professional development programmes at {esc} lille. this method aims at providing effective and efficient structure and process for acting and learning in various complex, uncertain and ambiguous managerial situations (projects, programmes, portfolios). the paper is developed around three main parts. first, i suggest revisiting the dominant vision of the project management knowledge field, based on the assumptions they are not addressing adequately current business and management contexts and situations, and that competencies in management of entrepreneurial activities are the sources of creation of value for organisations. then, grounded on the former developments, i introduce the underlying concepts supporting {map} method seen as a 'convention generator' and how this meta-method inextricably links learning and practice in addressing managerial situations. finally, i briefly describe an example of application, illustrating with a case study how the method integrates project management governance, and give few examples of use in management education and professional development."
4781936,book,,,,springer,,,,2007,dec,2010-06-11 14:59:29,,probability theory: a comprehensive course (universitext),"probabilistic concepts play an increasingly important role in mathematics,physics, biology, financial engineering and computer science. they help us tounderstand magnetism, amorphous media, genetic diversity and the perils ofrandom developments on the financial markets, and they guide us inconstructing more efficient {algorithms.this} text is a comprehensive course in modern probability theory and itsmeasure-theoretical foundations. aimed primarily at graduate students andresearchers, the book covers a wide variety of topics, many of which are notusually found in introductory textbooks, such as: * limit theorems for sums of random variables; * martingales; * percolation; * markov chains and electrical networks; * construction of stochastic processes; * poisson point processes and infinite divisibility; * large deviation principles and statistical physics; * brownian motion; and * stochastic integral and stochastic differential {equations.the} theory is developed rigorously and in a self-contained way, with thechapters on measure theory interlaced with the probabilistic chapters in orderto display the power of the abstract concepts in the world of probabilitytheory. in addition, plenty of figures, computer simulations, biographicdetails of key mathematicians, and a wealth of examples support and enliventhe presentation."
11700736,article,plos comput biol,,,public library of science,,8,11,2012,nov,2012-11-16 11:13:59,,a bayesian inference framework to reconstruct transmission trees using epidemiological and genetic data,"the accurate identification of the route of transmission taken by an infectious agent through a host population is critical to understanding its epidemiology and informing measures for its control. however, reconstruction of transmission routes during an epidemic is often an underdetermined problem: data about the location and timings of infections can be incomplete, inaccurate, and compatible with a large number of different transmission scenarios. for fast-evolving pathogens like {rna} viruses, inference can be strengthened by using genetic data, nowadays easily and affordably generated. however, significant statistical challenges remain to be overcome in the full integration of these different data types if transmission trees are to be reliably estimated. we present here a framework leading to a bayesian inference scheme that combines genetic and epidemiological data, able to reconstruct most likely transmission patterns and infection dates. after testing our approach with simulated data, we apply the method to two {uk} epidemics of {foot-and-mouth} disease virus ({fmdv}): the 2007 outbreak, and a subset of the large 2001 epidemic. in the first case, we are able to confirm the role of a specific premise as the link between the two phases of the epidemics, while transmissions more densely clustered in space and time remain harder to resolve. when we consider data collected from the 2001 epidemic during a time of national emergency, our inference scheme robustly infers transmission chains, and uncovers the presence of undetected premises, thus providing a useful tool for epidemiological studies in real time. the generation of genetic data is becoming routine in epidemiological investigations, but the development of analytical tools maximizing the value of these data remains a priority. our method, while applied here in the context of {fmdv}, is general and with slight modification can be used in any situation where both spatiotemporal and genetic data are available. in order to most effectively control the spread of an infectious disease, we need to better understand how pathogens spread within a host population, yet this is something we know remarkably little about. cases close together in their locations and timing are often thought to be linked, but timings and locations alone are usually consistent with many different scenarios of who-infected-who. the genome of many pathogens evolves so quickly relative to the rate that they are transmitted, that even over single short epidemics we can identify which hosts contain pathogens that are most closely related to each other. this information is valuable because when combined with the spatial and timing data it should help us infer more reliably who-transmitted-to-who over the course of a disease outbreak. however, doing this so that these three different lines of evidence are appropriately weighted and interpreted remains a major statistical challenge. in our paper we present a new statistical method for combining these different types of data and estimating trees that show how infection was most likely transmitted between individuals in a host population. because sequencing genetic material has become so affordable, we think methods like ours will become very important for future epidemiology."
6744007,article,the yale law journal,,,"the yale law journal company, inc.",70,113,6,2004,apr,2010-02-28 23:59:20,,the two western cultures of privacy: dignity versus liberty,"privacy advocates often like to claim that all modern societies feel the same intuitive need to protect privacy. yet it is clear that intuitive sensibilities about privacy differ from society to society, even as between the closely kindred societies of the united states and continental europe. some of the differences involve questions of everyday behavior, such as whether or not one may appear nude in public. but many involve tha law. in fact, we are in the midst of major legal conflicts between the countries on either side of the atlantic-conflicts over questions like the protection of consumer data, the use of discovery iin civil procedure, the public exposure of criminal offenders, and more. clearly the idea that there are as the basis of a universal law of privacy, cannot be right. this article explores these conflicts, trying to show that european privacy norms are founded on french and german ideas of ""personal honor."" continental ""privacy,"" like continental sexual harassment law, prison law, and many other bodies of law, aims to protect the ""personal honor"" of ordinary french and german folk. american law takes a very different approach, protecting primarily a liberty interest. the article traces the roots of french and german attitudes over the last couple of centuries, highlighting the french experience of sexual license in the nineteenth century and the german experience of nazism. the articlee then discusses the current state of french and german law with regard to matters such as consumer credit reporting, public nudity, and the law of baby names. it contrasts continental approaches to what we find in american law. throughout, the article argues, american law shows a far greater sensitivity to intrusions on the part of the state, while continentla law shows a far greater sensitivity to the protection of one's public face. these are not differences that we can understand unless we abandon the approach taken by most privacy advocates, since such differences have little to do with the supposedly universal intuitive needs of ""personhood."" instead, they are differences that reflect the constrasting political and social ideals of american and continental law. indeed, we should broadly reject intuitionism in our legal scholarship, focusing instead on social and political ideals."
118605,article,acm trans. graph.,,,acm,9,22,3,2003,jul,2005-03-09 18:58:15,"new york, ny, usa",{treejuxtaposer}: scalable tree comparison using {focus+context} with guaranteed visibility,"structural comparison of large trees is a dif cult task that is only partially supported by current visualization techniques, which are mainly designed for browsing. we present {treejuxtaposer}, a system designed to support the comparison task for large trees of several hundred thousand nodes. we introduce the idea of \`{\i}guaranteed visibility\^{i}, where highlighted areas are treated as landmarks that must remain visually apparent at all times. we propose a new methodology for detailed structural comparison between two trees and provide a new nearly-linear algorithm for computing the best corresponding node from one tree to another. in addition, we present a new rectilinear {focus+context} technique for navigation that is well suited to the dynamic linking of side-by-side views while guaranteeing landmark visibility and constant frame rates. these three contributions result in a system delivering a  uid exploration experience that scales both in the size of the dataset and the number of pixels in the display. we have based the design decisions for our system on the needs of a target audience of biologists who must understand the structural details of many phylogenetic, or evolutionary, trees. our tool is also useful in many other application domains where tree comparison is needed, ranging from network management to call graph optimization to genealogy."
3444430,incollection,information visualization,,,,41,,,2008,,2008-10-23 20:55:17,,creation and collaboration: engaging new audiences for information visualization,"in recent years we have seen information visualization technology move from an advanced research topic to mainstream adoption in both commercial and personal use. this move is in part due to many businesses recognizing the need for more effective tools for extracting knowledge from the data warehouses they are gathering. increased mainstream interest is also a result of more exposure to advanced interfaces in contemporary online media. the adoption of information visualization technologies by lay users – as opposed to the traditional information visualization audience of scientists and analysts – has important implications for visualization research, design and development. since we cannot expect each of these lay users to design their own visualizations, we have to provide them tools that make it easy to create and deploy visualizations of their datasets."
5839136,book,,,,addison-wesley professional,,,,2009,jun,2009-09-25 08:53:58,,elements of programming,"elements of programming provides a different understanding of programming than is presented elsewhere. its major premise is that practical programming, like other areas of science and engineering,must be based on a solid mathematical foundation. the book shows that algorithms implemented in a real programming language, such as c++, can operate in the most general mathematical setting. for example, the fast exponentiation  algorithm is defined to work with any associative operation. using abstract algorithms leads to efficient, reliable, secure, and economical software."
374939,article,neuroimage,,,,11,23,1,2004,sep,2005-11-01 10:23:42,"department of neurology, reed neurologic research center, university of california los angeles, los angeles, ca 90095, usa. bdobkin@mednet.ucla.edu",ankle dorsiflexion as an {fmri} paradigm to assay motor control for walking during rehabilitation.,"the ability to walk independently with the velocity and endurance that permit home and community activities is a highly regarded goal for neurological rehabilitation after stroke. this pilot study explored a functional magnetic resonance imaging ({fmri}) activation paradigm for its ability to reflect phases of motor learning over the course of locomotor rehabilitation-mediated functional gains. ankle dorsiflexion is an important kinematic aspect of the swing and initial stance phase of the gait cycle. the motor control of dorsiflexion depends in part on descending input from primary motor cortex. thus, an {fmri} activation paradigm using voluntary ankle dorsiflexion has face validity for the serial study of walking-related interventions. healthy control subjects consistently engaged contralateral primary sensorimotor cortex ({s1m1}), supplementary motor area ({sma}), premotor ({pm}) and cingulate motor ({cma}) cortices, and ipsilateral cerebellum. four adults with chronic hemiparetic stroke evolved practice-induced representational plasticity associated with gains in speed, endurance, motor control, and kinematics for walking. for example, an initial increase in activation within the thoracolumbar muscle representation of {s1m1} in these subjects was followed by more focused activity toward the foot representation with additional pulses of training. contralateral {cma} and the secondary sensory area also reflected change with practice and gains. we demonstrate that the supraspinal sensorimotor network for the neural control of walking can be assessed indirectly by ankle dorsiflexion. the ankle paradigm may serve as an ongoing physiological assay of the optimal type, duration, and intensity of rehabilitative gait training."
2393065,incollection,,advances in neural information processing systems 20,,mit press,,,,2008,,2008-02-18 09:13:26,"cambridge, ma",the infinite markov model,
9713211,article,journal of experimental criminology,,,springer netherlands,23,,,2011,aug,2011-08-26 21:19:11,,"the possible  ? backfire? effects of hot spots policing: an experimental assessment of impacts on legitimacy, fear and collective efficacy","objectives to examine the impacts of broken windows policing at crime hot spots on fear of crime, ratings of police legitimacy and reports of collective efficacy among residents of targeted hot spots. methods a block randomized experimental design with a police intervention targeting disorder delivered to 55 treatment street segments with an equal number of segments serving as controls. main outcomes were measured using a panel survey of 371 persons living or working in these sites. results the broken windows police intervention delivered to crime hot spots in this study had no significant impacts on fear of crime, police legitimacy, collective efficacy, or perceptions of crime or social disorder. perceptions of physical disorder appear to have been modestly increased in the target areas. conclusions the findings suggest that recent criticisms of hot spots policing approaches which focus on possible negative  ? backfire? effects for residents of the targeted areas may be overstated. the study shows that residents are not aware of, or much affected by, a three hour per week dosage of aggressive order maintenance policing on their blocks (in addition to routine police responses in these areas). future research needs to replicate these findings focusing on varied target populations and types of crime hot spots, and examining different styles of hot spots policing."
4002037,article,current pharmaceutical design,,,bentham science publishers,9,12,17,2006,jun,2010-04-21 12:18:38,,recent developments of the chemistry development kit ({cdk}) - an {open-source} java library for chemo- and bioinformatics,"the chemistry development kit ({cdk}) provides methods for common tasks in molecular informatics, including {2d} and {3d} rendering of chemical structures, {i/o} routines, {smiles} parsing and generation, ring searches, isomorphism checking, structure diagram generation, etc. implemented in java, it is used both for server-side computational services, possibly equipped with a web interface, as well as for applications and client-side applets. this article introduces the {cdk}\&\#39;s new {qsar} capabilities and the recently introduced interface to statistical software."
965002,article,intern. j. of pattern recogn. and artific. intelige.,,,,23,??,3,1988,,2006-11-28 07:40:35,,motion and structure from motion in a piecewise planar environment,
7853484,article,the american journal of human genetics,,,,8,87,3,2010,sep,2010-09-19 04:02:38,,direct measure of the de novo mutation rate in autism and schizophrenia cohorts,"the role of de novo mutations ({dnms}) in common diseases remains largely unknown. nonetheless, the rate of de novo deleterious mutations and the strength of selection against de novo mutations are critical to understanding the genetic architecture of a disease. discovery of high-impact {dnms} requires substantial high-resolution interrogation of partial or complete genomes of families via resequencing. we hypothesized that deleterious {dnms} may play a role in cases of autism spectrum disorders ({asd}) and schizophrenia ({scz}), two etiologically heterogeneous disorders with significantly reduced reproductive fitness. we present a direct measure of the de novo mutation rate (?) and selective constraints from {dnms} estimated from a deep resequencing data set generated from a large cohort of {asd} and {scz} cases (n = 285) and population control individuals (n = 285) with available parental {dna}. a survey of ?430 mb of {dna} from 401 synapse-expressed genes across all cases and 25 mb of {dna} in controls found 28 candidate {dnms}, 13 of which were cell line artifacts. our calculated direct neutral mutation rate (1.36 ?10(-8)) is similar to previous indirect estimates, but we observed a significant excess of potentially deleterious {dnms} in {asd} and {scz} individuals. our results emphasize the importance of {dnms} as genetic mechanisms in {asd} and {scz} and the limitations of using {dna} from archived cell lines to identify functional variants."
4491461,article,,,,,,,,2010,jul,2009-05-08 09:41:20,,the cold spot as a large void: lensing effect on {cmb} two and three point correlation functions,
340808,article,vaccine,,,,8,23,15,2005,mar,2005-10-04 16:51:59,"cnrs umr 6037, ifrmp 23, gdr 2590, universit\'{e} de rouen-b\^{a}timent de biologie (extension), blvd de broglie, 76821 mont saint aignan cedex, france. lfaye@crihan.fr",protein modifications in the plant secretory pathway: current status and practical implications in molecular pharming.,"plants have become, over the last ten years, a suitable alternative to microbial and animal cell factories for the production of clinically-useful, therapeutic proteins. besides the well known advantage of low-cost and large-scale production of safe and biologically active mammalian proteins, plants also are able to perform most post-translational maturations required for biological activity and suitable pharmacokinetics of recombinant therapeutic proteins. in this short review we focus on glycosylation and proteolytic processing of plant-made pharmaceuticals during their transport through the plant cell's secretory pathway. we also address the practical implications of these important processes on the effectiveness of plant molecular pharming systems."
711311,article,european journal of soil science,,,,,0,0,0,,2006-06-26 14:08:28,,determining soil saturated hydraulic conductivity and sorptivity from single ring infiltration tests,"summary the difference between the cumulative infiltration occurring during three-dimensional axisymmetric and one-dimensional vertical flow is a linear function of time. the slope of this line is a function of the source radius, initial and final volumetric soil water contents and the soil sorptivity. this allows the determination of the sorptivity and saturated conductivity of the soil from data of axisymmetric flow in a single ring of small diameter under negligible head of water. the method is based on the optimization of the sorptivity and saturated conductivity on the one-dimensional vertical cumulative infiltration inferred from axisymmetric flow data. to examine the reliability of the method to determine these parameters, numerical three- and one-dimensional data are generated on soils with known hydrologic properties from the literature. the linearity versus time of the difference of the two types of flow is verified. several physically based expressions for the vertical cumulative infiltration as a function of time are considered. the optimized values of the sorptivity and saturated conductivity are compared to the their real known values. despite the large errors on the optimized parameters, namely the saturated conductivity, the error on the vertical predicted cumulative infiltration is limited to 10\%. this makes possible the application of this method on a large scale for hydrological modelling purposes."
7212671,article,journal of functional programming,,,cambridge university press,17,12,6,2002,nov,2010-05-25 15:40:51,"new york, ny, usa",the lambda calculus is algebraic,"this paper serves as a self-contained, tutorial introduction to combinatory models of the untyped lambda calculus. we focus particularly on the interpretation of free variables. we argue that free variables should not be interpreted as elements in a model, as is usually done, but as indeterminates. we claim that the resulting interpretation is more natural and leads to a closer correspondence between models and theories. in particular, it solves the problem of the notorious ?-rule, which asserts that equations should be preserved under binders, and which fails to be sound for the usual interpretation."
1553829,article,nucleic acids res,,,,,,,2007,aug,2007-08-11 11:10:10,"interdepartmental program in computational biology and bioinformatics department of molecular biophysics and biochemistry and department of computer science, yale university, usa.",toward a universal microarray: prediction of gene expression through nearest-neighbor probe sequence identification.,"a generic {dna} microarray design applicable to any species would greatly benefit comparative genomics. we have addressed the feasibility of such a design by leveraging the great feature densities and relatively unbiased nature of genomic tiling microarrays. specifically, we first divided each homo sapiens refseq-derived gene's spliced nucleotide sequence into all of its possible contiguous 25 nt subsequences. for each of these 25 nt subsequences, we searched a recent human transcript mapping experiment's probe design for the 25 nt probe sequence having the fewest mismatches with the subsequence, but that did not match the subsequence exactly. signal intensities measured with each gene's nearest-neighbor features were subsequently averaged to predict their gene expression levels in each of the experiment's thirty-three hybridizations. we examined the fidelity of this approach in terms of both sensitivity and specificity for detecting actively transcribed genes, for transcriptional consistency between exons of the same gene, and for reproducibility between tiling array designs. taken together, our results provide proof-of-principle for probing nucleic acid targets with off-target, nearest-neighbor features."
564010,techreport,,,,successful.com,,,,2006,feb,2006-03-26 19:06:04,,municipal wireless snapshot: what's the price of free?,
8510428,article,bmc genomics,,,,,12,1,2011,,2011-01-06 03:47:58,,the genome sequence of e. coli w ({atcc} 9637): comparative genome analysis and an improved genome-scale reconstruction of e. coli.,
6942528,article,journal of computer-mediated communication,,,blackwell publishing ltd,20,15,2,2010,jan,2010-04-02 15:27:46,"school of information, uc berkeley, 102 south hall, berkeley, ca 94720",evaluating shared access: social equality and the circulation of mobile phones in rural uganda,"this article examines forms of shared access to technology where some privileges of ownership are retained. sharing is defined as informal, non-remunerative resource distributing activities where multiple individuals have a relationship to a single device as purchaser, owner, possessor, operator and/or user. in the specific case of mobile phones in rural uganda, dynamics of social policing and social obligation were mediated and concretized by these devices. patterns of sharing mobile phones in rural uganda led to preferential access for needy groups (such as those in ill health) while systematically and disproportionately excluding others (women in particular). the framework for sharing proposed in this article will be useful for structuring comparisons of technology adoption and access across cultural contexts."
296024,article,proceedings of the national academy of sciences of the united states of america,,,national academy of sciences,5,102,29,2005,jul,2008-09-30 10:12:03,"max planck institute of colloids and interfaces, 14424 potsdam, germany.",dynamic pattern evolution on scale-free networks,"a general class of dynamic models on scale-free networks is studied by analytical methods and computer simulations. each network consists of n vertices and is characterized by its degree distribution, p(k), which represents the probability that a randomly chosen vertex is connected to k nearest neighbors. each vertex can attain two internal states described by binary variables or ising-like spins that evolve in time according to local majority rules. scale-free networks, for which the degree distribution has a power law tail p(k) ? k -?, are shown to exhibit qualitatively different dynamic behavior for ? < 5/2 and ? > 5/2, shedding light on the empirical observation that many real-world networks are scale-free with 2 < ? < 5/2. for 2 < ? < 5/2, strongly disordered patterns decay within a finite decay time even in the limit of infinite networks. for ? > 5/2, on the other hand, this decay time diverges as {ln(n}) with the network size n. an analogous distinction is found for a variety of more complex models including hopfield models for associative memory networks. in the latter case, the storage capacity is found, within mean field theory, to be independent of n in the limit of large n for ? > 5/2 but to grow as n ? with ? = (5 - 2?)/(? - 1) for 2 < ? < 5/2."
612068,article,mathematical structures in computer science,,,,18,1,1,1991,,2006-05-03 02:10:08,,a categorical manifesto,
12659333,article,journal of european insustrial training,,,,4,23,1,1999,,2013-09-27 12:56:54,,"employability, the emerging new deal?",
717613,inproceedings,"3d data processing visualization and transmission, 2002. proceedings. first international symposium on","3d data processing visualization and transmission, 2002. proceedings. first international symposium on",,,11,,,2002,,2006-06-30 15:57:02,,"generation, visualization, and editing of {3d} video","{3d} video is the ultimate image medium recording dynamic visual events in the real world as is. recorded object behaviors can be observed from any viewpoint, because {3d} video records the object's full {3d} shape, motion, and precise surface properties (i.e. color and texture). in our last paper, we presented a method of reconstructing dynamic {3d} object shape from multi-view video images, by which a temporal series of {3d} voxel representations of the object behavior can be obtained in real-time. in this paper, following an overview of the real-time {3d} shape reconstruction method, we present: 1) an algorithm of generating texture on the {3d} object surface from the multi-view video images, and 2) an editing system for visualizing {3d} video with an omnidirectional background image using versatile {3d} camera works. this paper mainly discusses how we can generate high fidelity object images from arbitrary viewpoints based on the {3d} object shape of limited accuracy. we propose a novel texture mapping algorithm which maps textures onto the {3d} object surface depending on a viewpoint. experimental results demonstrate its effectiveness in generating high fidelity object images from arbitrary viewpoints."
2949833,article,expert syst. appl.,,,"pergamon press, inc.",11,36,2,2009,mar,2008-07-02 04:29:56,"tarrytown, ny, usa",using contextual information and multidimensional approach for recommendation,"it has been recognized that recommendation system is a very important and indispensable topic in e-commerce. many famous e-commerce websites utilize recommendation systems to convert browsers into buyers. the forms of recommendation include suggesting products/services to the customer, providing personalized product/service information, summarizing community opinion, and providing community critiques. personalized recommendation methods are mainly classified into content-based recommendation approach and collaborative filtering recommendation approach. both recommendation approaches, however, have their own drawbacks. this study proposes the integrated contextual information as the foundation concept of multidimensional recommendation model, and uses the online analytical processing ({olap}) ability of data warehousing to solve the contradicting problems among hierarchy ratings. the evaluation studies show that by establishing additional customer profiles and using multidimensional analyses to find the key factors affecting customer perceptions, the proposed approach increases the recommendation quality."
1946942,article,the journal of political economy,,,,25,103,6,1995,,2007-11-20 19:58:31,,on the form of transfers to special interests,"an important question in political economy concerns the form of transfers to special interests. the chicago view is that political competition leads politicians to make such transfers efficiently. the virginia position is that lack of information on the part of voters leads politicians to favor inefficient \&quot;sneaky\&quot; methods of redistribution. this paper analyzes the form of transfers in a model of political competition in which politicians have incentives to make transfers to special interests. it shows that when voters have imperfect information about both the effects of policy and the predispositions of politicians, inefficient methods of redistribution may be employed."
1550920,inproceedings,electronic notes in theoretical computer science,,,,11,131,,2005,,2007-08-10 07:57:48,,inferring object invariants: extended abstract.,
267339,article,international journal of human-computer studies,,,,11,55,3,2001,sep,2005-07-28 16:47:39,,interactive machine learning: letting users build classifiers,"according to standard procedure, building a classifier using machine learning is a fully automated process that follows the preparation of training data by a domain expert. in contrast, interactive machine learning engages users in actually generating the classifier themselves. this offers a natural way of integrating background knowledge into the modelling stage-as long as interactive tools can be designed that support efficient and effective communication. this paper shows that appropriate techniques can empower users to create models that compete with classifiers built by state-of-the-art learning algorithms. it demonstrates that users-even users who are not domain experts-can often construct good classifiers, without any help from a learning algorithm, using a simple two-dimensional visual interface. experiments on real data demonstrate that, not surprisingly, success hinges on the domain: if a few attributes can support good predictions, users generate accurate classifiers, whereas domains with many high-order attribute interactions favour standard machine learning techniques. we also present an artificial example where domain knowledge allows an ''expert user'' to create a much more accurate model than automatic learning algorithms. these results indicate that our system has the potential to produce highly accurate classifiers in the hands of a domain expert who has a strong interest in the domain and therefore some insights into how to partition the data. moreover, small expert-defined models offer the additional advantage that they will generally be more intelligible than those generated by automatic techniques."
3752905,article,environmental health,,,,,7,1,2008,,2008-12-06 23:07:52,,immune cell counts and risks of respiratory infections among infants exposed pre- and post-natally to organochlorine compounds: a prospective study,"{background}:early-life chemical exposure may influence immune system development, subsequently affecting child health. we investigated immunomodulatory potentials of polychlorinated biphenyls ({pcbs}) and {p,p'-dde} in {infants.methods}:prenatal exposure to {pcbs} and {p,p'-dde} was estimated from maternal serum concentrations during pregnancy. postnatal exposure was calculated from concentrations of the compounds in mother's milk, total number of nursing days, and percentage of full nursing each week during the 3 month nursing period. number and types of infections among infants were registered by the mothers (n=190). white blood cell counts (n=86) and lymphocyte subsets (n=52) were analyzed in a subgroup of infants at 3 months of {age.results}:infants with the highest prenatal exposure to {pcb} congeners {cb}-28, {cb}-52 and {cb}-101 had an increased risk of respiratory infection during the study period. in contrast, the infection odds ratios ({ors}) were highest among infants with the lowest prenatal mono-ortho {pcb} ({cb}-105, {cb}-118, {cb}-156, {cb}-167) and di-ortho {pcb} ({cb}-138, {cb}-153, {cb}-180) exposure, and postnatal mono- and di-ortho {pcb}, and {p,p'-dde} exposure. similar results were found for pre- and postnatal {cb}-153 exposure, a good marker for total {pcb} exposure. altogether, a negative relationship was indicated between infections and total organochlorine compound exposure during the whole pre- and postnatal period. prenatal exposure to {cb}-28, {cb}-52 and {cb}-101 was positively associated with numbers of lymphocytes and monocytes in infants 3 months after delivery. prenatal exposure to {p,p'-dde} was negatively associated with the percentage of eosinophils. no significant associations were found between {pcb} and {p,p'-dde} exposure and numbers/percentages of lymphocyte subsets, after adjustment for potential {confounders.conclusions}:this hypothesis generating study suggests that background exposure to {pcbs} and {p,p'-dde} early in life modulate immune system development. strong correlations between mono- and di-ortho {pcbs}, and {p,p'-dde} exposures make it difficult to identify the most important contributor to the suggested immunomodulation, and to separate effects due to pre- and postnatal exposure. the suggested {pcb} and {p,p'-dde} modulation of infection risks may have consequences for the health development during childhood, since respiratory infections early in life may be risk factors for asthma and middle ear infections."
1874425,proceedings,"peer-to-peer computing, 2007. p2p 2007. seventh ieee international conference on","peer-to-peer computing, 2007. p2p 2007. seventh ieee international conference on",,,9,,,2007,,2007-11-06 16:16:07,,mapping small worlds,"social networks are usually navigable small worlds: individuals are able to find short chains of acquaintances connecting pairs of unrelated nodes. this property can be explained by the fact that nodes are characterized by a series of properties, such as geographical position, work or educational background; the navigation proceeds towards the node that is ""most similar"" to the destination. since nodes are likely to be linked with similar individuals, this strategy permits to quickly reach the destination. we approach the problem of creating the information that makes a network navigable. starting from a given network, and without any other information, we show how nodes can reconstruct, with a scalable and decentralized algorithm, a  ? network map?: a d-dimensional layout that places nodes in a way that reflects the network structure, so that navigability is achieved. euclidean distance on the layout is used as a measure for node similarity, and efficient routing can be simply achieved by iteratively jumping towards the neighbor that is closest to the destination. the network map provides a means for implementing routing on social networks that can be used in ""darknets"", that is, anonymous networks where nodes establish connections only if they are mutually trusted. moreover, the distance between nodes on the network map can be used as a measure of node affinity, and may help in various types of network analysis, for instance to help evaluate reputation in webs of trust, or in order to perform ""personalized"" ranking."
1269033,article,,on security,,columbia university press,,,,-1,,2007-04-30 20:54:17,"new york, ny","the value of security ? hobbes, marx, nietzsche, and baudrilliard",
2236789,article,magn. reson. med.,,,"wiley subscription services, inc., a wiley company",6,53,1,2005,jan,2008-01-16 00:22:20,"laboratory of cardiac energetics, national heart, lung, and blood institute, national institutes of health, dhhs, bethesda, maryland; departments of biomedical engineering and radiology, northwestern university, chicago, illinois; siemens medical solutions, usa, chicago, illinois",motion-corrected free-breathing delayed enhancement imaging of myocardial infarction,"following administration of {gd-dtpa}, infarcted myocardium exhibits delayed enhancement and can be imaged using an inversion-recovery sequence. a conventional segmented acquisition requires a number of breath-holds to image the heart. single-shot phase-sensitive inversion-recovery ({psir}) {true-fisp} may be combined with parallel imaging using {sense} to achieve high spatial resolution. {snr} may be improved by averaging multiple motion-corrected images acquired during free breathing. {psir} techniques have demonstrated a number of benefits including consistent contrast and appearance over a relatively wide range of inversion recovery times ({ti}), improved contrast-to-noise ratio, and consistent size of the enhanced region. comparison between images acquired using segmented breath-held {turbo-flash} and averaged, motion-corrected, free-breathing {true-fisp} show excellent agreement of measured {cnr} and infarct size. in this study, motion correction was implemented using image registration postprocessing rather than navigator correction of individual frames. navigator techniques may be incorporated as well. magn reson med 53:194?200, 2005. published 2004 {wiley-liss}, inc."
9404770,article,fems microbiology ecology,,,blackwell publishing ltd,,,,2011,,2011-06-14 09:14:19,,monitoring horizontal antibiotic resistance gene transfer in a colonic fermentation model,"abstract the human microbiota is suggested to be a reservoir of antibiotic resistance ({abr}) genes, which are exchangeable between transient colonizers and residing bacteria. in this study, transfer of {abr} genes from enterococcus faecalis to listeria monocytogenes and to commensal bacteria of the human gut microbiota was demonstrated in a colonic fermentation model. in the first fermentation, an e. faecalis donor harboring the marked 50-kb conjugative plasmid {pre25}* and a chromosomal marker was co-immobilized with l. monocytogenes and infant feces. in this complex environment, transfer of {pre25}* to l. monocytogenes was observed. in a second fermentation, only the e. faecalis donor and feces were co-immobilized. enumeration of {pre25}* and the donor strain by quantitative {pcr} revealed an increasing ratio of {pre25}* to the donor throughout the 16-days fermentation, indicating transfer of {pre25}*. an enterococcus avium transconjugant was isolated, demonstrating that {abr} gene transfer to gut commensals occurred. moreover, {pre25}* was still functional in both the e. avium and l. monocytogenes transconjugant and transmittable to other genera in filter mating experiments. our study reveals that transfer of a multiresistance plasmid to commensal bacteria in the presence of competing fecal microbiota occurs in a colonic model, suggesting that commensal bacteria contribute to the increasing prevalence of antibiotic resistant bacteria."
1309374,book,,,,cambridge university press,,,,1985,jul,2007-05-19 19:36:16,,foundations of illocutionary logic,"{this is a formal and systematic study of the logical foundations of speech act theory. the study of speech acts has been a flourishing branch of the philosophy of language and linguistics over the last two decades, and john searle has of course himself made some of the most notable contributions to that study in the sequence of books speech acts (1969), expression and meaning (1979) and intentionality (1983). in collaboration with daniel vanderveken he now presents the first formalised logic of a general theory of speech acts, dealing with such things as the nature of an illocutionary force, the logical form of its components, and the conditions of success of elementary illocutionary acts. the central chapters present a systematic exposition of the axioms and general laws of illocutionary logic.}"
14150030,article,physical review b,,,,,94,8,2016,apr,2016-10-01 18:52:10,,geometric defects in quantum hall states,
1974369,article,coastal engineering,coastal hydrodynamics and morphodynamics,,,6,53,2-3,2006,feb,2007-11-24 19:34:20,,numerical modeling of water waves with the {sph} method,"smoothed particle hydrodynamics ({sph}) is a relatively new method for examining the propagation of highly nonlinear and breaking waves. at johns hopkins university, we have been working since 2000 to develop an engineering tool using this technique. however, there have been some difficulties in taking the model from examples using a small number of particles to more elaborate and better resolved cases. several improvements that we have implemented are presented here to handle turbulence, the fluid viscosity and density, and a different time-stepping algorithm is used. the final model is shown to be able to model breaking waves on beaches in two and three dimensions, green water overtopping of decks, and wave-structure interaction."
304051,article,j neurophysiol,,,,17,94,1,2005,jul,2006-10-19 00:21:20,"neuroscience training program, university of wisconsin, 6001 research park boulevard, madison, wisconsin 53719-1176, usa.",modeling the effects of transcranial magnetic stimulation on cortical circuits.,"transcranial magnetic stimulation ({tms}) is commonly used to activate or inactivate specific cortical areas in a noninvasive manner. because of technical constraints, the precise effects of {tms} on cortical circuits are difficult to assess experimentally. here, this issue is investigated by constructing a detailed model of a portion of the thalamocortical system and examining the effects of the simulated delivery of a {tms} pulse. the model, which incorporates a large number of physiological and anatomical constraints, includes 33,000 spiking neurons arranged in a 3-layered motor cortex and over 5 million intra- and interlayer synaptic connections. the model was validated by reproducing several results from the experimental literature. these include the frequency, timing, dose response, and pharmacological modulation of epidurally recorded responses to {tms} (the so-called i-waves), as well as paired-pulse response curves consistent with data from several experimental studies. the modeled responses to simulated {tms} pulses in different experimental paradigms provide a detailed, self-consistent account of the neural and synaptic activities evoked by {tms} within prototypical cortical circuits."
10550993,article,the annals of applied statistics,,,,27,5,3,2011,,2012-04-10 04:26:25,,measuring reproducibility of high-throughput experiments,
5309100,inproceedings,"3g mobile communication technologies, 2001. second international conference on (conf. publ. no. 477)","3g mobile communication technologies, 2001. second international conference on (conf. publ. no. 477)",,,4,,,2001,,2009-07-31 15:41:41,,{crumpet}: creation of user-friendly mobile services personalised for tourism,
2731785,article,nucleic acids research,,,oxford university press,10,35,13,2007,jul,2008-04-29 05:53:44,,nearest-neighbor non-additivity versus long-range non-additivity in {tata}-box structure and its implications for {tbp}-binding mechanism,"{tbp} recognizes its target sites, {tata} boxes, by recognizing their sequence-dependent structure and flexibility. studying this mode of {tata}-box recognition, termed 'indirect readout', is important for elucidating the binding mechanism in this system, as well as for developing methods to locate new binding sites in genomic {dna}. we determined the binding stability and {tbp}-induced {tata}-box bending for consensus-like {tata} boxes. in addition, we calculated the individual information score of all studied sequences. we show that various non-additive effects exist in {tata} boxes, dependent on their structural properties. by several criterions, we divide {tata} boxes to two main groups. the first group contains sequences with 3?4 consecutive adenines. sequences in this group have a rigid context-independent cooperative structure, best described by a nearest-neighbor non-additive model. sequences in the second group have a flexible, context-dependent conformation, which cannot be described by an additive model or by a nearest-neighbor non-additive model. classifying {tata} boxes by these and other structural rules clarifies the different recognition pathways and binding mechanisms used by {tbp} upon binding to different {tata} boxes. we discuss the structural and evolutionary sources of the difficulties in predicting new binding sites by probabilistic weight-matrix methods for proteins in which indirect readout is dominant."
3171485,book,,,,consulting psychologists press,,,,1978,,2008-08-29 10:20:40,palo alto,facial action coding system: a technique for the measurement of facial movement.,
4546116,article,archives of dermatology,,,,3,145,1,2009,jan,2009-05-19 22:48:41,,minocycline-induced drug hypersensitivity syndrome followed by multiple autoimmune sequelae.,
2515159,article,gene,,,,9,301,1-2,2002,nov,2008-03-11 14:35:17,"sars international centre for marine molecular biology, bergen high technology centre, thorm{\o}hlensgt. 55, n-5008, bergen, norway.","gene structure and expression of {cg-alr1}, a type i activin-like receptor from the bivalve mollusc crassostrea gigas.","members of the transforming growth factor beta superfamily of cell signaling polypeptides have attracted much attention because of their ability, from nematodes to mammals, to control cellular functions that in turn, regulate embryo development and tissue homeostasis (the transforming growth factors betas 95 (1990) 419). to understand the divergent evolution of the structures and functions of the transforming growth factor beta receptors (superfamily) we report here the cloning and characterization of an activin-like type i receptor gene from the oyster crassostrea gigas ({cgalr1}). this 6 kb gene encodes a 534 amino acid long protein consisting of a signal peptide, an extracellular ligand binding domain, a transmembrane region and an intracellular domain. the intracellular domain contains sequence motifs such as the {gs} box and {eif}/v and {rikktl} boxes that are thought to be hallmarks of activin type i receptors. the protein sequence shares 67\% amino acid identity with other serine/threonine kinase receptors in the most conserved kinase domain and 47-49\% similarity with vertebrate type i receptors. the temporal expression pattern of {cgalr1} transcripts was examined during early larval developmental stages. to gain insight into evolutionary diversification, phylogenetic analysis as well as an investigation of the genomic structure, including the promoter region of the {cgalr1} gene were carried out."
9698131,inproceedings,,proceedings of the acm sigcomm 2009 conference on data communication,sigcomm,acm,11,,,2009,,2011-08-23 03:24:58,"new york, ny, usa","{bcube}: a high performance, server-centric network architecture for modular data centers","this paper presents {bcube}, a new network architecture specifically designed for shipping-container based, modular data centers. at the core of the {bcube} architecture is its server-centric network structure, where servers with multiple network ports connect to multiple layers of {cots} (commodity off-the-shelf) mini-switches. servers act as not only end hosts, but also relay nodes for each other. {bcube} supports various bandwidth-intensive applications by speeding-up one-to-one, one-to-several, and one-to-all traffic patterns, and by providing high network capacity for all-to-all traffic. {bcube} exhibits graceful performance degradation as the server and/or switch failure rate increases. this property is of special importance for shipping-container data centers, since once the container is sealed and operational, it becomes very difficult to repair or replace its components. our implementation experiences show that {bcube} can be seamlessly integrated with the {tcp}/{ip} protocol stack and {bcube} packet forwarding can be efficiently implemented in both hardware and software. experiments in our testbed demonstrate that {bcube} is fault tolerant and load balancing and it significantly accelerates representative bandwidth-intensive applications."
9449372,incollection,,,,cambridge university press,37,,,1990,,2011-06-22 18:46:13,,conceptualizing wisdom: the primacy of affect-cognition relations,
634118,incollection,,"digital libraries: policy, planning, and practice",,ashgate publishing,,,,2004,,2006-05-14 19:23:54,,networked digital library of theses and dissertations,
6658356,article,"robotics and automation, ieee transactions on",,,,11,18,4,2002,dec,2010-02-12 17:53:11,,distributed computing in robotics and automation,"the pervasive introduction of the internet into robotics and automation systems pushes forward an evolution that began when the computer was introduced in the enterprise in the middle of the last century, and that continued. with the interconnection of shop-floor workstations in local networks in the 1980s. today, the internet represents a challenge both for research and development in the area of distributed robotics and automation. in order to gain a better understanding and evaluation of results in distributed computing the paper classifies the most promising technological approaches, provides examples of how they are applied in robotics and automation, and discusses available standards and commercial solutions."
139985,article,bioinformatics,,,,1,20,1,2004,jan,2005-03-25 16:56:54,"department of computer science and information engineering, national cheng kung university, tainan 701, taiwan, roc. jchiang@mail.ncku.edu.tw",{gis}: a biomedical text-mining system for gene information discovery,"summary: we present a biomedical text-mining system focused on four types of gene-related information: biological functions, associated diseases, related genes and gene?gene relations. the aim of this system is to provide researchers an easy-to-use bio-information service that will rapidly survey the rapidly burgeoning biomedical {literature.availability}: http://iir.csie.ncku.edu.tw/\~{}yuhc/gis/"
2348579,article,journal of molecular biology,,,,19,323,2,2002,oct,2008-02-07 10:28:07,,a new method to detect related function among proteins independent of sequence and fold homology,"a new method has been developed to detect functional relationships among proteins independent of a given sequence or fold homology. it is based on the idea that protein function is intimately related to the recognition and subsequent response to the binding of a substrate or an endogenous ligand in a well-characterized binding pocket. thus, recognition of similar ligands, supposedly linked to similar function, requires conserved recognition features exposed in terms of common physicochemical interaction properties  via  the functional groups of the residues flanking a particular binding cavity. following a technique commonly used in the comparison of small molecule ligands, generic pseudocenters coding for possible interaction properties were assigned for a large sample set of cavities extracted from the entire {pdb} and stored in the database cavbase. using a particular query cavity a series of related cavities of decreasing similarity is detected based on a clique detection algorithm. the detected similarity is ranked according to property-based surface patches shared in common by the different clique solutions. the approach either retrieves protein cavities accommodating the same (e.g. co-factors) or closely related ligands or it extracts proteins exhibiting similar function in terms of a related catalytic mechanism. finally the new method has strong potential to suggest alternative molecular skeletons in  de novo  design. the retrieval of molecular building blocks accommodated in a particular sub-pocket that shares similarity with the pocket in a protein studied by drug design can inspire the discovery of novel ligands."
