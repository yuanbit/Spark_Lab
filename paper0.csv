12832332,inbook,,foreign aid and the making of democracy in nepal,,alliance for aid monitor nepal,29,,,2013,dec,2013-12-14 09:30:14,,deepening democracy at the local level,"local governance bodies ({lgbs}) have been part and parcel of the nepalese people for more than five decades. for nearly all nepa­lese people, the most familiar public organization is one of two local governance bodies, i.e. village development committee ({vdc}) in rural areas or municipalities in urban areas and the district development committee at the district level. since 1997 there has been no election to these bodies and upon completion of the five year term of the representatives elected in july 2002, are being run and managed by government employees. the government funding support to the {lgbs} has, however, been an increasing trend. another major program, the local governance and community development program ({lgcdp}) has been under implementation since 2008 with the support of a number of donors. activities related to demand-strengthening and citizen empowerment, especially the marginalized sections of the society in the planning process of the {lgbs}, are the important components of this program. the ward citizen forum ({wcf}) and the citizen awareness center ({cac}) are institutional arrangements made at the {vdc} and municipality under this component. in this paper the {wcf} and {cac} have been dealt with in the context of the planning process of the {lgbs}, on the basis of available literature and quick field study of two {vdcs} (one each from the district of kathmandu and bhaktapur) and one municipality of the kavre district, all belonging to the central development region of the country, a limitation of the paper in itself."
1305474,misc,,,,,,,,2002,,2007-05-18 16:14:16,,the {tesla} broadcast authentication protocol,"one of the main challenges of securing broadcast communication is source authentication, or enabling receivers of broadcast data to verify that the received data really originates from the claimed source and was not modified en route. this problem is complicated by mutually untrusted receivers and unreliable communication environments where the sender does not retransmit lost packets."
1001231,proceedings,infocom 2005. 24th annual joint conference of the ieee computer and communications societies. proceedings ieee,,,,,3,,2005,,2006-12-19 01:28:53,,anonymous communications in mobile ad hoc networks,"due to the broadcast nature of radio transmissions, communications in mobile ad hoc networks ({manets}) are more susceptible to malicious traffic analysis. in this paper we propose a novel anonymous on-demand routing protocol, termed {mask}, to enable anonymous communications thereby thwarting possible traffic analysis attacks. based on a new cryptographic concept called pairing, we first propose an anonymous neighborhood authentication protocol which allows neighboring nodes to authenticate each other without revealing their identities. then utilizing the secret pairwise link identifiers and keys established between neighbors during the neighborhood authentication process, {mask} fulfills the routing and packet forwarding tasks nicely without disclosing the identities of participating nodes under a rather strong adversarial model. {mask} provides the desirable sender and receiver anonymity, as well as the relationship anonymity of the sender and receiver. it is also resistant to a wide range of adversarial attacks. moreover, {mask} preserves the routing efficiency in contrast to previous proposals. detailed anonymity analysis and simulation studies are carried out to validate and justify the effectiveness of {mask}."
352713,misc,ieee communications magazine,,,,12,,,2002,aug,2007-05-30 11:47:53,,a survey on sensor networks,"recent advancement in wireless communica- tions and electronics has enabled the develop- ment of low-cost sensor networks. the sensor networks can be used for various application areas (e.g., health, military, home). for different application areas, there are different technical issues that researchers are currently resolving. the current state of the art of sensor networks is captured in this article, where solutions are discussed under their related protocol stack layer sections. this article ..."
956315,article,"selected areas in communications, ieee journal on",,,ieee,10,24,2,2006,feb,2006-11-22 03:22:00,,wormhole attacks in wireless networks,"as mobile ad hoc network applications are deployed, security emerges as a central requirement. in this paper, we introduce the wormhole attack, a severe attack in ad hoc networks that is particularly challenging to defend against. the wormhole attack is possible even if the attacker has not compromised any hosts, and even if all communication provides authenticity and confidentiality. in the wormhole attack, an attacker records packets (or bits) at one location in the network, tunnels them (possibly selectively) to another location, and retransmits them there into the network. the wormhole attack can form a serious threat in wireless networks, especially against many ad hoc network routing protocols and location-based wireless security systems. for example, most existing ad hoc network routing protocols, without some mechanism to defend against the wormhole attack, would be unable to find routes longer than one or two hops, severely disrupting communication. we present a general mechanism, called packet leashes, for detecting and, thus defending against wormhole attacks, and we present a specific protocol, called {tik}, that implements leashes. we also discuss topology-based wormhole detection, and show that it is impossible for these approaches to detect some wormhole topologies."
945604,inproceedings,infocom 2003. twenty-second annual joint conference of the ieee computer and communications. ieee societies,infocom 2003. twenty-second annual joint conference of the ieee computer and communications. ieee societies,,ieee,,3,,2003,mar,2006-11-16 04:19:13,,packet leashes: a defense against wormhole attacks in wireless networks,"as mobile ad hoc network applications are deployed, security emerges as a central requirement. in this paper, we introduce the wormhole attack, a severe attack in ad hoc networks that is particularly challenging to defend against. the wormhole attack is possible even if the attacker has not compromised any hosts, and even if all communication provides authenticity and confidentiality. in the wormhole attack, an attacker records packets (or bits) at one location in the network, tunnels them (possibly selectively) to another location, and retransmits them there into the network. the wormhole attack can form a serious threat in wireless networks, especially against many ad hoc network routing protocols and location-based wireless security systems. for example, most existing ad hoc network routing protocols, without some mechanism to defend against the wormhole attack, would be unable to find routes longer than one or two hops, severely disrupting communication. we present a new, general mechanism, called packet leashes, for detecting and thus defending against wormhole attacks, and we present a specific protocol, called {tik}, that implements leashes."
10294999,article,,,,,,,,2012,feb,2012-02-02 10:28:55,,a 2\% distance to z = 0.35 by reconstructing baryon acoustic oscillations - {iii} : cosmological measurements and interpretation,
967275,inproceedings,"security and privacy for emerging areas in communications networks, 2005. securecomm 2005. first international conference on","security and privacy for emerging areas in communications networks, 2005. securecomm 2005. first international conference on",,ieee,11,,,2005,,2006-11-29 18:51:32,,on the survivability of routing protocols in ad hoc wireless networks,"survivable routing protocols are able to provide service in the presence of attacks and failures. the strongest attacks that protocols can experience are attacks where adversaries have full control of a number of authenticated nodes that behave arbitrarily to disrupt the network, also referred to as byzantine attacks. this work examines the survivability of ad hoc wireless routing protocols in the presence of several byzantine attacks: black holes, flood rushing, wormholes and overlay network wormholes. traditional secure routing protocols that assume authenticated nodes can always be trusted, fail to defend against such attacks. our protocol, {odsbr}, is an on-demand wireless routing protocol able to provide correct service in the presence of failures and byzantine attacks. we demonstrate through simulation its effectiveness in mitigating such attacks. our analysis of the impact of these attacks versus the adversarys effort gives insights into their relative strengths, their interaction and their importance when designing wireless routing protocols."
115945,article,"bioessays : news and reviews in molecular, cellular and developmental biology",,,"wiley subscription services, inc., a wiley company",11,27,3,2005,mar,2005-03-07 02:40:55,"department of biology, washington university, campus box 1229, st. louis, mo 63130, usa.",a twelve-step program for evolving multicellularity and a division of labor.,"the volvocine algae provide an unrivalled opportunity to explore details of an evolutionary pathway leading from a unicellular ancestor to multicellular organisms with a division of labor between different cell types. members of this monophyletic group of green flagellates range in complexity from unicellular chlamydomonas through a series of extant organisms of intermediate size and complexity to volvox, a genus of spherical organisms that have thousands of cells and a germ-soma division of labor. it is estimated that these organisms all shared a common ancestor about 50 +/- 20 {mya}. here we outline twelve important ways in which the developmental repertoire of an ancestral unicell similar to modern c. reinhardtii was modified to produce first a small colonial organism like gonium that was capable of swimming directionally, then a sequence of larger organisms (such as pandorina, eudorina and pleodorina) in which there was an increasing tendency to differentiate two cell types, and eventually volvox carteri with its complete germ-soma division of labor."
11733005,article,genome biology and evolution,,,oxford university press,7,4,7,2012,jan,2012-11-20 13:31:29,,evidence for widespread {gc}-biased gene conversion in eukaryotes,"{gc}-biased gene conversion ({gbgc}) is a process that tends to increase the {gc} content of recombining {dna} over evolutionary time and is thought to explain the evolution of {gc} content in mammals and yeasts. evidence for {gbgc} outside these two groups is growing but is still limited. here, we analyzed 36 completely sequenced genomes representing four of the five major groups in eukaryotes (unikonts, excavates, chromalveolates and plantae). {gbgc} was investigated by directly comparing {gc} content and recombination rates in species where recombination data are available, that is, half of them. to study all species of our dataset, we used chromosome size as a proxy for recombination rate and compared it with {gc} content. among the 17 species showing a significant relationship between {gc} content and chromosome size, 15 are consistent with the predictions of the {gbgc} model. importantly, the species showing a pattern consistent with {gbgc} are found in all the four major groups of eukaryotes studied, which suggests that {gbgc} may be widespread in eukaryotes."
9045137,article,annals of botany,,,,24,99,4,2007,apr,2011-03-22 23:55:46,,nuclear {dna} content estimates in green algal lineages: chlorophyta and streptophyta,"background and aims consensus higher-level molecular phylogenies present a compelling case that an ancient divergence separates eukaryotic green algae into two major monophyletic lineages, chlorophyta and streptophyta, and a residuum of green algae, which have been referred to prasinophytes or micromonadophytes. nuclear {dna} content estimates have been published for less than 1\% of the described green algal members of chlorophyta, which includes multicellular green marine algae and freshwater flagellates (e.g. chlamydomonas and volvox). the present investigation summarizes the state of our knowledge and adds substantially to our database of c-values, especially for the streptophyte charophycean lineage which is the sister group of the land plants. a recent list of {2c} nuclear {dna} contents for isolates and species of green algae is expanded by 72 to {157.methods} the {dna}-localizing fluorochrome {dapi} (4′,6-diamidino-2-phenylindole) and red blood cell (chicken erythrocytes) standard were used to estimate {2c} values with static {microspectrophotometry.key} results in chlorophyta, including chlorophyceae, prasinophyceae, trebouxiophyceae and ulvophyceae, {2c} {dna} estimates range from 0·01 to 5·8 pg. nuclear {dna} content variation trends are noted and discussed for specific problematic taxon pairs, including {ulotrichales–ulvales}, and {cladophorales–siphonocladales}. for streptophyta, {2c} nuclear {dna} contents range from 0·2 to 6·4 pg, excluding the highly polyploid charales and desmidiales, which have genome sizes of up to 14·8 and 46·8 pg, respectively. nuclear {dna} content data for streptophyta superimposed on a contemporary molecular phylogeny indicate that early diverging lineages, including some members of chlorokybales, coleochaetales and klebsormidiales, have genomes as small as 0·1–0·5 pg. it is proposed that the streptophyte ancestral nuclear genome common to both the charophyte and the embryophyte lineages can be characterized as {1c} = 0·2 pg and 1n = {6.conclusions} these data will help pre-screen candidate species for the on-going construction of bacterial artificial chromosome nuclear genome libraries for land plant ancestors. data for the prasinophyte mesostigma are of particular interest as this alga reportedly most closely resembles the 'ancestral green flagellate'. both mechanistic and ecological processes are discussed that could have produced the observed c-value increase of >100-fold in the charophyte green algae whereas the ancestral genome was conserved in the embryophytes."
3728173,article,proceedings of the national academy of sciences,,,national academy of sciences,5,104,Suppl 1,2007,may,2008-11-29 20:58:14,,evolution of individuality during the transition from unicellular to multicellular life,"individuality is a complex trait, yet a series of stages each advantageous in itself can be shown to exist allowing evolution to get from unicellular individuals to multicellular individuals. we consider several of the key stages involved in this transition: the initial advantage of group formation, the origin of reproductive altruism within the group, and the further specialization of cell types as groups increase in size. how do groups become individuals? this is the central question we address. our hypothesis is that fitness tradeoffs drive the transition of a cell group into a multicellular individual through the evolution of cells specialized at reproductive and vegetative functions of the group. we have modeled this hypothesis and have tested our models in two ways. we have studied the origin of the genetic basis for reproductive altruism (somatic cells specialized at vegetative functions) in the multicellular volvox carteri by showing how an altruistic gene may have originated through cooption of a life-history tradeoff gene present in a unicellular ancestor. second, we ask why reproductive altruism and individuality arise only in the larger members of the volvocine group (recognizing that high levels of kinship are present in all volvocine algae groups). our answer is that the selective pressures leading to reproductive altruism stem from the increasing cost of reproduction with increasing group size. concepts from population genetics and evolutionary biology appear to be sufficient to explain complexity, at least as it relates to the problem of the major transitions between the different kinds of evolutionary individuals."
8310458,article,evolution,,,blackwell publishing inc,15,62,2,2008,,2010-11-26 15:46:08,,evolution of complexity in the volvocine algae: transitions in individuality through darwin's eye,"the transition from unicellular to differentiated multicellular organisms constitutes an increase in the level complexity, because previously existing individuals are combined to form a new, higher-level individual. the volvocine algae represent a unique opportunity to study this transition because they diverged relatively recently from unicellular relatives and because extant species display a range of intermediate grades between unicellular and multicellular, with functional specialization of cells. following the approach darwin used to understand  ” organs of extreme perfection” such as the vertebrate eye, this jump in complexity can be reduced to a series of small steps that cumulatively describe a gradual transition between the two levels. we use phylogenetic reconstructions of ancestral character states to trace the evolution of steps involved in this transition in volvocine algae. the history of these characters includes several well-supported instances of multiple origins and reversals. the inferred changes can be understood as components of cooperation–conflict–conflict mediation cycles as predicted by multilevel selection theory. one such cycle may have taken place early in volvocine evolution, leading to the highly integrated colonies seen in extant volvocine algae. a second cycle, in which the defection of somatic cells must be prevented, may still be in progress."
80546,article,biology and philosophy,,,,17,19,2,2004,mar,2005-01-26 21:35:21,,the arbitrariness of the genetic code,"the genetic code has been regarded as arbitrary in the sense that the codon-amino acid assignments could be different than they actually are. this general idea has been spelled out differently by previous, often rather implicit accounts of arbitrariness. they have drawn on the frozen accident theory, on evolutionary contingency, on alternative causal pathways, and on the absence of direct stereochemical interactions between codons and amino acids. it has also been suggested that the arbitrariness of the genetic code justifies attributing semantic information to macromolecules, notably to {dna}. i argue that these accounts of arbitrariness are unsatisfactory. i propose that the code is arbitrary in the sense of jacques monod's concept of chemical arbitrariness: the genetic code is arbitrary in that any codon requires certain chemical and structural properties to specify a particular amino acid, but these properties are not required in virtue of a principle of chemistry. this notion of arbitrariness is compatible with several recent hypotheses about code evolution. i maintain that the code's chemical arbitrariness is neither sufficient nor necessary for attributing semantic information to nucleic acids."
5842862,article,molecular cell,,,elsevier,2,35,6,2009,sep,2009-09-30 17:11:23,,how to choose a good scientific problem,"choosing good problems is essential for being a good scientist. but what is a good problem, and how do you choose one? the subject is not usually discussed explicitly within our profession. scientists are expected to be smart enough to figure it out on their own and through the observation of their teachers. this lack of explicit discussion leaves a vacuum that can lead to approaches such as choosing problems that can give results that merit publication in valued journals, resulting in a job and tenure."
1242600,article,oikos,,,blackwell publishing ltd,4,116,5,2007,may,2007-05-01 11:06:49,,how to write consistently boring scientific literature,"although scientists typically insist that their research is very exciting and adventurous when they talk to laymen and prospective students, the allure of this enthusiasm is too often lost in the predictable, stilted structure and language of their scientific publications. i present here, a top-10 list of recommendations for how to write consistently boring scientific publications. i then discuss why we should and how we could make these contributions more accessible and exciting."
3467077,article,plos computational biology,,,public library of science,,4,10,2008,oct,2008-10-30 23:02:02,,defrosting the digital library: bibliographic tools for the next generation web.,"many scientists now manage the bulk of their bibliographic information electronically, thereby organizing their publications and citation material from digital libraries. however, a library has been described as ""thought in cold storage,"" and unfortunately many digital libraries can be cold, impersonal, isolated, and inaccessible places. in this review, we discuss the current chilly state of digital libraries for the computational biologist, including {pubmed}, {ieee} xplore, the {acm} digital library, {isi} web of knowledge, scopus, citeseer, {arxiv}, {dblp}, and google scholar. we illustrate the current process of using these libraries with a typical workflow, and highlight problems with managing data and metadata using {uris}. we then examine a range of new applications such as zotero, mendeley, mekentosj papers, {myncbi}, {citeulike}, connotea, and {hubmed} that exploit the web to make these digital libraries more personal, sociable, integrated, and accessible places. we conclude with how these applications may begin to help achieve a digital defrost, and discuss some of the issues that will help or hinder this in terms of making libraries on the web warmer places in the future, becoming resources that are considerably more useful to both humans and machines."
309395,article,plos medicine,,,public library of science,,2,8,2005,aug,2005-09-15 01:16:48,,why most published research findings are false,"there is increasing concern that most current published research findings are false. the probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. in this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. in this essay, i discuss the implications of these problems for the conduct and interpretation of research."
305755,article,,,,,,,,2005,aug,2005-08-27 18:07:09,,the structure of collaborative tagging systems,
6603134,article,mol cell,,,cell press,1,37,2,2010,jan,2010-01-29 11:33:17,,how to build a motivated research group,"motivated group members experience a full sense of choice: of doing what one wants. such behavior shows high performance, is enjoyable, and enhances innovation. this essay describes principles of building a motivated research group."
99,article,nature,,,nature publishing group,2,393,6684,1998,jun,2004-11-07 13:58:29,"department of theoretical and applied mechanics, cornell university, ithaca, new york 14853, usa. djw24@columbia.edu",collective dynamics of 'small-world' networks,"networks of coupled dynamical systems have been used to model biological oscillators1, 2, 3, 4, josephson junction arrays5,6, excitable media7, neural networks8, 9, 10, spatial games11, genetic control networks12 and many other self-organizing systems. ordinarily, the connection topology is assumed to be either completely regular or completely random. but many biological, technological and social networks lie somewhere between these two extremes. here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. we find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. we call them 'small-world' networks, by analogy with the small-world phenomenon13,14 (popularly known as six degrees of separation15). the neural network of the worm caenorhabditis elegans, the power grid of the western united states, and the collaboration graph of film actors are shown to be small-world networks. models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. in particular, infectious diseases spread more easily in small-world networks than in regular lattices."
105595,book,,,,plume,,,,2003,apr,2005-02-27 02:23:03,,linked: how everything is connected to everything else and what it means,how is the human brain like the {aids} epidemic? ask physicist {albert-l\'{a}szl\'{o
212874,article,nature genetics,,,nature publishing group,4,25,1,2000,may,2005-05-27 13:30:37,"department of genetics, stanford university school of medicine, california, usa. cherry@stanford.edu",gene ontology: tool for the unification of biology. the gene ontology consortium.,"genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. the goal of the gene ontology consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. to this end, three independent ontologies accessible on the {world-wide} web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component."
740681,article,journal of information science,,,sage publications,10,32,2,2006,apr,2006-07-05 18:36:15,"thousand oaks, ca, usa",usage patterns of collaborative tagging systems,"collaborative tagging describes the process by which many users add metadata in the form of keywords to shared content. recently, collaborative tagging has grown in popularity on the web, on sites that allow users to tag bookmarks, photographs and other content. in this paper we analyze the structure of collaborative tagging systems as well as their dynamic aspects. specifically, we discovered regularities in user activity, tag frequencies, kinds of tags used, bursts of popularity in bookmarking and a remarkable stability in the relative proportions of tags within a given {url}. we also present a dynamic model of collaborative tagging that predicts these stable patterns and relates them to imitation and shared knowledge."
101,article,science,,,american association for the advancement of science,3,298,5594,2002,oct,2004-11-08 11:27:57,"departments of physics of complex systems and molecular cell biology, weizmann institute of science, rehovot, israel 76100.",network motifs: simple building blocks of complex networks,"complex networks are studied across many fields of science. to uncover their structural design principles, we defined  ” network motifs,” patterns of interconnections occurring in complex networks at numbers that are significantly higher than those in randomized networks. we found such motifs in networks from biochemistry, neurobiology, ecology, and engineering. the motifs shared by ecological food webs were distinct from the motifs shared by the genetic networks of escherichia coli and saccharomyces cerevisiae or from those found in the world wide web. similar motifs were found in networks that perform information processing, even though they describe elements as different as biomolecules within a cell and synaptic connections between neurons in caenorhabditis elegans. motifs may thus define universal classes of networks. this approach may uncover the basic building blocks of most networks."
99857,article,american journal of sociology,,,the university of chicago press,20,78,6,1973,,2005-02-20 23:48:01,,the strength of weak ties,"analysis of social networks is suggested as a tool for linking micro and macro levels of sociological theory. the procedure is illustrated by elaboration of the macro implications of one aspect of small-scale interaction: the strength of dyadic ties. it is argued that the degree of overlap of two individuals' friendship networks varies directly with the strength of their tie to one another. the impact of this principle on diffusion of influence and information, mobility opportunity, and community organization is explored. stress is laid on the cohesive power of weak ties. most network models deal, implicitly, with strong ties, thus confining their applicability to small, well-defined groups. emphasis on weak ties lends itself to discussion of relations between groups and to analysis of segments of social structure not easily defined in terms of primary groups."
3614773,article,nature reviews genetics,,,nature publishing group,6,10,1,2009,jan,2008-11-20 17:50:25,,{rna}-seq: a revolutionary tool for transcriptomics,"{rna}-seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. {rna}-seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. this article describes the {rna}-seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
873540,book,,,,springer,,,,2006,oct,2006-09-26 18:44:17,,pattern recognition and machine learning,"the field of pattern recognition has undergone substantial development over the years. this book reflects these developments while providing a grounding in the basic concepts of pattern recognition and machine learning. it is aimed at advanced undergraduates or first year {phd} students, as well as researchers and practitioners."
6434100,article,plos comput biol,,,public library of science,,5,12,2009,dec,2009-12-24 05:57:41,,a quick guide for developing effective bioinformatics programming skills,
100088,article,journal of molecular biology,,,,7,215,3,1990,oct,2005-02-21 16:47:05,"national center for biotechnology information, national library of medicine, national institutes of health, bethesda, md 20894.",basic local alignment search tool.,"a new approach to rapid sequence comparison, basic local alignment search tool ({blast}), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair ({msp}) score. recent mathematical results on the stochastic properties of {msp} scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. the basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straightforward {dna} and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long {dna} sequences. in addition to its flexibility and tractability to mathematical analysis, {blast} is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity."
1387765,article,siam review,,,,42,51,4,2009,feb,2007-06-13 17:29:15,,power-law distributions in empirical data,
161814,book,,,,springer,,,,2003,jul,2005-04-15 15:57:22,,the elements of statistical learning,
117535,article,journal of the royal statistical society. series b (methodological),,,blackwell publishing for the royal statistical society,37,39,1,1977,,2005-03-08 19:21:57,,maximum likelihood from incomplete data via the {em} algorithm,"a broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis."
5307378,article,plos computational biology,plos comput biol,,public library of science,,5,7,2009,jul,2009-07-31 09:14:26,,a quick guide to organizing computational biology projects,
361498,article,,,,,,,,2005,sep,2005-10-22 11:31:35,,folksonomy as a complex network,
3283,techreport,,,,,,,,1998,,2004-12-13 09:25:46,,the {pagerank} citation ranking: bringing order to the web,"the importance of a web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. but there is still much that can be said objectively about the relative importance of web pages. this paper describes {pagerank}, a method for rating web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. we compare {pagerank} to an idealized random web surfer. we show how to efficiently compute {pagerank} for large..."
4131662,article,genome biology,genome biology,,biomed central ltd,-15,10,3,2009,mar,2009-03-04 11:12:15,,ultrafast and memory-efficient alignment of short {dna} sequences to the human genome,"bowtie is an ultrafast, memory-efficient alignment program for aligning short {dna} sequence reads to large genomes. for the human genome, {burrows-wheeler} indexing allows bowtie to align more than 25 million reads per {cpu} hour with a memory footprint of approximately 1.3 gigabytes. bowtie extends previous {burrows-wheeler} techniques with a novel quality-aware backtracking algorithm that permits mismatches. multiple processor cores can be used simultaneously to achieve even greater alignment speeds. bowtie is open source http://bowtie.cbcb.umd.edu."
115158,book,,,,addison-wesley professional,,,,1994,jan,2005-03-06 00:48:06,,design patterns: elements of reusable {object-oriented} software,"<{i>design} {patterns</i}> is a modern classic in the literature of object-oriented development, offering timeless and elegant solutions to common problems in software design. it describes patterns for managing object creation, composing objects into larger structures, and coordinating control flow between objects. the book provides numerous examples where using composition rather than inheritance can improve the reusability and flexibility of code. note, though, that it's not a tutorial but a catalog that you can use to find an object-oriented design pattern that's appropriate for the needs of your particular application--a selection for virtuoso programmers who appreciate (or require) consistent, well-engineered object-oriented designs. now on {cd}, this internationally acclaimed bestseller is more valuable than ever! <p> use the contents of the {cd} to create your own design documents and reusable components. the {cd} contains: 23 patterns you can cut and paste into your own design documents; sample code demonstrating pattern implementation; complete design patterns content in standard {html} format, with numerous hyperlinked cross-references; accessed through a standard web browser; java-based dynamic search mechanism, enhancing online seach capabilities; graphical user environment, allowing ease of navigation. <p> first published in 1995, this landmark work on object-oriented software design presents a catalog of simple and succinct solutions to common design problems. created by four experienced designers, the 23 patterns contained herein have become an essential resource for anyone developing reusable object-oriented software. in response to reader demand, the complete text and pattern catalog are now available on {cd}-{rom}. this electronic version of <{i>design} patterns</i> enables programmers to install the book directly onto a computer or network for use as an online reference for creating reusable object-oriented software. <p> the authors first describe what patterns are and how they can help you in the design process. they then systematically name, explain, evaluate, and catalog recurring designs in object-oriented systems. all patterns are compiled from real-world examples and include code that demonstrates how they may be implemented in object-oriented programming languages such as c++ and smalltalk. readers who already own the book will want the {cd} to take advantage of its dynamic search mechanism and ready-to-install patterns."
5662136,article,plos comput biol,,,public library of science,,5,8,2009,aug,2009-08-28 08:29:46,,a quick guide to teaching r programming to computational biology students,
816066,inproceedings,,proceedings of the seventeenth conference on hypertext and hypermedia,hypertext,acm,9,,,2006,,2006-08-24 21:17:15,"new york, ny, usa","{ht06}, tagging paper, taxonomy, flickr, academic article, to read","in recent years, tagging systems have become increasingly popular. these systems enable users to add keywords (i.e., ""tags"") to internet resources (e.g., web pages, images, videos) without relying on a controlled vocabulary. tagging systems have the potential to improve search, spam detection, reputation systems, and personal organization while introducing new modalities of social communication and opportunities for data mining. this potential is largely due to the social structure that underlies many of the current {systems.despite} the rapid expansion of applications that support tagging of resources, tagging systems are still not well studied or understood. in this paper, we provide a short description of the academic related work to date. we offer a model of tagging systems, specifically in the context of web-based systems, to help us illustrate the possible benefits of these tools. since many such systems already exist, we provide a taxonomy of tagging systems to help inform their analysis and design, and thus enable researchers to frame and compare evidence for the sustainability of such systems. we also provide a simple taxonomy of incentives and contribution models to inform potential evaluative frameworks. while this work does not present comprehensive empirical results, we present a preliminary study of the photo-sharing and tagging system flickr to demonstrate our model and explore some of the issues in one sample system. this analysis helps us outline and motivate possible future directions of research in tagging systems."
10132366,article,science,,,american association for the advancement of science,6,334,6062,2011,dec,2011-12-15 21:05:31,,detecting novel associations in large data sets,"identifying interesting relationships between pairs of variables in large data sets is increasingly important. here, we present a measure of dependence for two-variable relationships: the maximal information coefficient ({mic}). {mic} captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (r(2)) of the data relative to the regression function. {mic} belongs to a larger class of maximal information-based nonparametric exploration ({mine}) statistics for identifying and classifying relationships. we apply {mic} and {mine} to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships."
1688531,article,faseb journal,,,federation of american societies for experimental biology,4,22,2,2008,feb,2007-09-24 07:31:33,"*alfa institute of biomedical sciences, athens, greece;department of medicine, tufts university school of medicine, boston, massachusetts, usa; andinstitute of continuing medical education of ioannina, ioannina, greece.","comparison of {pubmed}, scopus, web of science, and google scholar: strengths and weaknesses.","the evolution of the electronic age has led to the development of numerous medical databases on the world wide web, offering search facilities on a particular subject and the ability to perform citation analysis. we compared the content coverage and practical utility of {pubmed}, scopus, web of science, and google scholar. the official web pages of the databases were used to extract information on the range of journals covered, search facilities and restrictions, and update frequency. we used the example of a keyword search to evaluate the usefulness of these databases in biomedical information retrieval and a specific published article to evaluate their utility in performing citation analysis. all databases were practical in use and offered numerous search facilities. {pubmed} and google scholar are accessed for free. the keyword search with {pubmed} offers optimal update frequency and includes online early articles; other databases can rate articles by number of citations, as an index of importance. for citation analysis, scopus offers about 20\% more coverage than web of science, whereas google scholar offers results of inconsistent accuracy. {pubmed} remains an optimal tool in biomedical electronic research. scopus covers a wider journal range, of help both in keyword searching and citation analysis, but it is currently limited to recent articles (published after 1995) compared with web of science. google scholar, as for the web in general, can help in the retrieval of even the most obscure information but its use is marred by inadequate, less often updated, citation information."
70828,article,contemporary physics,,,taylor \& francis,28,46,5,2005,sep,2004-12-29 16:08:54,,"power laws, pareto distributions and zipf's law","when the probability of measuring a particular value of some quantity varies inversely as a power of that value, the quantity is said to follow a power law, also known variously as zipf's law or the pareto distribution. power laws appear widely in physics, biology, earth and planetary sciences, economics and finance, computer science, demography and the social sciences. for instance, the distributions of the sizes of cities, earthquakes, forest fires, solar flares, moon craters and people's personal fortunes all appear to follow power laws. the origin of power-law behaviour has been a topic of debate in the scientific community for more than a century. here we review some of the empirical evidence for the existence of power-law forms and the theories proposed to explain them."
1272533,article,the journal of cell biology,j. cell biol.,,rockefeller university press,4,177,1,2007,apr,2007-05-02 19:37:24,,error bars in experimental biology.,"error bars commonly appear in figures in publications, but experimental biologists are often unsure how they should be used and interpreted. in this article we illustrate some basic features of error bars and explain how they can help communicate data and assist correct interpretation. error bars may show confidence intervals, standard errors, standard deviations, or other quantities. different types of error bars give quite different information, and so figure legends must make clear what error bars represent. we suggest eight simple rules to assist with effective use and interpretation of error bars."
141092,book,,,,cambridge university press,,,,2003,oct,2005-03-26 08:56:53,,"information theory, inference and learning algorithms",
525366,article,proceedings of the national academy of sciences,proceedings of the national academy of sciences of the united states of america,,national academy of sciences,5,102,43,2005,oct,2006-03-01 14:37:54,,gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles,"although genomewide {rna} expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. here, we describe a powerful analytical method called gene set enrichment analysis ({gsea}) for interpreting gene expression data. the method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. we demonstrate how {gsea} yields insights into several cancer-related data sets, including leukemia and lung cancer. notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, {gsea} reveals many biological pathways in common. the {gsea} method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets."
238188,article,nucleic acids research,,,oxford university press,13,25,17,1997,sep,2005-07-18 11:44:05,"national center for biotechnology information, national library of medicine, national institutes of health, bethesda, md 20894, usa. altschul@ncbi.nlm.nih.gov",gapped {blast} and {psi}-{blast}: a new generation of protein database search programs.,"the {blast} programs are widely used tools for searching protein and {dna} databases for sequence similarities. for protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the {blast} programs to be decreased substantially while enhancing their sensitivity to weak similarities. a new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped {blast} program that runs at approximately three times the speed of the original. in addition, a method is introduced for automatically combining statistically significant alignments produced by {blast} into a position-specific score matrix, and searching the database using this matrix. the resulting {position-specific} iterated {blast} ({psi}-{blast}) program runs at approximately the same speed per iteration as gapped {blast}, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. {psi}-{blast} is used to uncover several new and interesting members of the {brct} superfamily."
4778506,article,"bioinformatics (oxford, england)",,,oxford university press,1,25,16,2009,aug,2009-06-09 07:53:59,,the sequence {alignment/map} format and {samtools}.,"the sequence {alignment/map} ({sam}) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 mbp) produced by different sequencing platforms. it is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 genomes project are released. {samtools} implements various utilities for post-processing alignments in the {sam} format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. http://samtools.sourceforge.net."
6397938,article,nature reviews. genetics,,,nature publishing group,15,11,1,2010,jan,2009-12-17 21:44:38,,sequencing technologies - the next generation.,"demand has never been greater for revolutionary technologies that deliver fast, inexpensive and accurate genome information. this challenge has catalysed the development of next-generation sequencing ({ngs}) technologies. the inexpensive production of large volumes of sequence data is the primary advantage over conventional methods. here, i present a technical review of template preparation, sequencing and imaging, genome alignment and assembly approaches, and recent advances in current and near-term commercially available {ngs} instruments. i also outline the broad range of applications for {ngs} technologies, in addition to providing guidelines for platform selection to address biological questions of interest."
155,misc,,,,,,,,2003,mar,2004-11-10 17:13:30,,the structure and function of complex networks,
523772,article,plos comput biol,,,public library of science,,1,5,2005,oct,2006-02-27 19:00:43,,ten simple rules for getting published,
3010240,article,journal of cell science,,,company of biologists,,121,11,2008,jun,2008-07-16 22:25:46,,the importance of stupidity in scientific research,10.1242/jcs.033340
2860398,article,nat meth,nat meth,,nature publishing group,7,5,7,2008,jul,2008-06-12 00:57:36,"[1] division of biology, mc 156-29, california institute of technology, pasadena, california 91125, usa. [2] these authors contributed equally to this work.",mapping and quantifying mammalian transcriptomes by {rna}-seq,"we have mapped and quantified mouse transcriptomes by deeply sequencing them and recording how frequently each gene is represented in the sequence sample ({rna}-seq). this provides a digital measure of the presence and prevalence of transcripts from known and previously unknown genes. we report reference measurements composed of 41-52 million mapped 25-base-pair reads for {poly(a})-selected {rna} from adult mouse brain, liver and skeletal muscle tissues. we used {rna} standards to quantify transcript prevalence and to test the linear range of transcript detection, which spanned five orders of magnitude. although >90\% of uniquely mapped reads fell within known exons, the remaining data suggest new and revised gene models, including changed or additional promoters, exons and 3' untranscribed regions, as well as new candidate {microrna} precursors. {rna} splice events, which are not readily measured by standard gene expression microarray or serial analysis of gene expression methods, were detected directly by mapping splice-crossing sequence reads. we observed 1.45 x 10(5) distinct splices, and alternative splices were prominent, with 3,500 different genes expressing one or more alternate internal splices."
90558,article,science,,,american association for the advancement of science,3,286,5439,1999,oct,2005-06-14 03:29:04,,emergence of scaling in random networks,"systems as diverse as genetic networks or the world wide web are best described as networks with complex topology. a common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. this feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. a model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems."
1206611,article,nature,,,nature publishing group,3,446,7136,2007,apr,2007-04-04 19:39:59,,quantifying social group evolution,"the rich set of interactions between individuals in society1, 2, 3, 4, 5, 6, 7 results in complex community structure, capturing highly connected circles of friends, families or professional cliques in a social network3, 7, 8, 9, 10. thanks to frequent changes in the activity and communication patterns of individuals, the associated social and communication network is subject to constant evolution7, 11, 12, 13, 14, 15, 16. our knowledge of the mechanisms governing the underlying community dynamics is limited, but is essential for a deeper understanding of the development and self-optimization of society as a whole17, 18, 19, 20, 21, 22. we have developed an algorithm based on clique percolation23, 24 that allows us to investigate the time dependence of overlapping communities on a large scale, and thus uncover basic relationships characterizing community evolution. our focus is on networks capturing the collaboration between scientists and the calls between mobile phone users. we find that large groups persist for longer if they are capable of dynamically altering their membership, suggesting that an ability to change the group composition results in better adaptability. the behaviour of small groups displays the opposite tendency—the condition for stability is that their composition remains unchanged. we also show that knowledge of the time commitment of members to a given community can be used for estimating the community's lifetime. these findings offer insight into the fundamental differences between the dynamics of small groups and large institutions."
167581,book,,,,wiley-interscience,,,,2000,nov,2005-04-22 18:33:13,,pattern classification (pt.1),"this edition has been completely revised, enlarged and formatted in two colour. it is a systematic account of the major topics in pattern recognition, based on the fundamental principles. it includes extensive examples, exercises and a solutions manual."
4544032,article,bioinformatics,,,oxford university press,6,25,14,2009,jul,2009-05-19 00:37:13,,fast and accurate short read alignment with {burrows–wheeler} transform,"motivation: the enormous amount of short reads generated by the new {dna} sequencing technologies call for the development of fast and accurate read alignment programs. a first generation of hash table-based methods has been developed, including {maq}, which is accurate, feature rich and fast enough to align short reads from a single individual. however, {maq} does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. the speed of {maq} is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals."
484851,electronic,,,,,,,,2005,dec,2006-01-29 15:41:43,,collaborative tagging as a tripartite network,
2199619,article,oikos,,,blackwell publishing ltd,4,116,5,2007,may,2008-01-06 08:41:21,,how to write consistently boring scientific literature,"although scientists typically insist that their research is very exciting and adventurous when they talk to laymen and prospective students, the allure of this enthusiasm is too often lost in the predictable, stilted structure and language of their scientific publications. i present here, a top-10 list of recommendations for how to write consistently boring scientific publications. i then discuss why we should and how we could make these contributions more accessible and exciting."
268,article,nat rev genet,,,nature publishing group,12,5,2,2004,feb,2004-11-12 19:49:45,"department of physics, university of notre dame, notre dame, indiana 46556, usa. alb@nd.edu",network biology: understanding the cell's functional organization,"a key aim of postgenomic biomedical research is to systematically catalogue all molecules and their interactions within a living cell. there is a clear need to understand how these molecules and the interactions between them determine the function of this enormously complex machinery, both in isolation and when surrounded by other cells. rapid advances in network biology indicate that cellular networks are governed by universal laws and offer a new conceptual framework that could potentially revolutionize our view of biology and disease pathologies in the twenty-first century."
81501,article,proceedings of the national academy of sciences,,,national academy of sciences,5,99,12,2002,jun,2005-01-21 16:03:13,"santa fe institute, 1399 hyde park road, santa fe, nm 87501, usa. girvan@santafe.edu",community structure in social and biological networks,"a number of recent studies have focused on the statistical properties of networked systems such as social networks and the worldwide web. researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. in this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. we propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. we test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. we also apply the method to two networks whose community structure is not well known—a collaboration network and a food web—and find that it detects significant and informative community divisions in both cases."
65083,article,artificial organs,,,blackwell publishing,1,29,1,2005,jan,2005-01-11 06:43:05,"general, visceral and transplantation surgery, experimental surgery and regenerative medicine, charitcampus virchow, university medicine berlin, berlin, germany.","""blogs"" and ""wikis"" are valuable software tools for communication within research groups.",
822253,inproceedings,,proceedings of the seventeenth conference on hypertext and hypermedia,hypertext,acm,3,,,2006,,2006-08-30 17:39:21,"new york, ny, usa",harvesting social knowledge from folksonomies,"collaborative tagging systems, or folksonomies, have the potential of becoming technological infrastructure to support knowledge management activities in an organization or a society. there are many challenges, however. this paper presents designs that enhance collaborative tagging systems to meet some key challenges: community identification, ontology generation, user and document recommendation. design prototypes, evaluation methodology and selected preliminary results are presented."
44,article,nature,,,nature publishing group,8,410,6825,2001,mar,2004-11-04 02:26:33,"department of theoretical and applied mechanics and center for applied mathematics, cornell university, ithaca, new york 14853-1503, usa. strogatz@cornell.edu",exploring complex networks,"the study of networks pervades all of science, from neurobiology to statistical physics. the most basic issues are structural: how does one characterize the wiring diagram of a food web or the internet or the metabolic network of the bacterium escherichia coli? are there any unifying principles underlying their topology? from the perspective of nonlinear dynamics, we would also like to understand how an enormous network of interacting dynamical systems — be they neurons, power stations or lasers — will behave collectively, given their individual dynamics and coupling architecture. researchers are only now beginning to unravel the structure and dynamics of complex networks."
3391364,article,nature biotechnology,nat biotech,,nature publishing group,10,26,10,2008,oct,2008-10-09 20:09:55,,next-generation {dna} sequencing,"{dna} sequence represents a single format onto which a broad range of biological phenomena can be projected for high-throughput data collection. over the past three years, massively parallel {dna} sequencing platforms have become widely available, reducing the cost of {dna} sequencing by over two orders of magnitude, and democratizing the field by putting the sequencing capacity of a major genome center in the hands of individual investigators. these new technologies are rapidly evolving, and near-term challenges include the development of robust protocols for generating sequencing libraries, building effective new approaches to data-analysis, and often a rethinking of experimental design. next-generation {dna} sequencing has the potential to dramatically accelerate biological and biomedical research, by enabling the comprehensive analysis of genomes, transcriptomes and interactomes to become inexpensive, routine and widespread, rather than requiring significant production-scale efforts."
8133402,article,nature,,,nature research,12,467,7319,2010,oct,2010-10-27 18:35:05,,a map of human genome variation from population-scale sequencing,"the 1000 genomes project aims to provide a deep characterization of human genome sequence variation as a foundation for investigating the relationship between genotype and phenotype. here we present results of the pilot phase of the project, designed to develop and compare different strategies for genome-wide sequencing with high-throughput platforms. we undertook three projects: low-coverage whole-genome sequencing of 179 individuals from four populations; high-coverage sequencing of two mother-father-child trios; and exon-targeted sequencing of 697 individuals from seven populations. we describe the location, allele frequency and local haplotype structure of approximately 15 million single nucleotide polymorphisms, 1 million short insertions and deletions, and 20,000 structural variants, most of which were previously undescribed. we show that, because we have catalogued the vast majority of common variation, over 95\% of the currently accessible variants found in any individual are present in this data set. on average, each person is found to carry approximately 250 to 300 loss-of-function variants in annotated genes and 50 to 100 variants previously implicated in inherited disorders. we demonstrate how these results can be used to inform association and functional studies. from the two trios, we directly estimate the rate of de novo germline base substitution mutations to be approximately 10(-8) per base pair per generation. we explore the data with regard to signatures of natural selection, and identify a marked reduction of genetic variation in the neighbourhood of genes, due to selection at linked sites. these methods and public data will support the next phase of human genetic research."
4200367,article,"bioinformatics (oxford, england)",,,oxford university press,6,25,9,2009,may,2009-03-20 18:39:43,,{tophat}: discovering splice junctions with {rna}-seq.,"a new protocol for sequencing the messenger {rna} in a cell, known as {rna}-seq, generates millions of short sequence fragments in a single run. these fragments, or 'reads', can be used to measure levels of gene expression and to identify novel splice variants of genes. however, current software for aligning {rna}-seq data to a genome relies on known splice junctions and cannot identify novel ones. {tophat} is an efficient read-mapping algorithm designed to align reads from an {rna}-seq experiment to a reference genome without relying on known splice sites. we mapped the {rna}-seq reads from a recent mammalian {rna}-seq experiment and recovered more than 72\% of the splice junctions reported by the annotation-based software from that study, along with nearly 20,000 previously unreported junctions. the {tophat} pipeline is much faster than previous systems, mapping nearly 2.2 million reads per {cpu} hour, which is sufficient to process an entire {rna}-seq experiment in less than a day on a standard desktop computer. we describe several challenges unique to ab initio splice site discovery from {rna}-seq reads that will require further algorithm development. {tophat} is free, open-source software available from http://tophat.cbcb.umd.edu. supplementary data are available at bioinformatics online."
197260,book,,,,cambridge university press,,,,1991,sep,2005-05-11 21:28:08,,"situated learning: legitimate peripheral participation (learning in doing: social, cognitive and computational perspectives)",
4968720,article,plos comput biol,plos comput biol,,public library of science,,5,6,2009,jun,2009-06-26 09:00:26,,managing and analyzing {next-generation} sequence data,
1042553,article,journal of the royal statistical society. series b (methodological),,,blackwell publishing for the royal statistical society,11,57,1,1995,,2007-01-15 14:10:29,,controlling the false discovery rate: a practical and powerful approach to multiple testing,"the common approach to the multiplicity problem calls for controlling the familywise error rate ({fwer}). this approach, though, has faults, and we point out a few. a different approach to problems of multiple significance testing is presented. it calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. this error rate is equivalent to the {fwer} when all hypotheses are true but is smaller otherwise. therefore, in problems where the control of the false discovery rate rather than that of the {fwer} is desired, there is potential for a gain in power. a simple sequential bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. the use of the new procedure and the appropriateness of the criterion are illustrated with examples."
469428,article,nature reviews genetics,,,nature publishing group,10,7,2,2006,feb,2006-01-21 06:09:24,,literature mining for the biologist: from information retrieval to biological discovery,"for the average biologist, hands-on literature mining currently means a keyword search in {pubmed}. however, methods for extracting biomedical facts from the scientific literature have improved considerably, and the associated tools will probably soon be used in many laboratories to automatically annotate and analyse the growing number of system-wide experimental data sets. owing to the increasing body of text and the open-access policies of many journals, literature mining is also becoming useful for both hypothesis generation and biological discovery. however, the latter will require the integration of literature and high-throughput data, which should encourage close collaborations between biologists and computational linguists."
2492402,article,nature biotechnology,,,nature publishing group,1,26,3,2008,mar,2008-03-09 12:24:32,,what is principal component analysis?,"principal component analysis is often incorporated into genome-wide expression studies, but what is it and how can it be used to explore high-dimensional data?"
83751,article,acm comput. surv.,,,acm,59,31,3,1999,sep,2005-01-26 09:13:20,"new york, ny, usa",data clustering: a review,
3721754,article,nucleic acids research,,,oxford university press,12,37,1,2009,jan,2008-11-28 13:45:48,,bioinformatics enrichment tools: paths toward the comprehensive functional analysis of large gene lists,"functional analysis of large gene lists, derived in most cases from emerging high-throughput genomic, proteomic and bioinformatics scanning approaches, is still a challenging and daunting task. the gene-annotation enrichment analysis is a promising high-throughput strategy that increases the likelihood for investigators to identify biological processes most pertinent to their study. approximately 68 bioinformatics enrichment tools that are currently available in the community are collected in this survey. tools are uniquely categorized into three major classes, according to their underlying enrichment algorithms. the comprehensive collections, unique tool classifications and associated questions/issues will provide a more comprehensive and up-to-date view regarding the advantages, pitfalls and recent trends in a simpler tool-class level rather than by a tool-by-tool approach. thus, the survey will help tool designers/developers and experienced end users understand the underlying algorithms and pertinent details of particular tool categories/tools, enabling them to make the best choices for their particular research interests."
938,article,commun. acm,,,acm,5,47,12,2004,dec,2004-11-23 02:13:34,"new york, ny, usa",semantic blogging and decentralized knowledge management,tapping into the structured metadata in snippets of information gives communities of interest effective access to their collective knowledge.
405907,article,proceedings of the ieee,proceedings of the ieee,,ieee,29,77,2,1989,feb,2005-11-23 14:41:25,,a tutorial on hidden markov models and selected applications in speech recognition,"this tutorial provides an overview of the basic theory of hidden markov models ({hmms}) as originated by {l.e}. baum and t. petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. the author first reviews the theory of discrete markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. the theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. three fundamental problems of {hmms} are noted and several practical techniques for solving these problems are given. the various types of {hmms} that have been studied, including ergodic as well as left-right models, are described"
2620950,article,genome research,genome research,,cold spring harbor laboratory press,8,18,5,2008,may,2008-04-01 21:51:05,,velvet: algorithms for de novo short read assembly using de bruijn graphs.,"we have developed a new set of algorithms, collectively called ""velvet,"" to manipulate de bruijn graphs for genomic sequence assembly. a de bruijn graph is a compact representation based on short words (k-mers) that is ideal for high coverage, very short read (25-50 bp) data sets. applying velvet to very short reads and paired-ends information only, one can produce contigs of significant length, up to 50-kb n50 length in simulations of prokaryotic data and 3-kb n50 on simulated mammalian {bacs}. when applied to real solexa data sets without read pairs, velvet generated contigs of approximately 8 kb in a prokaryote and 2 kb in a mammalian {bac}, in close agreement with our simulated results without read-pair information. velvet represents a new approach to assembly that can leverage very short reads in combination with read pairs to produce useful assemblies."
4265782,article,science,,,american association for the advancement of science,4,324,5923,2009,apr,2009-04-03 03:48:42,,the automation of science,"the basis of science is the hypothetico-deductive method and the recording of experiments in sufficient detail to enable reproducibility. we report the development of robot scientist  ” adam,” which advances the automation of both. adam has autonomously generated functional genomics hypotheses about the yeast saccharomyces cerevisiae and experimentally tested these hypotheses by using laboratory automation. we have confirmed adam's conclusions through manual experiments. to describe adam's research, we have developed an ontology and logical language. the resulting formalization involves over 10,000 different research units in a nested treelike structure, 10 levels deep, that relates the 6.6 million biomass measurements to their logical description. this formalization describes how a machine contributed to scientific knowledge."
227153,article,nature,,,nature publishing group,61,409,6822,2001,feb,2005-06-14 02:46:37,,initial sequencing and analysis of the human genome,"the human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. we also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence."
255030,article,nucleic acids research,,,oxford university press,7,28,1,2000,jan,2005-07-13 17:11:25,"research collaboratory for structural bioinformatics (rcsb), rutgers university, piscataway, nj 08854-8087, usa. berman@rcsb.rutgers.edu",the protein data bank,"the protein data bank ({pdb}; http://www.rcsb.org/pdb/ ) is the single worldwide archive of structural data of biological macromolecules. this paper describes the goals of the {pdb}, the systems in place for data deposition and access, how to obtain further information, and near-term plans for the future development of the resource."
2058201,article,,,,,,,,2005,may,2009-09-16 12:38:25,,spike and slab variable selection: frequentist and bayesian strategies,
5394760,article,nature biotechnology,,,nature publishing group,6,27,8,2009,aug,2009-08-08 08:00:03,,the systems biology graphical notation.,"circuit diagrams and unified modeling language diagrams are just two examples of standard visual languages that help accelerate work by promoting regularity, removing ambiguity and enabling software tool support for communication of complex information. ironically, despite having one of the highest ratios of graphical to textual information, biology still lacks standard graphical notations. the recent deluge of biological knowledge makes addressing this deficit a pressing concern. toward this goal, we present the systems biology graphical notation ({sbgn}), a visual language developed by a community of biochemists, modelers and computer scientists. {sbgn} consists of three complementary languages: process diagram, entity relationship diagram and activity flow diagram. together they enable scientists to represent networks of biochemical interactions in a standard, unambiguous way. we believe that {sbgn} will foster efficient and accurate representation, visualization, storage, exchange and reuse of information on all kinds of biological knowledge, from gene regulation, to metabolism, to cellular signaling."
5785226,article,plos biol,,,public library of science,,7,9,2009,sep,2009-09-15 07:43:42,,real lives and white lies in the funding of scientific research,
4524121,article,plos comput biol,,,public library of science,,5,6,2009,jun,2009-05-15 18:13:22,,ten simple rules for choosing between industry and academia,
2883810,article,genome research,,,cold spring harbor laboratory press,8,18,9,2008,sep,2008-06-11 21:57:14,,{rna}-seq: an assessment of technical reproducibility and comparison with gene expression arrays,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
481248,article,physics reports,,,,133,424,4-5,2006,feb,2006-01-26 05:04:14,,complex networks: structure and dynamics,"coupled biological and chemical systems, neural networks, social interacting species, the internet and the world wide web, are only a few examples of systems composed by a large number of highly interconnected dynamical units. the first approach to capture the global properties of such systems is to model them as graphs whose nodes represent the dynamical units, and whose links stand for the interactions between them. on the one hand, scientists have to cope with structural issues, such as characterizing the topology of a complex wiring architecture, revealing the unifying principles that are at the basis of real networks, and developing models to mimic the growth of a network and reproduce its structural properties. on the other hand, many relevant questions arise when studying complex networks' dynamics, such as learning how a large ensemble of dynamical systems that interact through a complex wiring topology can behave collectively. we review the major concepts and results recently achieved in the study of the structure and dynamics of complex networks, and summarize the relevant applications of these ideas in many different disciplines, ranging from nonlinear science to biology, from statistical mechanics to medicine and engineering."
4025955,article,nat rev neurosci,,,nature publishing group,12,10,3,2009,mar,2009-02-09 16:40:14,,complex brain networks: graph theoretical analysis of structural and functional systems,"recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. the brain's structural and functional systems have features of complex networks--such as small-world topology, highly connected hubs and modularity--both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. in this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional {mri}, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. we also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field."
965334,inproceedings,,proceedings of the 2006 20th anniversary conference on computer supported cooperative work,cscw,acm,9,,,2006,,2006-11-28 14:56:29,"new york, ny, usa","tagging, communities, vocabulary, evolution","a tagging community's vocabulary of tags forms the basis for social navigation and shared {expression.we} present a user-centric model of vocabulary evolution in tagging communities based on community influence and personal tendency. we evaluate our model in an emergent tagging system by introducing tagging features into the {movielens} recommender {system.we} explore four tag selection algorithms for displaying tags applied by other community members. we analyze the algorithms 'effect on vocabulary evolution, tag utility, tag adoption, and user satisfaction."
820297,article,pattern recognition letters,roc analysis in pattern recognition,,elsevier science inc.,13,27,8,2006,jun,2006-08-29 02:24:46,"new york, ny, usa",an introduction to {roc} analysis,"receiver operating characteristics ({roc}) graphs are useful for organizing classifiers and visualizing their performance. {roc} graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. although {roc} graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. the purpose of this article is to serve as an introduction to {roc} graphs and as a guide for using them in research."
2739852,article,nature,,,nature publishing group,3,453,7191,2008,may,2008-04-30 21:28:34,,hierarchical structure and the prediction of missing links in networks,"networks have in recent years emerged as an invaluable tool for describing and quantifying complex systems in many branches of science1, 2, 3. recent studies suggest that networks often exhibit hierarchical organization, in which vertices divide into groups that further subdivide into groups of groups, and so forth over multiple scales. in many cases the groups are found to correspond to known functional units, such as ecological niches in food webs, modules in biochemical networks (protein interaction networks, metabolic networks or genetic regulatory networks) or communities in social networks4, 5, 6, 7. here we present a general technique for inferring hierarchical structure from network data and show that the existence of hierarchy can simultaneously explain and quantitatively reproduce many commonly observed topological properties of networks, such as right-skewed degree distributions, high clustering coefficients and short path lengths. we further show that knowledge of hierarchical structure can be used to predict missing connections in partly known networks with high accuracy, and for more general network structures than competing techniques8. taken together, our results suggest that hierarchy is a central organizing principle of complex networks, capable of offering insight into many network phenomena."
7122989,article,nature biotechnology,,,nature publishing group,4,28,5,2010,may,2010-05-04 21:31:11,,transcript assembly and quantification by {rna}-seq reveals unannotated transcripts and isoform switching during cell differentiation.,"high-throughput {mrna} sequencing ({rna}-seq) promises simultaneous transcript discovery and abundance estimation. however, this would require algorithms that are not restricted by prior gene annotations and that account for alternative transcription and splicing. here we introduce such algorithms in an open-source software program called cufflinks. to test cufflinks, we sequenced and analyzed >430 million paired 75-bp {rna}-seq reads from a mouse myoblast cell line over a differentiation time series. we detected 13,692 known transcripts and 3,724 previously unannotated ones, 62\% of which are supported by independent expression data or by homologous genes in other species. over the time series, 330 genes showed complete switches in the dominant transcription start site ({tss}) or splice isoform, and we observed more subtle shifts in 1,304 other genes. these results suggest that cufflinks can illuminate the substantial regulatory flexibility and complexity in even this well-studied model of muscle development and that it can improve transcriptome-based genome annotation."
172550,article,acm trans. inf. syst.,,,acm,48,22,1,2004,jan,2005-04-27 18:41:15,"new york, ny, usa",evaluating collaborative filtering recommender systems,"recommender systems have been evaluated in many, often incomparable, ways. in this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. in addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated."
168573,article,personal ubiquitous comput.,,,springer-verlag,11,8,1,2004,feb,2005-04-24 00:19:48,"london, uk, uk",what we talk about when we talk about context,"the emergence of ubiquitous computing as a new design paradigm poses significant challenges for human-computer interaction ({hci}) and interaction design. traditionally, {hci} has taken place within a constrained and well-understood domain of experience—single users sitting at desks and interacting with conventionally-designed computers employing screens, keyboards and mice for interaction. new opportunities have engendered considerable interest in  ” context-aware computing”—computational systems that can sense and respond to aspects of the settings in which they are used. however, considerable confusion surrounds the notion of  ” context”—what it means, what it includes and what role it plays in interactive systems. this paper suggests that the representational stance implied by conventional interpretations of  ” context” misinterprets the role of context in everyday human activity, and proposes an alternative model that suggests different directions for design."
556495,article,reviews of modern physics,,,american physical society,50,74,1,2002,jan,2006-03-18 18:52:38,,statistical mechanics of complex networks,"complex networks describe a wide range of systems in nature and society. frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the internet, a network of routers and computers connected by physical links. while traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. this article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. after reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network's robustness against failures and attacks."
430834,inproceedings,osdi '04,,,,13,,,-1,,2005-12-08 17:10:09,,{mapreduce}: simplified data processing on large clusters,"{mapreduce} is a programming model and an associated implementation for processing and generating large data sets.  users specify a \_map\_ function that processes a key/value pair to generate a set of intermediate key/value pairs, and a \_reduce\_ function that merges all intermediate values associated with the same intermediate key.  many real world tasks are expressible in this model, as shown in the paper. <p> programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. the run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter- machine communication.  this allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.  <p> our implementation of {mapreduce} runs on a large cluster of commodity machines and is highly scalable: a typical {mapreduce} computation processes many terabytes of data on thousands of machines. programmers find the system easy to use: hundreds of {mapreduce} programs have been implemented and upwards of one thousand {mapreduce} jobs are executed on google's clusters every day.     <p>"
154,article,physical review e,,,american physical society,,69,2,2003,aug,2004-11-10 17:09:17,,finding and evaluating community structure in networks,
5434882,article,science,science,,american association for the advancement of science,4,325,5942,2009,aug,2009-08-14 06:24:48,,"strategic reading, ontologies, and the future of scientific publishing","the revolution in scientific publishing that has been promised since the 1980s is about to take place. scientists have always read strategically, working with many articles simultaneously to search, filter, scan, link, annotate, and analyze fragments of content. an observed recent increase in strategic reading in the online environment will soon be further intensified by two current trends: (i) the widespread use of digital indexing, retrieval, and navigation resources and (ii) the emergence within many scientific disciplines of interoperable ontologies. accelerated and enhanced by reading tools that take advantage of ontologies, reading practices will become even more rapid and indirect, transforming the ways in which scientists engage the literature and shaping the evolution of scientific publishing."
2883820,article,nature,,,nature publishing group,9,453,7197,2008,jun,2008-06-11 22:05:46,,what we can do and what we cannot do with {fmri},"functional magnetic resonance imaging ({fmri}) is currently the mainstay of neuroimaging in cognitive neuroscience. advances in scanner technology, image acquisition protocols, experimental design, and analysis methods promise to push forward {fmri} from mere cartography to the true study of brain organization. however, fundamental questions concerning the interpretation of {fmri} data abound, as the conclusions drawn often ignore the actual limitations of the methodology. here i give an overview of the current state of {fmri}, and draw on neuroimaging and physiological data to present the current understanding of the haemodynamic signals and the constraints they impose on neuroimaging data interpretation."
200871,book,,,,basic books,,,,2002,sep,2005-05-15 20:37:03,,the design of everyday things,"even the smartest among us can feel inept as we fail to figure out which switch turns on which light or stove burner, or whether to push, pull, or slide a door. the fault lies in product designs that ignore the needs of users and the principles of cognitive psychology. a bestseller in the united states, this classic work on the cognitive aspects of design contains examples of both good and bad design and simple rules that designers can use to improve the usability of objects as diverse as cars, computers, doors, and {telephones.--from} publisher description."
1307464,article,nat rev genet,nat rev genet,,nature publishing group,11,8,6,2007,jun,2007-05-20 11:38:23,,network motifs: theory and experimental approaches,"transcription regulation networks control the expression of genes. the transcription networks of well-studied microorganisms appear to be made up of a small set of recurring regulation patterns, called network motifs. the same network motifs have recently been found in diverse organisms from bacteria to humans, suggesting that they serve as basic building blocks of transcription networks. here i review network motifs and their functions, with an emphasis on experimental studies. network motifs in other biological networks are also mentioned, including signalling and neuronal networks."
6758396,article,nature,,,nature publishing group,6,464,7285,2010,mar,2010-03-03 19:29:56,,a human gut microbial gene catalogue established by metagenomic sequencing,"to understand the impact of gut microbes on human health and well-being it is crucial to assess their genetic potential. here we describe the illumina-based metagenomic sequencing, assembly and characterization of 3.3 million non-redundant microbial genes, derived from 576.7 gigabases of sequence, from faecal samples of 124 european individuals. the gene set, \~{}150 times larger than the human gene complement, contains an overwhelming majority of the prevalent (more frequent) microbial genes of the cohort and probably includes a large proportion of the prevalent human intestinal microbial genes. the genes are largely shared among individuals of the cohort. over 99\% of the genes are bacterial, indicating that the entire cohort harbours between 1,000 and 1,150 prevalent bacterial species and each individual at least 160 such species, which are also largely shared. we define and describe the minimal gut metagenome and the minimal gut bacterial genome in terms of functions present in all individuals and most bacteria, respectively."
4302361,article,trends in biochemical sciences,,,,6,34,5,2009,may,2009-04-12 03:45:47,,four stages of a scientific discipline; four types of scientist,
197238,article,science,science,,american association for the advancement of science,47,291,5507,2001,feb,2005-05-11 20:15:06,"celera genomics, 45 west gude drive, rockville, md 20850, usa. humangenome@celera.com",the sequence of the human genome,
4511,article,commun. acm,,,acm,5,47,12,2004,dec,2004-12-22 16:50:14,"new york, ny, usa",why we blog,"bloggers are driven to document their lives, provide commentary and opinions, express deeply felt emotions, articulate ideas through writing, and form and maintain community forums."
113848,book,,,prentice hall series in artificial intelligence,prentice hall,,,,2002,dec,2005-03-04 08:43:31,,artificial intelligence: a modern approach (2nd edition),"presents a guide to artificial intelligence, covering such topics as intelligent agents, problem-solving, logical agents, planning, uncertainty, learning, and robotics."
2800782,article,nature reviews genetics,,,nature publishing group,6,9,7,2008,may,2008-05-16 05:31:42,"carnegie institution for science, department of plant biology, 260 panama street, stanford, california 94305, usa.",use and misuse of the gene ontology annotations,
1320727,article,proceedings of the national academy of sciences of the united states of america,,,national academy of sciences,5,104,21,2007,may,2007-05-23 09:40:03,,the human disease network.,"a network of disorders and disease genes linked by known disorder-gene associations offers a platform to explore in a single graph-theoretic framework all known phenotype and disease gene associations, indicating the common genetic origin of many diseases. genes associated with similar disorders show both higher likelihood of physical interactions between their products and higher expression profiling similarity for their transcripts, supporting the existence of distinct disease-specific functional modules. we find that essential human genes are likely to encode hub proteins and are expressed widely in most tissues. this suggests that disease genes also would play a central role in the human interactome. in contrast, we find that the vast majority of disease genes are nonessential and show no tendency to encode hub proteins, and their expression pattern indicates that they are localized in the functional periphery of the network. a selection-based model explains the observed difference between essential and disease genes and also suggests that diseases caused by somatic mutations should not be peripheral, a prediction we confirm for cancer genes."
340715,book,,,morgan kaufmann series in data management systems,morgan kaufmann,,,,2005,jun,2005-10-04 15:35:50,,data mining: practical machine learning tools and techniques,"as with any burgeoning technology that enjoys commercial attention, the use of data mining is surrounded by a great deal of hype. exaggerated reports tell of secrets that can be uncovered by setting algorithms loose on oceans of data. but there is no magic in machine learning, no hidden power, no alchemy. instead there is an identifiable body of practical techniques that can extract useful information from raw data. this book describes these techniques and shows how they work. <{br><br>the} book is a major revision of the first edition that appeared in 1999. while the basic core remains the same, it has been updated to reflect the changes that have taken place over five years, and now has nearly double the references. the highlights for the new edition include thirty new technique sections; an enhanced weka machine learning workbench, which now features an interactive interface; comprehensive information on neural networks; a new section on bayesian networks; plus much more.<br><br>+ authors, ian witten and eibe frank, recipients of the 2005 {acm} {sigkdd} service award.<br>+ algorithmic methods at the heart of successful data miningincluding tried and true techniques as well as leading edge methods; <br>+ performance improvement techniques that work by transforming the input or output; <br>+ downloadable weka, a collection of machine learning algorithms for data mining tasks, including tools for data pre-processing, classification, regression, clustering, association rules, and visualizationin a new, interactive interface."
688160,inproceedings,,www,,acm press,9,,,2006,,2006-06-07 11:20:08,"new york, ny, usa",visualizing tags over time,
3158518,article,genome research,,,cold spring harbor laboratory press,7,18,11,2008,nov,2008-08-27 16:06:37,sanger institute;,mapping short {dna} sequencing reads and calling variants using mapping quality scores.,"new sequencing technologies promise a new era in the use of {dna} sequence. however, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. in particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. we describe the software {maq} that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. {maq} makes full use of mate-pair information and estimates the error probability of each read alignment. error probabilities are also derived for the final genotype calls, using a bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. both read mapping and genotype calling are evaluated on simulated data and real data. {maq} is accurate, efficient, versatile, and user-friendly. it is freely available at http://maq.sourceforge.net."
165614,book,,,"structural analysis in the social sciences, 8",cambridge university press,,,,1994,nov,2005-04-21 02:34:58,,social network analysis: methods and applications (structural analysis in the social sciences),
105906,book,,,,the mit press,,,,1999,jun,2005-02-27 13:16:43,,foundations of statistical natural language processing,
201598,article,commun. acm,,,acm,2,40,3,1997,mar,2005-05-16 18:36:58,"new york, ny, usa",referral web: combining social networks and collaborative filtering,an abstract is not available.
8132834,article,genome biology,,,biomed central ltd,,11,10,2010,oct,2010-10-27 16:53:08,,differential expression analysis for sequence count data.,"high-throughput sequencing assays such as {rna}-seq, {chip}-seq or barcode counting provide quantitative readouts in the form of count data. to infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. we propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, {deseq}, as an {r/bioconductor} package."
6573750,article,science,,,american association for the advancement of science,6,327,5964,2010,jan,2010-01-21 19:49:16,,the genetic landscape of a cell,
9300222,article,nature biotechnology,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",8,29,7,2011,jul,2011-05-15 22:32:06,,full-length transcriptome assembly from {rna}-seq data without a reference genome.,"massively parallel sequencing of {cdna} has enabled deep and efficient probing of transcriptomes. current approaches for transcript reconstruction from such data often rely on aligning reads to a reference genome, and are thus unsuitable for samples with a partial or missing reference genome. here we present the trinity method for de novo assembly of full-length transcripts and evaluate it on samples from fission yeast, mouse and whitefly, whose reference genome is not yet available. by efficiently constructing and analyzing sets of de bruijn graphs, trinity fully reconstructs a large fraction of transcripts, including alternatively spliced isoforms and transcripts from recently duplicated genes. compared with other de novo transcriptome assemblers, trinity recovers more full-length transcripts across a broad range of expression levels, with a sensitivity similar to methods that rely on genome alignments. our approach provides a unified solution for transcriptome reconstruction in any sample, especially in the absence of a reference genome."
143101,book,,,,the mit press,,,,1996,oct,2005-03-30 20:06:19,,the sciences of the artificial - 3rd edition,
1051630,article,science,,,american association for the advancement of science,4,315,5814,2007,feb,2007-01-19 13:03:14,"department of electrical and computer engineering, university of toronto, 10 king's college road, toronto, ontario m5s 3g4, canada.",clustering by passing messages between data points,"clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. such  ” exemplars” can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. we devised a method called  ” affinity propagation,” which takes as input measures of similarity between pairs of data points. real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. we used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time."
6734445,article,plos comput biol,,,public library of science,,6,2,2010,feb,2010-02-26 17:20:09,,a primer on metagenomics,"metagenomics is a discipline that enables the genomic study of uncultured microorganisms. faster, cheaper sequencing technologies and the ability to sequence uncultured microbes sampled directly from their habitats are expanding and transforming our view of the microbial world. distilling meaningful information from the millions of new genomic sequences presents a serious challenge to bioinformaticians. in cultured microbes, the genomic data come from a single clone, making sequence assembly and annotation tractable. in metagenomics, the data come from heterogeneous microbial communities, sometimes containing more than 10,000 species, with the sequence data being noisy and partial. from sampling, to assembly, to gene calling and function prediction, bioinformatics faces new demands in interpreting voluminous, noisy, and often partial sequence data. although metagenomics is a relative newcomer to science, the past few years have seen an explosion in computational methods applied to metagenomic-based research. it is therefore not within the scope of this article to provide an exhaustive review. rather, we provide here a concise yet comprehensive introduction to the current computational requirements presented by metagenomics, and review the recent progress made. we also note whether there is software that implements any of the methods presented here, and briefly review its utility. nevertheless, it would be useful if readers of this article would avail themselves of the comment section provided by this journal, and relate their own experiences. finally, the last section of this article provides a few representative studies illustrating different facets of recent scientific discoveries made using metagenomics."
368051,book,,,,o'reilly media,,,,2005,oct,2005-10-27 19:31:24,,ambient findability: what we find changes who we become,"{how do you find your way in an age of information overload? how can you filter streams of complex information to pull out only what you want? why does it matter how information is structured when google seems to magically bring up the right answer to your questions? what does it mean to be ""findable"" in this day and age?  this eye-opening new book examines the convergence of information and connectivity. written by peter morville, author of the groundbreaking <i>information architecture for the world wide web</i>, the book defines our current age as a state of unlimited findability. in other words, anyone can find anything at any time. complete navigability.   <p>  morville discusses the internet, gis, and other network technologies that are coming together to make unlimited findability possible. he explores how the melding of these innovations impacts society, since web access is now a standard requirement for successful people and businesses. but before he does that, morville looks back at the history of wayfinding and human evolution, suggesting that our fear of being lost has driven us to create maps, charts, and now, the mobile internet.</p>  <p>  the book's central thesis is that information literacy, information architecture, and usability are all critical components of this new world order. hand in hand with that is the contention that only by planning and designing the best possible software, devices, and internet, will we be able to maintain this connectivity in the future. morville's book is highlighted with full color illustrations and rich examples that bring his prose to life.</p>  <p>  <i>ambient findability</i> doesn't preach or pretend to know all the answers. instead, it presents research, stories, and examples in support of its novel ideas. are we truly at a critical point in our evolution where the quality of our digital networks will dictate how we behave as a species? is findability indeed the primary key to a successful global marketplace in the 21st century and beyond. peter morville takes you on a thought-provoking tour of these memes and more -- ideas that will not only fascinate but will stir your creativity in practical ways that you can apply to your work immediately.</p>  <p>  <i>""a lively, enjoyable and informative tour of a topic that's only going to become more important.""</i><br>  --david weinberger, author, <i>small pieces loosely joined</i> and <i>the cluetrain manifesto</i></br></p>  <p>  <i>""i envy the young scholar who finds this inventive book, by whatever strange means are necessary. the future isn't just unwritten--it's unsearched.""</i><br>  --bruce sterling, writer, futurist, and co-founder, the electronic frontier foundation</br></p>  <p>  <i>""search engine marketing is the hottest thing in internet business, and deservedly so. ambient findability puts sem into a broader context and provides deeper insights into human behavior. this book will help you grow your online business in a world where being found is not at all certain.""</i><br>  --jakob nielsen, ph.d., author, <i>designing web usability: the practice of simplicity</i></br></p>  <p>  <i>""information that's hard to find will remain information that's hardly found--from one of the fathers of the discipline of information architecture, and one of its most experienced practitioners, come penetrating observations on why findability is elusive and how the act of seeking changes us.""</i><br>  --steve papa, founder and chairman, endeca</br></p>  <p>  <i>""whether it's a fact or a figure, a person or a place, peter morville knows how to make it findable. morville explores the possibilities of a world where everything can always be found--and the challenges in getting there--in this wide-ranging, thought-provoking book.""</i><br>  --jesse james garrett, author, <i>the elements of user experience</i></br></p>  <p>  <i>""it is easy to assume that current searching of the world wide web is the last word in finding and using information. peter morville shows us that search engines are just the beginning. skillfully weaving together information science research with his own extensive experience, he develops for the reader a feeling for the near future when information is truly findable all around us. there are immense implications, and morville's lively and humorous writing brings them home.""</i><br>  --marcia j. bates, ph.d., university of california los angeles</br></p>  <p>  <i>""i've always known that peter morville was smart. after reading ambient findability, i now know he's (as we say in boston) wicked smart. this is a timely book that will have lasting effects on how we create our future.</i><br>  --jared spool, founding principal, user interface engineering</br></p>  <p>  <i>""in ambient findability, peter morville has put his mind and keyboard on the pulse of the electronic noosphere. with tangible examples and lively writing, he lays out the challenges and wonders of finding our way in cyberspace, and explains the mutually dependent evolution of our changing world and selves. this is a must read for everyone and a practical guide for designers.""</i><br>  --gary marchionini, ph.d., university of north carolina</br></p>  <p>  <i>""find this book! anyone interested in making information easier to find, or understanding how finding and being found is changing, will find this thoroughly researched, engagingly written, literate, insightful and very, very cool book well worth their time. myriad examples from rich and varied domains and a valuable idea on nearly every page. fun to read, too!</i><br>  --joseph janes, ph.d., founder, internet public library</br></p>}"
90557,article,science,,,american association for the advancement of science,3,286,5439,1999,oct,2005-02-09 21:05:22,"department of physics, university of notre dame, notre dame, in 46556, usa.",emergence of scaling in random networks,
5913660,article,science,,,american association for the advancement of science,4,326,5950,2009,oct,2009-10-09 03:21:11,,comprehensive mapping of {long-range} interactions reveals folding principles of the human genome,"we describe {hi-c}, a method that probes the three-dimensional architecture of whole genomes by coupling proximity-based ligation with massively parallel sequencing. we constructed spatial proximity maps of the human genome with {hi-c} at a resolution of 1 megabase. these maps confirm the presence of chromosome territories and the spatial proximity of small, gene-rich chromosomes. we identified an additional level of genome organization that is characterized by the spatial segregation of open and closed chromatin to form two genome-wide compartments. at the megabase scale, the chromatin conformation is consistent with a fractal globule, a knot-free, polymer conformation that enables maximally dense packing while preserving the ability to easily fold and unfold any genomic locus. the fractal globule is distinct from the more commonly used globular equilibrium model. our results demonstrate the power of {hi-c} to map the dynamic conformations of whole genomes."
1033358,article,siam review,,,siam,89,45,2,2003,,2007-01-15 20:43:39,,the structure and function of complex networks,"inspired by empirical studies of networked systems such as the internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks."
920055,article,genome research,,,cold spring harbor laboratory press,6,13,11,2003,nov,2006-10-31 10:30:16,"institute for systems biology, seattle, washington 98103, usa.",cytoscape: a software environment for integrated models of biomolecular interaction networks,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
305879,book,,,,oxford university press,,,,1977,aug,2005-11-27 21:34:00,,"a pattern language: towns, buildings, construction (center for environmental structure)",
241030,article,proceedings of the national academy of sciences,,,national academy of sciences,5,100,16,2003,aug,2005-06-30 18:30:23,"department of biostatistics, university of washington, seattle, wa 98195, usa. jstorey@u.washington.edu",statistical significance for genomewide studies,"with the increase in genomewide experiments and the sequencing of multiple genomes, the analysis of large data sets has become commonplace in biology. it is often the case that thousands of features in a genomewide data set are tested against some null hypothesis, where a number of features are expected to be significant. here we propose an approach to measuring statistical significance in these genomewide studies based on the concept of the false discovery rate. this approach offers a sensible balance between the number of true and false positives that is automatically calibrated and easily interpreted. in doing so, a measure of statistical significance called the q value is associated with each tested feature. the q value is similar to the well known p value, except it is a measure of significance in terms of the false discovery rate rather than the false positive rate. our approach avoids a flood of false positive results, while offering a more liberal criterion than what has been used in genome scans for linkage."
336118,article,physical review e,,,american physical society,,68,3,2003,sep,2005-09-30 10:20:41,,why social networks are different from other types of networks,"we argue that social networks differ from most other types of networks, including technological and biological networks, in two important ways. first, they have nontrivial clustering or network transitivity and second, they show positive correlations, also called assortative mixing, between the degrees of adjacent vertices. social networks are often divided into groups or communities, and it has recently been suggested that this division could account for the observed clustering. we demonstrate that group structure in networks can also account for degree correlations. we show using a simple model that we should expect assortative mixing in such networks whenever there is variation in the sizes of the groups and that the predicted level of assortative mixing compares well with that observed in real-world networks."
6346339,article,nature biotechnology,nat biotech,,nature publishing group,2,27,12,2009,dec,2009-12-09 23:25:07,,how does multiple testing correction work?,"when prioritizing hits from a high-throughput experiment, it is important to correct for random events that falsely appear significant. how is this done and what methods should be used?"
1263124,article,plos comput biol,,,public library of science,,3,4,2007,apr,2007-04-28 12:32:03,,ten simple rules for making good oral presentations,
664041,inproceedings,,chi,chi,acm,3,,,2006,,2006-05-22 08:30:55,"new york, ny, usa",why do tagging systems work?,"the panel will explore the relevance of the emerging tagging systems (flickr, del.icio.us, {rawsugar} and more). why do they seem to work? what kinds of incentives are required for users to participate? will tagging survive and scale to mass adoption? what are the behavioral, economic, and social models that underlie each tagging system? what are the dynamics of those systems, and how are they derived from the specific application's design and {affordances?.we} will demand answers to these questions and others from some of the pioneering practitioners and academics in the field. bring your wireless laptop to participate in a live tagging experiment! the experiment results will be shown and discussed at the end of the panel. to add to the fun, parts of the discussion will be motivated by short video segments."
477450,article,nature,,,nature publishing group,5,440,7084,2006,jan,2006-01-25 04:59:31,,proteome survey reveals modularity of the yeast cell machinery,"protein complexes are key molecular entities that integrate multiple gene products to perform cellular functions. here we report the first genome-wide screen for complexes in an organism, budding yeast, using affinity purification and mass spectrometry. through systematic tagging of open reading frames ({orfs}), the majority of complexes were purified several times, suggesting screen saturation. the richness of the data set enabled a de novo characterization of the composition and organization of the cellular machinery. the ensemble of cellular proteins partitions into 491 complexes, of which 257 are novel, that differentially combine with additional attachment proteins or protein modules to enable a diversification of potential functions. support for this modular organization of the proteome comes from integration with available data on expression, localization, function, evolutionary conservation, protein structure and binary interactions. this study provides the largest collection of physically determined eukaryotic cellular machines so far and a platform for biological data integration and modelling."
201641,book,,,,the university of chicago press,,,,1996,dec,2005-05-16 22:28:45,,"the structure of scientific revolutions, 3rd edition","{there's a ""frank \& ernest"" comic strip showing a chick breaking out of its shell, looking around, and saying, ""oh, wow! paradigm shift!"" blame the late thomas kuhn. few indeed are the philosophers or historians influential enough to make it into the funny papers, but kuhn is one.<p>  <i>the structure of scientific revolutions</i> is indeed a paradigmatic work in the history of science. kuhn's use of terms such as ""paradigm shift"" and ""normal science,"" his ideas of how scientists move from disdain through doubt to acceptance of a new theory, his stress on social and psychological factors in science--all have had profound effects on historians, scientists, philosophers, critics, writers, business gurus, and even the cartoonist in the street.<p>  some scientists (such as steven weinberg and ernst mayr) are profoundly irritated by kuhn, especially by the doubts he casts--or the way  his work has been used to cast doubt--on the idea of scientific progress. yet it has been said that the acceptance of plate tectonics in the 1960s, for instance, was sped by geologists' reluctance to be on the downside of a paradigm shift. even weinberg has said that ""<i>structure</i> has had a wider influence than any other book on the history of science."" as one of kuhn's obituaries noted, ""we all live in a post-kuhnian age."" <i>--mary ellen curtin</i> }"
4202607,article,"bioinformatics (oxford, england)",,,oxford university press,1,25,11,2009,jun,2009-03-21 11:58:12,,biopython: freely available python tools for computational molecular biology and bioinformatics.,"the biopython project is a mature open source international collaboration of volunteer developers, providing python libraries for a wide range of bioinformatics problems. biopython includes modules for reading and writing different sequence file formats and multiple sequence alignments, dealing with {3d} macro molecular structures, interacting with common tools such as {blast}, {clustalw} and {emboss}, accessing key online databases, as well as providing numerical methods for statistical learning. biopython is freely available, with documentation and source code at (www.biopython.org) under the biopython license."
165117,inproceedings,,proceedings of the 2004 acm conference on computer supported cooperative work,cscw,acm,9,,,2004,,2005-04-19 19:59:44,"new york, ny, usa",using social psychology to motivate contributions to online communities,"under-contribution is a problem for many online communities. social psychology theories of social loafing and goal-setting can provide mid-level design principles to address this problem. we tested the design principles in two field experiments. in one, members of an online movie recommender community were reminded of the uniqueness of their contributions and the benefits that follow from them. in the second, they were given a range of individual or group goals for contribution. as predicted by theory, individuals contributed when they were reminded of their uniqueness and when they were given specific and challenging goals, but other predictions were not borne out. the paper ends with suggestions and challenges for mining social science theories as well as implications for design."
244827,book,,,,{sage publications},,,,2000,jan,2005-07-04 18:17:47,,social network analysis: a handbook,"{the revised and updated edition of this bestselling text provides an accessible introduction to the theory and practice of network analysis in the social sciences. it gives a clear and authoritative guide to the general framework of network analysis, explaining the basic concepts, technical measures and reviewing the available computer programs.<p></p><p>the book outlines both the theoretical basis of network analysis and the key techniques for using it as a research tool. building upon definitions of points, lines and paths, john scott demonstrates their use in clarifying such measures as density, fragmentation and centralization. he identifies the various cliques, components and circles into which networks are formed, and outlines an approach to the study of socially structured positions. he also discusses the use of multidimensional methods for investigating social networks.</p><p></p><p><b>social network analysis</b> is an invaluable resource for researchers across the social sciences and for students of social theory and research methods.</p>}"
1279898,inproceedings,,proceedings of the sigchi conference on human factors in computing systems,chi,acm,9,,,2007,,2007-05-05 20:33:20,"new york, ny, usa",why we tag: motivations for annotation in mobile and online media,"why do people tag? users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. we investigate the incentives for annotation in flickr, a popular web-based photo-sharing system, and {zonetag}, a cameraphone photo capture and annotation tool that uploads images to flickr. in flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. {zonetag}, in turn, makes it easier to tag cameraphone photos that are uploaded to flickr by allowing annotation and suggesting relevant tags immediately after capture. a qualitative study of {zonetag}/flickr users exposed various tagging patterns and emerging motivations for photo annotation. we offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation."
6043685,article,nat meth,nat meth,,nature publishing group,10,6,11s,2009,nov,2009-10-30 17:15:59,,computation for {chip}-seq and {rna}-seq studies,"genome-wide measurements of {protein-dna} interactions and transcriptomes are increasingly done by deep {dna} sequencing methods ({chip}-seq and {rna}-seq). the power and richness of these counting-based measurements comes at the cost of routinely handling tens to hundreds of millions of reads. whereas early adopters necessarily developed their own custom computer code to analyze the first {chip}-seq and {rna}-seq datasets, a new generation of more sophisticated algorithms and software tools are emerging to assist in the analysis phase of these projects. here we describe the multilayered analyses of {chip}-seq and {rna}-seq datasets, discuss the software packages currently available to perform tasks at each layer and describe some upcoming challenges and features for future analysis tools. we also discuss how software choices and uses are affected by specific aspects of the underlying biology and data structure, including genome size, positional clustering of transcription factor binding sites, transcript discovery and expression quantification."
3623940,article,science,,,american association for the advancement of science,5,323,5910,2009,jan,2008-11-20 22:53:43,,{real-time} {dna} sequencing from single polymerase molecules,"we present single-molecule, real-time sequencing data obtained from a {dna} polymerase performing uninterrupted template-directed synthesis using four distinguishable fluorescently labeled deoxyribonucleoside triphosphates ({dntps}). we detected the temporal order of their enzymatic incorporation into a growing {dna} strand with zero-mode waveguide nanostructure arrays, which provide optical observation volume confinement and enable parallel, simultaneous detection of thousands of single-molecule sequencing reactions. conjugation of fluorophores to the terminal phosphate moiety of the {dntps} allows continuous observation of {dna} synthesis over thousands of bases without steric hindrance. the data report directly on polymerase dynamics, revealing distinct polymerization states and pause sites corresponding to {dna} secondary structure. sequence data were aligned with the known reference sequence to assay biophysical parameters of polymerization for each template position. consensus sequences were generated from the single-molecule reads at 15-fold coverage, showing a median accuracy of 99.3\%, with no systematic error beyond fluorophore-dependent error rates."
2709781,book,,,,cambridge university press,,,,2008,jul,2008-04-23 19:59:52,cambridge,introduction to information retrieval,"""class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. all the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures."" -- publisher's description."
478707,article,nature,,,nature publishing group,1,411,6833,2001,may,2006-01-24 10:12:20,,lethality and centrality in protein networks,"proteins are traditionally identified on the basis of their individual actions as catalysts, signalling molecules, or building blocks in cells and microorganisms. but our post-genomic view is expanding the protein's role into an element in a network of protein–protein interactions as well, in which it has a contextual or cellular function within functional modules1, 2. here we provide quantitative support for this idea by demonstrating that the phenotypic consequence of a single gene deletion in the yeast saccharomyces cerevisiae is affected to a large extent by the topological position of its protein product in the complex hierarchical web of molecular interactions."
468899,article,d-lib magazine,,,,,12,1,2006,,2006-01-18 12:33:50,,folksonomies: tidying up tags?,"a folksonomy is a type of distributed classification system. it is usually created by a group of individuals, typically the resource users. users add tags to online items, such as images, videos, bookmarks and text. these tags are then shared and sometimes refined. a general review of social bookmarking tools, one popular use area of folksonomies, was given in the april edition of {d-lib} [1]. in the article the authors elaborate on the approach taken by social classification systems and the motivators behind tagging. they write, ""...tags are just one kind of metadata and are not a replacement for formal classification systems such as dublin core, {mods"
4117809,article,genome research,,,cold spring harbor laboratory press,6,19,6,2009,jun,2009-03-02 01:17:50,,{abyss}: a parallel assembler for short read sequence data,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
459365,article,science,,,american association for the advancement of science,2,311,5757,2006,jan,2006-01-13 06:08:51,,empirical analysis of an evolving social network,"social networks evolve over time, driven by the shared activities and affiliations of their members, by similarity of individuals' attributes, and by the closure of short network cycles. we analyzed a dynamic social network comprising 43,553 students, faculty, and staff at a large university, in which interactions between individuals are inferred from time-stamped e-mail headers recorded over one academic year and are matched with affiliations and attributes. we found that network evolution is dominated by a combination of effects arising from network topology itself and the organizational structure in which the network is embedded. in the absence of global perturbations, average network properties appear to approach an equilibrium state, whereas individual properties are unstable."
922,article,computer networks and isdn systems,,,,10,30,1--7,1998,,2004-11-22 17:49:53,,the anatomy of a large-scale hypertextual web search engine,"in this paper, we present google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. google is designed to crawl and index the web efficiently and produce much more satisfying search results than existing systems. the prototype with a full text and hyperlink database of at least 24 million pages is available at"
7157821,article,briefings in bioinformatics,,,oxford university press,10,11,5,2010,sep,2010-05-12 10:29:45,,a survey of sequence alignment algorithms for next-generation sequencing,"rapidly evolving sequencing technologies produce data on an unparalleled scale. a central challenge to the analysis of this data is sequence alignment, whereby sequence reads must be compared to a reference. a wide variety of alignment algorithms and software have been subsequently developed over the past two years. in this article, we will systematically review the current development of these algorithms and introduce their practical applications on different types of experimental data. we come to the conclusion that short-read alignment is no longer the bottleneck of data analyses. we also consider future development of alignment algorithms with respect to emerging long sequence reads and the prospect of cloud computing."
2212959,article,commun. acm,,,acm,6,51,1,2008,jan,2008-01-10 03:49:25,"new york, ny, usa",{mapreduce}: simplified data processing on large clusters,"{mapreduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. programmers find the system easy to use: more than ten thousand distinct {mapreduce} programs have been implemented internally at google over the past four years, and an average of one hundred thousand {mapreduce} jobs are executed on google's clusters every day, processing a total of more than twenty petabytes of data per day."
3746363,article,microbiology and molecular biology reviews,,,american society for microbiology,21,72,4,2008,dec,2008-12-04 12:34:48,,a bioinformatician's guide to metagenomics,"summary: as random shotgun metagenomic projects proliferate and become the dominant source of publicly available sequence data, procedures for the best practices in their execution and analysis become increasingly important. based on our experience at the joint genome institute, we describe the chain of decisions accompanying a metagenomic project from the viewpoint of the bioinformatic analysis step by step. we guide the reader through a standard workflow for a metagenomic project beginning with presequencing considerations such as community composition and sequence data type that will greatly influence downstream analyses. we proceed with recommendations for sampling and data generation including sample and metadata collection, community profiling, construction of shotgun libraries, and sequencing strategies. we then discuss the application of generic sequence processing steps (read preprocessing, assembly, and gene prediction and annotation) to metagenomic data sets in contrast to genome projects. different types of data analyses particular to metagenomes are then presented, including binning, dominant population analysis, and gene-centric analysis. finally, data management issues are presented and discussed. we hope that this review will assist bioinformaticians and biologists in making better-informed decisions on their journey during a metagenomic project."
7203126,article,"science (new york, n.y.)",,,american association for the advancement of science,4,329,5987,2010,jul,2010-05-20 18:55:26,,creation of a bacterial cell controlled by a chemically synthesized genome.,
6699577,article,bmc bioinformatics,bmc bioinformatics,,biomed central,-81,11,1,2010,feb,2010-02-18 19:33:31,,evaluation of statistical methods for normalization and differential expression in {mrna}-seq experiments,"{background}:high-throughput sequencing technologies, such as the illumina genome analyzer, are powerful new tools for investigating a wide range of biological and medical questions. statistical and computational methods are key for drawing meaningful and accurate conclusions from the massive and complex datasets generated by the sequencers. we provide a detailed evaluation of statistical methods for normalization and differential expression ({de}) analysis of illumina transcriptome sequencing ({mrna}-seq) {data.results}:we compare statistical methods for detecting genes that are significantly {de} between two types of biological samples and find that there are substantial differences in how the test statistics handle low-count genes. we evaluate how {de} results are affected by features of the sequencing platform, such as, varying gene lengths, base-calling calibration method (with and without phi x control lane), and flow-cell/library preparation effects. we investigate the impact of the read count normalization method on {de} results and show that the standard approach of scaling by total lane counts (e.g., {rpkm}) can bias estimates of {de}. we propose more general quantile-based normalization procedures and demonstrate an improvement in {de} {detection.conclusions}:our results have significant practical and methodological implications for the design and analysis of {mrna}-seq experiments. they highlight the importance of appropriate statistical methods for normalization and {de} inference, to account for features of the sequencing platform that could impact the accuracy of results. they also reveal the need for further research in the development of statistical and computational methods for {mrna}-seq."
261749,book,,,,harvard university press,,,,1978,mar,2005-07-21 18:09:44,,mind in society: the development of higher psychological processes,
5759073,article,nature reviews. genetics,,,nature publishing group,11,10,10,2009,oct,2009-09-09 15:04:02,,{chip}-seq: advantages and challenges of a maturing technology.,"chromatin immunoprecipitation followed by sequencing ({chip}-seq) is a technique for genome-wide profiling of {dna}-binding proteins, histone modifications or nucleosomes. owing to the tremendous progress in next-generation sequencing technology, {chip}-seq offers higher resolution, less noise and greater coverage than its array-based predecessor {chip}-chip. with the decreasing cost of sequencing, {chip}-seq has become an indispensable tool for studying gene regulation and epigenetic mechanisms. in this review, i describe the benefits and challenges in harnessing this technique with an emphasis on issues related to experimental design and data analysis. {chip}-seq experiments generate large quantities of data, and effective computational analysis will be crucial for uncovering biological mechanisms."
148945,book,,,,mcgraw-hill science/engineering/math,,,,1997,mar,2005-04-03 21:01:30,,machine learning,"{this book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. the book is intended to support upper level undergraduate and introductory level graduate courses in machine learning.}"
975331,inproceedings,,proceedings of the 12th acm sigkdd international conference on knowledge discovery and data mining,kdd,acm,6,,,2006,,2006-12-05 14:42:30,"new york, ny, usa",structure and evolution of online social networks,"in this paper, we consider the evolution of structure within large online social networks. we present a series of measurements of two such networks, together comprising in excess of five million people and ten million friendship links, annotated with metadata capturing the time of every event in the life of the network. our measurements expose a surprising segmentation of these networks into three regions: singletons who do not participate in the network; isolated communities which overwhelmingly display star structure; and a giant component anchored by a well-connected core region which persists even in the absence of {stars.we} present a simple model of network growth which captures these aspects of component structure. the model follows our experimental results, characterizing users as either passive members of the network; inviters who encourage offline friends and acquaintances to migrate online; and linkers who fully participate in the social evolution of the network."
9345497,article,nature methods,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",8,8,6,2011,jun,2011-05-27 19:23:18,,computational methods for transcriptome annotation and quantification using {rna}-seq.,"high-throughput {rna} sequencing ({rna}-seq) promises a comprehensive picture of the transcriptome, allowing for the complete annotation and quantification of all genes and their isoforms across samples. realizing this promise requires increasingly complex computational methods. these computational challenges fall into three main categories: (i) read mapping, (ii) transcriptome reconstruction and (iii) expression quantification. here we explain the major conceptual and practical challenges, and the general classes of solutions for each category. finally, we highlight the interdependence between these categories and discuss the benefits for different biological applications."
270463,article,nature,nature,,nature publishing group,4,437,7057,2005,jul,2005-09-15 07:31:37,,genome sequencing in microfabricated high-density picolitre reactors,"the proliferation of large-scale {dna}-sequencing projects in recent years has driven a search for alternative methods to reduce time and cost. here we describe a scalable, highly parallel sequencing system with raw throughput significantly greater than that of state-of-the-art capillary electrophoresis instruments. the apparatus uses a novel fibre-optic slide of individual wells and is able to sequence 25 million bases, at 99\% or better accuracy, in one four-hour run. to achieve an approximately 100-fold increase in throughput over current sanger sequencing technology, we have developed an emulsion method for {dna} amplification and an instrument for sequencing by synthesis using a pyrosequencing protocol optimized for solid support and picolitre-scale volumes. here we show the utility, throughput, accuracy and robustness of this system by shotgun sequencing and de novo assembly of the mycoplasma genitalium genome with 96\% coverage at 99.96\% accuracy in one run of the machine."
332255,article,nature,,,nature publishing group,5,402,6761 Suppl,1999,dec,2005-09-26 02:40:38,"fred hutchinson cancer center, seattle, washington 98109, usa.",from molecular to modular cell biology.,"cellular functions, such as signal transmission, are carried out by 'modules' made up of many species of interacting molecules. understanding how modules work has depended on combining phenomenological analysis with molecular studies. general principles that govern the structure and behaviour of modules may be discovered with help from synthetic sciences such as engineering and computer science, from stronger interactions between experiment and theory in cell biology, and from an appreciation of evolutionary constraints."
142465,article,sociological theory,social structure and network analysis,,sage publications,32,1,,1982,,2005-12-09 01:53:37,"beverly hills, ca",the strength of weak ties: a network theory revisited,"in this chapter i review empirical studies directly testing the hypotheses of my 1973 paper ""the strength of weak ties"" (hereafter ""{swt}"") and work that elaborates those hypotheses theoretically or uses them to suggest new empirical research not discussed in my original formulation. along the way, i will reconsider various aspects of the theoretical argument, attempt to plug some holes, and broaden its base."
7355647,article,nature,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",3,466,7307,2010,aug,2010-06-24 08:15:19,,link communities reveal multiscale complexity in networks.,"networks have become a key approach to understanding systems of interacting objects, unifying the study of diverse phenomena including biological organisms and human society. one crucial step when studying the structure and dynamics of networks is to identify communities: groups of related nodes that correspond to functional subunits such as protein complexes or social spheres. communities in networks often overlap such that nodes simultaneously belong to several groups. meanwhile, many networks are known to possess hierarchical organization, where communities are recursively grouped into a hierarchical structure. however, the fact that many real networks have communities with pervasive overlap, where each and every node belongs to more than one group, has the consequence that a global hierarchy of nodes cannot capture the relationships between overlapping groups. here we reinvent communities as groups of links rather than nodes and show that this unorthodox approach successfully reconciles the antagonistic organizing principles of overlapping communities and hierarchy. in contrast to the existing literature, which has entirely focused on grouping nodes, link communities naturally incorporate overlap while revealing hierarchical organization. we find relevant link communities in many networks, including major biological networks such as protein-protein interaction and metabolic networks, and show that a large social network contains hierarchically organized community structures spanning inner-city to regional scales while maintaining pervasive overlap. our results imply that link communities are fundamental building blocks that reveal overlap and hierarchical organization in networks to be two aspects of the same phenomenon."
248,article,"science (new york, n.y.)",,,american association for the advancement of science,2,295,5560,2002,mar,2004-11-12 15:27:40,"sony computer science laboratories, inc., 3-14-13 higashi-gotanda, shinagawa, tokyo 141-0022, japan. kitano@csl.sony.co.jp",systems biology: a brief overview.,"to understand biology at the system level, we must examine the structure and dynamics of cellular and organismal function, rather than the characteristics of isolated parts of a cell or organism. properties of systems, such as robustness, emerge as central issues, and understanding these properties may have an impact on the future of medicine. however, many breakthroughs in experimental devices, advanced software, and analytical methods are required before the achievements of systems biology can live up to their much-touted potential."
217178,book,,,,addison wesley,,,,1999,may,2005-06-02 22:50:32,,modern information retrieval,
1116998,article,molecular systems biology,,,nature publishing group,,3,1,2007,feb,2007-02-21 21:52:46,,how to infer gene networks from expression profiles.,"inferring, or 'reverse-engineering', gene networks can be defined as the process of identifying gene interactions from experimental data through computational analysis. gene expression data from microarrays are typically used for this purpose. here we compared different reverse-engineering algorithms for which ready-to-use software was available and that had been tested on experimental data sets. we show that reverse-engineering algorithms are indeed able to correctly infer regulatory interactions among genes, at least when one performs perturbation experiments complying with the algorithm requirements. these algorithms are superior to classic clustering algorithms for the purpose of finding regulatory interactions among genes, and, although further improvements are needed, have reached a discreet performance for being practically useful."
46,article,nature,,,nature publishing group,4,417,6887,2002,may,2004-11-04 02:28:11,"european molecular biology laboratory, meyerhofstrasse 1, 69012 heidelberg, germany.",comparative assessment of large-scale data sets of protein-protein interactions,"comprehensive protein protein interaction maps promise to reveal many aspects of the complex regulatory network underlying cellular function. recently, large-scale approaches have predicted many new protein interactions in yeast. to measure their accuracy and potential as well as to identify biases, strengths and weaknesses, we compare the methods with each other and with a reference set of previously reported protein interactions."
9753548,article,nat rev genet,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",11,12,10,2011,oct,2011-09-08 17:04:31,,next-generation transcriptome assembly,"transcriptomics studies often rely on partial reference transcriptomes that fail to capture the full catalogue of transcripts and their variations. recent advances in sequencing technologies and assembly algorithms have facilitated the reconstruction of the entire transcriptome by deep {rna} sequencing ({rna}-seq), even without a reference genome. however, transcriptome assembly from billions of {rna}-seq reads, which are often very short, poses a significant informatics challenge. this review summarizes the recent developments in transcriptome assembly approaches — reference-based, de novo and combined strategies — along with some perspectives on transcriptome assembly in the near future."
6756679,article,genome biology,genome biology,,biomed central,8,11,3,2010,mar,2010-03-03 11:51:17,,a scaling normalization method for differential expression analysis of {rna}-seq data.,"the fine detail provided by sequencing-based transcriptome surveys suggests that {rna}-seq is likely to become the platform of choice for interrogating steady state {rna}. in order to discover biologically important changes in expression, we show that normalization continues to be an essential step in the analysis. we outline a simple and effective method for performing normalization and show dramatically improved results for inferring differential expression in simulated and publicly available data sets."
129,article,proceedings of the national academy of sciences,,,national academy of sciences,3,97,21,2000,oct,2004-11-08 17:15:37,"center for polymer studies and department of physics, boston university, boston, ma 02215, usa. amaral@buphy.bu.edu",classes of small-world networks,"we study the statistical properties of a variety of diverse real-world networks. we present evidence of the occurrence of three classes of small-world networks: (a) scale-free networks, characterized by a vertex connectivity distribution that decays as a power law; (b) broad-scale networks, characterized by a connectivity distribution that has a power law regime followed by a sharp cutoff; and (c) single-scale networks, characterized by a connectivity distribution with a fast decaying tail. moreover, we note for the classes of broad-scale and single-scale networks that there are constraints limiting the addition of new links. our results suggest that the nature of such constraints may be the controlling factor for the emergence of different classes of networks."
90413,article,computer mediated communication,,,,,,,2004,dec,2005-02-08 16:06:26,,folksonomies - cooperative classification and communication through shared metadata,
4163618,article,plos one,plos one,,public library of science,,4,3,2009,mar,2009-03-11 02:30:29,,clickstream data yields {high-resolution} maps of science,"intricate maps of science have been created from citation data to visualize the structure of scientific activity. however, most scientific publications are now accessed online. scholarly web portals record detailed log data at a scale that exceeds the number of all existing citations combined. such log data is recorded immediately upon publication and keeps track of the sequences of user requests (clickstreams) that are issued by a variety of users across many different domains. given these advantages of log datasets over citation data, we investigate whether they can produce high-resolution, more current maps of science. over the course of 2007 and 2008, we collected nearly 1 billion user interactions recorded by the scholarly web portals of some of the most significant publishers, aggregators and institutional consortia. the resulting reference data set covers a significant part of world-wide use of scholarly web portals in 2006, and provides a balanced coverage of the humanities, social sciences, and natural sciences. a journal clickstream model, i.e. a first-order markov chain, was extracted from the sequences of user interactions in the logs. the clickstream model was validated by comparing it to the getty research institute's architecture and art thesaurus. the resulting model was visualized as a journal network that outlines the relationships between various scientific domains and clarifies the connection of the social sciences and humanities to the natural sciences. maps of science resulting from large-scale clickstream data provide a detailed, contemporary view of scientific activity and correct the underrepresentation of the social sciences and humanities that is commonly found in citation data."
266187,article,"science (new york, n.y.)",,,american association for the advancement of science,4,290,5500,2000,dec,2005-07-27 22:07:17,"department of psychology, stanford university, stanford, ca 94305, usa. jbt@psych.stanford.edu",a global geometric framework for nonlinear dimensionality reduction.,"scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. the human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. unlike classical techniques such as principal component analysis ({pca}) and multidimensional scaling ({mds}), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. in contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure."
8468415,article,genome biology,,,biomed central ltd,,11,12,2010,dec,2010-12-22 17:45:46,,from {rna}-seq reads to differential expression results,many methods and tools are available for preprocessing high-throughput {rna} sequencing data and detecting differential expression.
4774374,article,bioinformatics,,,oxford university press,1,25,15,2009,aug,2009-06-08 07:52:19,,{soap2}: an improved ultrafast tool for short read alignment,"summary: {soap2} is a significantly improved version of the short oligonucleotide alignment program that both reduces computer memory usage and increases alignment speed at an unprecedented rate. we used a burrows wheeler transformation ({bwt}) compression index to substitute the seed strategy for indexing the reference sequence in the main memory. we tested it on the whole human genome and found that this new algorithm reduced memory usage from 14.7 to 5.4 {gb} and improved alignment speed by 20–30 times. {soap2} is compatible with both single- and paired-end reads. additionally, this tool now supports multiple text and compressed file formats. a consensus builder has also been developed for consensus assembly and {snp} detection from alignment of short reads on a reference {genome.availability}: {http://soap.genomics.org.cncontact}: soap@genomics.org.cn"
1288839,inproceedings,,proceedings of the 16th international conference on world wide web,www,acm,9,,,2007,,2007-05-10 20:43:05,"new york, ny, usa",google news personalization: scalable online collaborative filtering,"several approaches to collaborative filtering have been studied but seldom have studies been reported for large (several millionusers and items) and dynamic (the underlying item set is continually changing) settings. in this paper we describe our approach to collaborative filtering for generating personalized recommendations for users of google news. we generate recommendations using three approaches: collaborative filtering using {minhash} clustering, probabilistic latent semantic indexing ({plsi}), and covisitation counts. we combine recommendations from different algorithms using a linear model. our approach is content agnostic and consequently domain independent, making it easily adaptable for other applications and languages with minimal effort. this paper will describe our algorithms and system setup in detail, and report results of running the recommendations engine on google news."
95914,article,commun. acm,,,acm,5,15,12,1972,dec,2005-02-15 16:43:34,"new york, ny, usa",on the criteria to be used in decomposing systems into modules,"this paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. the effectiveness of a  ” modularization” is dependent upon the criteria used in dividing the system into modules. a system design problem is presented and both a conventional and unconventional decomposition are described. it is shown that the unconventional decompositions have distinct advantages for the goals outlined. the criteria used in arriving at the decompositions are discussed. the unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. an alternative approach to implementation which does not have this effect is sketched."
72879,article,nature biotechnology,,,nature publishing group,7,23,1,2005,jan,2005-10-24 16:46:29,,assessing computational tools for the discovery of transcription factor binding sites,"the prediction of regulatory elements is a problem where computational methods offer great hope. over the past few years, numerous tools have become available for this task. the purpose of the current assessment is twofold: to provide some guidance to users regarding the accuracy of currently available tools in various settings, and to provide a benchmark of data sets for assessing future tools."
4495448,article,nature biotechnology,,,nature publishing group,2,27,5,2009,may,2009-05-10 23:47:19,,how to map billions of short reads onto genomes.,mapping the vast quantities of short sequence fragments produced by next-generation sequencing platforms is a challenge. what programs are available and how do they work?
10401697,article,nature protocols,,,nature research,16,7,3,2012,mar,2012-03-01 16:19:23,,differential gene and transcript expression analysis of {rna}-seq experiments with {tophat} and cufflinks,
163662,book,,,,cambridge university press,,,,2004,mar,2005-04-18 20:01:17,,convex optimization,"{convex optimization problems arise frequently in many different fields. a comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. the focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. the text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.}"
1099,article,personal ubiquitous comput.,personal and ubiquitous computing,,springer-verlag,3,5,1,2001,jan,2004-11-27 18:24:34,"london, uk, uk",understanding and using context,"context is a poorly used source of information in our computing environments. as a result, we have an impoverished understanding of what context is and how it can be used. in this paper, we provide an operational definition of context and discuss the different ways in which context can be used by context-aware applications. we also present the context toolkit, an architecture that supports the building of these context-aware applications. we discuss the features and abstractions in the toolkit that make the task of building applications easier. finally, we introduce a new abstraction, a situation which we believe will provide additional support to application designers."
5907455,article,nature,nature,,nature publishing group,6,461,7265,2009,oct,2009-10-07 21:25:36,,finding the missing heritability of complex diseases.,"genome-wide association studies have identified hundreds of genetic variants associated with complex human diseases and traits, and have provided valuable insights into their genetic architecture. most variants identified so far confer relatively small increments in risk, and explain only a small proportion of familial clustering, leading many to question how the remaining, 'missing' heritability can be explained. here we examine potential sources of missing heritability and propose research strategies, including and extending beyond current genome-wide association approaches, to illuminate the genetics of complex diseases and enhance its potential to enable effective disease prevention or treatment."
227174,article,nature,,,nature publishing group,5,430,6995,2004,jul,2005-06-14 03:31:29,,evidence for dynamically organized modularity in the yeast protein-protein interaction network,
318263,article,genome research,,,cold spring harbor laboratory press,8,12,4,2002,apr,2005-09-13 17:15:06,"department of biology and center for molecular biology of rna, university of california-santa cruz, santa cruz, ca 95064, usa. kent@biology.ucsc.edu",{blat}—the {blast}-like alignment tool,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
2862276,article,nature,,,nature publishing group,3,453,7196,2008,jun,2008-06-05 04:06:24,,understanding individual human mobility patterns,"despite their importance for urban planning1, traffic forecasting2 and the spread of biological3, 4, 5 and mobile viruses6, our understanding of the basic laws governing human motion remains limited owing to the lack of tools to monitor the time-resolved location of individuals. here we study the trajectory of 100,000 anonymized mobile phone users whose position is tracked for a six-month period. we find that, in contrast with the random trajectories predicted by the prevailing l\'{e}vy flight and random walk models7, human trajectories show a high degree of temporal and spatial regularity, each individual being characterized by a time-independent characteristic travel distance and a significant probability to return to a few highly frequented locations. after correcting for differences in travel distances and the inherent anisotropy of each trajectory, the individual travel patterns collapse into a single spatial probability distribution, indicating that, despite the diversity of their travel history, humans follow simple reproducible patterns. this inherent similarity in travel patterns could impact all phenomena driven by human mobility, from epidemic prevention to emergency response, urban planning and agent-based modelling."
4265776,article,"science (new york, n.y.)",,,american association for the advancement of science,4,324,5923,2009,apr,2009-04-03 04:51:25,,distilling free-form natural laws from experimental data.,"for centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. a key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. we propose a principle for the identification of nontriviality. we demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered hamiltonians, lagrangians, and other laws of geometric and momentum conservation. the discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the ""alphabet"" used to describe those systems."
346450,book,,,,cambridge university press,,,,1999,sep,2005-10-09 17:04:18,,"communities of practice: learning, meaning, and identity (learning in doing: social, cognitive and computational perspectives)",{presents a broad conceptual framework for thinking about learning as a process of social participation.}
5248382,article,"science (new york, n.y.)",,,american association for the advancement of science,1,325,5939,2009,jul,2009-07-24 08:30:04,,scale-free networks: a decade and beyond.,"for decades, we tacitly assumed that the components of such complex systems as the cell, the society, or the internet are randomly wired together. in the past decade, an avalanche of research has shown that many real networks, independent of their age, function, and scope, converge to similar architectures, a universality that allowed researchers from different disciplines to embrace network theory as a common paradigm. the decade-old discovery of scale-free networks was one of those events that had helped catalyze the emergence of network science, a new research field with its distinct set of challenges and accomplishments."
95936,article,phys. rev. e,,,american physical society,,70,6,2004,dec,2005-02-15 17:26:20,,finding community structure in very large networks,"the discovery and analysis of community structure in networks is a topic of considerable recent interest within the physics community, but most methods proposed so far are unsuitable for very large networks because of their computational cost. here we present a hierarchical agglomeration algorithm for detecting community structure which is faster than many competing algorithms: its running time on a network with \$n\$ vertices and \$m\$ edges is \$o(md\phantom{\rule{0.2em}{0ex}}\mathrm{log}\phantom{\rule{0.2em}{0ex}}n)\$ where \$d\$ is the depth of the dendrogram describing the community structure. many real-world networks are sparse and hierarchical, with \$m\ensuremath{\sim}n\$ and \$d\ensuremath{\sim}\mathrm{log}\phantom{\rule{0.2em}{0ex}}n\$, in which case our algorithm runs in essentially linear time, \$o(n\phantom{\rule{0.2em}{0ex}}{\mathrm{log}}^{2}\phantom{\rule{0.2em}{0ex}}n)\$. as an example of the application of this algorithm we use it to analyze a network of items for sale on the web site of a large on-line retailer, items in the network being linked if they are frequently purchased by the same buyer. the network has more than 400 000 vertices and \$2\ifmmode\times\else\texttimes\fi{}{10}^{6}\$ edges. we show that our algorithm can extract meaningful communities from this network, revealing large-scale patterns present in the purchasing habits of customers."
1022500,article,science,,,american association for the advancement of science,3,314,5805,2006,dec,2007-01-02 22:43:01,"program for evolutionary dynamics, department of organismic and evolutionary biology, and department of mathematics, harvard university, cambridge, ma 02138, usa. martin\_nowak@harvard.edu",five rules for the evolution of cooperation,"cooperation is needed for evolution to construct new levels of organization. genomes, cells, multicellular organisms, social insects, and human society are all based on cooperation. cooperation means that selfish replicators forgo some of their reproductive potential to help one another. but natural selection implies competition and therefore opposes cooperation unless a specific mechanism is at work. here i discuss five mechanisms for the evolution of cooperation: kin selection, direct reciprocity, indirect reciprocity, network reciprocity, and group selection. for each mechanism, a simple rule is derived that specifies whether natural selection can lead to cooperation."
880918,article,science,,,american association for the advancement of science,6,313,5795,2006,sep,2006-10-02 09:35:58,"broad institute of massachusetts institute of technology and harvard university, cambridge, ma 02142, usa. justin@broad.mit.edu","the connectivity map: using {gene-expression} signatures to connect small molecules, genes, and disease","to pursue a systematic approach to the discovery of functional connections among diseases, genetic perturbation, and drug action, we have created the first installment of a reference collection of gene-expression profiles from cultured human cells treated with bioactive small molecules, together with pattern-matching software to mine these data. we demonstrate that this ""connectivity map"" resource can be used to find connections among small molecules sharing a mechanism of action, chemicals and physiological processes, and diseases and drugs. these results indicate the feasibility of the approach and suggest the value of a large-scale community connectivity map project."
3281478,article,genome biology,,,biomed central ltd,,9,9,2008,sep,2008-09-17 18:30:52,,model-based analysis of {chip}-seq ({macs}),"we present model-based analysis of {chip}-seq data, {macs}, which analyzes data generated by short read sequencers such as solexa's genome analyzer. {macs} empirically models the shift size of {chip}-seq tags, and uses it to improve the spatial resolution of predicted binding sites. {macs} also uses a dynamic poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. {macs} compares favorably to existing {chip}-seq peak-finding algorithms, and is freely available."
270732,article,commun. acm,,,acm,7,18,11,1975,nov,2005-08-01 12:57:53,"new york, ny, usa",a vector space model for automatic indexing,"in a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. an approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. typical evaluation results are shown, demonstating the usefulness of the model."
333353,article,proceedings of the national academy of sciences of the united states of america,,,national academy of sciences,5,102,39,2005,sep,2005-09-27 19:51:25,"departments of molecular cell biology and physics of complex systems, the weizmann institute of science, rehovot 76100, israel.",spontaneous evolution of modularity and network motifs,"biological networks have an inherent simplicity: they are modular with a design that can be separated into units that perform almost independently. furthermore, they show reuse of recurring patterns termed network motifs. little is known about the evolutionary origin of these properties. current models of biological evolution typically produce networks that are highly nonmodular and lack understandable motifs. here, we suggest a possible explanation for the origin of modularity and network motifs in biology. we use standard evolutionary algorithms to evolve networks. a key feature in this study is evolution under an environment (evolutionary goal) that changes in a modular fashion. that is, we repeatedly switch between several goals, each made of a different combination of subgoals. we find that such  ” modularly varying goals” lead to the spontaneous evolution of modular network structure and network motifs. the resulting networks rapidly evolve to satisfy each of the different goals. such switching between related goals may represent biological evolution in a changing environment that requires different combinations of a set of basic biological functions. the present study may shed light on the evolutionary forces that promote structural simplicity in biological networks and offers ways to improve the evolutionary design of engineered systems."
9277950,article,nature,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",6,473,7346,2011,may,2011-05-11 18:54:12,,controllability of complex networks,
613999,electronic,,,,,,,,2006,may,2006-05-05 06:07:46,,collaborative tagging and semiotic dynamics,
141840,article,proceedings of the national academy of sciences,,,national academy of sciences,5,95,25,1998,dec,2005-03-28 01:37:14,"department of genetics, stanford university school of medicine, 300 pasteur avenue, stanford, ca 94305, usa.",cluster analysis and display of genome-wide expression patterns,"a system of cluster analysis for genome-wide expression data from {dna} microarray hybridization is described that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. the output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. we have found in the budding yeast saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. also, coexpression of genes of known function with poorly characterized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently."
222956,article,nature,,,nature publishing group,4,435,7043,2005,jun,2005-12-21 21:12:41,,uncovering the overlapping community structure of complex networks in nature and society,"many complex systems in nature and society can be described in terms of networks capturing the intricate web of connections among the units they are made of1, 2, 3, 4. a key question is how to interpret the global organization of such networks as the coexistence of their structural subunits (communities) associated with more highly interconnected parts. identifying these a priori unknown building blocks (such as functionally related proteins5, 6, industrial sectors7 and groups of people8, 9) is crucial to the understanding of the structural and functional properties of networks. the existing deterministic methods used for large networks find separated communities, whereas most of the actual networks are made of highly overlapping cohesive groups of nodes. here we introduce an approach to analysing the main statistical features of the interwoven sets of overlapping communities that makes a step towards uncovering the modular structure of complex systems. after defining a set of new characteristic quantities for the statistics of communities, we apply an efficient technique for exploring overlapping communities on a large scale. we find that overlaps are significant, and the distributions we introduce reveal universal features of networks. our studies of collaboration, word-association and protein interaction graphs show that the web of communities has non-trivial correlations and specific scaling properties."
4295691,article,"science (new york, n.y.)",,,,3,324,5924,2009,apr,2009-04-10 02:22:29,,coding-sequence determinants of gene expression in escherichia coli.,"synonymous mutations do not alter the encoded protein, but they can influence gene expression. to investigate how, we engineered a synthetic library of 154 genes that varied randomly at synonymous sites, but all encoded the same green fluorescent protein ({gfp}). when expressed in escherichia coli, {gfp} protein levels varied 250-fold across the library. {gfp} messenger {rna} ({mrna}) levels, {mrna} degradation patterns, and bacterial growth rates also varied, but codon bias did not correlate with gene expression. rather, the stability of {mrna} folding near the ribosomal binding site explained more than half the variation in protein levels. in our analysis, {mrna} folding and associated rates of translation initiation play a predominant role in shaping expression levels of individual genes, whereas codon bias influences global translation efficiency and cellular fitness."
249,article,nature,,,nature publishing group,4,420,6912,2002,nov,2004-11-12 15:34:56,"sony computer science laboratories, inc., shinagwa, tokyo, japan. kitano@csl.sony.co.jp",computational systems biology.,"to understand complex biological systems requires the integration of experimental and computational research -- in other words a systems biology approach. computational biology, through pragmatic modelling and theoretical exploration, provides a powerful foundation from which to address critical scientific questions head-on. the reviews in this insight cover many different aspects of this energetic field, although all, in one way or another, illuminate the functioning of modular circuits, including their robustness, design and manipulation. computational systems biology addresses questions fundamental to our understanding of life, yet progress here will lead to practical innovations in medicine, drug discovery and engineering."
678563,article,int. j. comput. vision,international journal of computer vision,,kluwer academic publishers,19,60,2,2004,nov,2006-05-31 16:26:29,"hingham, ma, usa",distinctive image features from {scale-invariant} keypoints,"this paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. the features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in {3d} viewpoint, addition of noise, and change in illumination. the features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. this paper also describes an approach to using these features for object recognition. the recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. this approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
300020,inproceedings,sigops oper. syst. rev.,proceedings of the nineteenth acm symposium on operating systems principles,sosp,acm,14,37,5,2003,oct,2005-08-21 13:10:35,"new york, ny, usa",the google file system,an abstract is not available.
5961524,article,nature,,,macmillan publishers limited. all rights reserved,4,461,7268,2009,oct,2009-10-18 20:18:43,,genome evolution and adaptation in a long-term experiment with escherichia coli,"the relationship between rates of genomic evolution and organismal adaptation remains uncertain, despite considerable interest. the feasibility of obtaining genome sequences from experimentally evolving populations offers the opportunity to investigate this relationship with new precision. here we sequence genomes sampled through 40,000 generations from a laboratory population of escherichia coli. although adaptation decelerated sharply, genomic evolution was nearly constant for 20,000 generations. such clock-like regularity is usually viewed as the signature of neutral evolution, but several lines of evidence indicate that almost all of these mutations were beneficial. this same population later evolved an elevated mutation rate and accumulated hundreds of additional mutations dominated by a neutral signature. thus, the coupling between genomic and adaptive evolution is complex and can be counterintuitive even in a constant environment. in particular, beneficial substitutions were surprisingly uniform over time, whereas neutral substitutions were highly variable."
4238864,article,genome biology,,,,,10,3,2009,,2009-03-31 08:39:38,,evaluation of next generation sequencing platforms for population targeted sequencing studies.,
4041910,article,science,,,american association for the advancement of science,3,323,5916,2009,feb,2009-02-13 01:51:55,,network analysis in the social sciences,"over the past decade, there has been an explosion of interest in network research across the physical and social sciences. for social scientists, the theory of networks has been a gold mine, yielding explanations for social phenomena in a wide variety of disciplines from psychology to economics. here, we review the kinds of things that social scientists have tried to explain using social network analysis and provide a nutshell description of the basic assumptions, goals, and explanatory mechanisms prevalent in the field. we hope to contribute to a dialogue among researchers from across the physical and social sciences who share a common interest in understanding the antecedents and consequences of network phenomena."
498902,article,science,,,american association for the advancement of science,3,297,5584,2002,aug,2006-02-08 15:44:54,"laboratory of cancer biology, center for studies in physics and biology, rockefeller university, new york, ny 10021, usa. elowitm@rockefeller.edu",stochastic gene expression in a single cell,"clonal populations of cells exhibit substantial phenotypic variation. such heterogeneity can be essential for many biological processes and is conjectured to arise from stochasticity, or noise, in gene expression. we constructed strains of escherichia coli that enable detection of noise and discrimination between the two mechanisms by which it is generated. both stochasticity inherent in the biochemical process of gene expression (intrinsic noise) and fluctuations in other cellular components (extrinsic noise) contribute substantially to overall variation. transcription rate, regulatory dynamics, and genetic factors control the amplitude of noise. these results establish a quantitative foundation for modeling noise in genetic networks and reveal how low intracellular copy numbers of molecules can fundamentally limit the precision of gene regulation."
8493482,article,nat rev genet,,,"nature publishing group, a division of macmillan publishers limited. all rights reserved.",11,12,2,2011,feb,2010-12-30 11:37:09,,"{rna} sequencing: advances, challenges and opportunities",
560813,article,nature,,,nature publishing group,6,440,7084,2006,mar,2006-03-30 17:19:25,,global landscape of protein complexes in the yeast saccharomyces cerevisiae.,"identification of protein-protein interactions often provides insight into protein function, and many cellular processes are performed by stable protein complexes. we used tandem affinity purification to process 4,562 different tagged proteins of the yeast saccharomyces cerevisiae. each preparation was analysed by both matrix-assisted laser desorption/ionization-time of flight mass spectrometry and liquid chromatography tandem mass spectrometry to increase coverage and accuracy. machine learning was used to integrate the mass spectrometry scores and assign probabilities to the protein-protein interactions. among 4,087 different proteins identified with high confidence by mass spectrometry from 2,357 successful purifications, our core data set (median precision of 0.69) comprises 7,123 protein-protein interactions involving 2,708 proteins. a markov clustering algorithm organized these interactions into 547 protein complexes averaging 4.9 subunits per complex, about half of them absent from the {mips} database, as well as 429 additional interactions between pairs of complexes. the data (all of which are available online) will help future studies on individual proteins as well as functional genomics and systems biology."
77453,article,,cscw,,acm press,9,,,2004,,2005-01-13 12:13:54,,"blogging as social activity, or, would you let 900 million people read your diary?",
957831,article,nature,nature,,nature publishing group,10,444,7118,2006,nov,2006-11-22 18:15:13,,global variation in copy number in the human genome.,"copy number variation ({cnv}) of {dna} sequences is functionally significant but has yet to be fully ascertained. we have constructed a first-generation {cnv} map of the human genome through the study of 270 individuals from four populations with ancestry in europe, africa or asia (the {hapmap} collection). {dna} from these individuals was screened for {cnv} using two complementary technologies: single-nucleotide polymorphism ({snp}) genotyping arrays, and clone-based comparative genomic hybridization. a total of 1,447 copy number variable regions ({cnvrs}), which can encompass overlapping or adjacent gains or losses, covering 360 megabases (12\% of the genome) were identified in these populations. these {cnvrs} contained hundreds of genes, disease loci, functional elements and segmental duplications. notably, the {cnvrs} encompassed more nucleotide content per genome than {snps}, underscoring the importance of {cnv} in genetic diversity and evolution. the data obtained delineate linkage disequilibrium patterns for many {cnvs}, and reveal marked variation in copy number among populations. we also demonstrate the utility of this resource for genetic disease studies."
108703,article,science,,,american association for the advancement of science,3,290,5500,2000,dec,2005-03-01 19:34:33,,nonlinear dimensionality reduction by locally linear embedding,"many areas of science depend on exploratory data analysis and visualization. the need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. here, we introduce locally linear embedding ({lle}), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. unlike clustering methods for local dimensionality reduction, {lle} maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. by exploiting the local symmetries of linear reconstructions, {lle} is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text."
531300,article,the journal of chemical physics,,,aip,5,21,6,1953,jun,2006-03-06 13:34:11,,equation of state calculations by fast computing machines,"a general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. the method consists of a modified monte carlo integration over configuration space. results for the two-dimensional rigid-sphere system have been obtained on the los alamos {maniac} and are presented here. these results are compared to the free volume equation of state and to a four-term virial coefficient expansion. the journal of chemical physics is copyrighted by the american institute of physics."
114322,book,,,,addison-wesley professional,,,,2001,apr,2005-03-04 21:41:20,,the wiki way: quick collaboration on the web,"{suitable for system administrators or managers seeking an affordable content-management solution, <i>the wiki way</i> shows off how to take advantage of wiki collaborative software, which allows users to post and edit content remotely. this book is all you need to get up and running with this exciting (and free) way to build and manage content.<p>  this text is first and foremost a guide to what wiki software is and how to install, customize, and administer it within your organization. early sections discuss the advantages of wiki web sites, which allow all users to add and edit content. while it might sound like a free-for-all, the authors suggest such web sites have been used successfully in research, business, and education to document project designs, for brainstorming, and for otherwise creating content in a collaborative fashion. case studies for such organizations as georgia tech, new york times digital, and motorola give a glimpse of wiki used in real settings, so you will get a sense of what to expect.<p>  this book is also a guide to the nuts and bolts of downloading and installing wiki and customizing it for your site. sections on basic tweaks to wiki's perl scripts will let you customize your site to match your organization's needs. standout material includes almost three dozen customization tips. this volume is illustrated with actual screen shots of wiki, so you can get a sense of what it is like for users to work together in such an unrestricted fashion. <p>  throughout the text, the authors are suitably upbeat about wiki's prospects for wider adoption, but they are realistic enough to note compromises (such as requiring passwords and restricting edit rights) required in business settings. they also survey the field of wiki open-source projects and clones, as well as other similar content-management solutions (such as zope and the emerging webdav standard).<p>  while it's hard to predict whether wiki-based web sites are for everyone, this book presents the pros and cons of a potentially exciting and useful tool that promotes collaborative content creation. this title can help any organization get going with a wiki web site, from the standpoint of planning, deployment, and basic administration. <i>--richard dragan</i><p>  <b>topics covered:</b><ul><li>collaboration tools explained <li>web-based collaboration <li>webdav <li>introduction to wiki <li>user conventions with wiki <li>survey of wiki open-source projects and clones <li>installing wiki (including apache web server and security issues) <li>using wiki (making notes, wiki used as a pim, content management and links, page editing) <li>how to structure wiki content (suggested default structure: pros and cons) <li>customizing wiki <li>tour of wiki perl scripts and tips for customizing your wiki site <li>wiki add-ons (including spellchecking and uploading files) <li>administration in wiki (viewing events, controlling access and authentication, database administration, and debugging techniques) <li>guidelines for wiki projects (dos and don'ts) <li>wiki case studies for education <li>business and research</ul> }"
166220,article,genome biology,genome biology,,biomed central,-64,5,10,2004,,2005-04-21 14:38:20,"department of biostatistical science, dana-farber cancer institute, 44 binney st, boston, ma 02115, usa. rgentlem@jimmy.harvard.edu",bioconductor: open software development for computational biology and bioinformatics.,"the bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. the goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. we describe details of our aims and methods, identify current challenges, compare bioconductor to other open bioinformatics projects, and provide working examples."
7280291,article,nat rev genet,,,nature publishing group,10,11,7,2010,jul,2010-06-09 09:59:02,,next-generation genomics: an integrative approach,
238,article,nature,,,nature publishing group,3,407,6804,2000,oct,2004-11-12 15:04:14,"department of physics, university of notre dame, indiana 46556, usa.",the large-scale organization of metabolic networks,"in a cell or microorganism, the processes that generate mass, energy, information transfer and cell-fate specification are seamlessly integrated through a complex network of cellular constituents and reactions1. however, despite the key role of these networks in sustaining cellular functions, their large-scale structure is essentially unknown. here we present a systematic comparative mathematical analysis of the metabolic networks of 43 organisms representing all three domains of life. we show that, despite significant variation in their individual constituents and pathways, these metabolic networks have the same topological scaling properties and show striking similarities to the inherent organization of complex non-biological systems2. this may indicate that metabolic organization is not only identical for all living organisms, but also complies with the design principles of robust and error-tolerant scale-free networks2, 3, 4, 5, and may represent a common blueprint for the large-scale organization of interactions among all cellular constituents."
3819677,article,nature protocols,nat. protocols,,nature publishing group,13,4,1,2009,dec,2008-12-22 20:45:42,,systematic and integrative analysis of large gene lists using {david} bioinformatics resources.,"{david} bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. this protocol explains how to use {david}, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. the procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. by following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies."
115243,inproceedings,,proceedings of the ninth acm sigkdd international conference on knowledge discovery and data mining,kdd,acm,9,,,2003,,2005-03-06 14:42:24,"new york, ny, usa",maximizing the spread of influence through a social network,"models for the processes by which ideas and influence propagate through a social network have been studied in a number of domains, including the diffusion of medical and technological innovations, the sudden and widespread adoption of various strategies in game-theoretic settings, and the effects of ""word of mouth"" in the promotion of new products. recently, motivated by the design of viral marketing strategies, domingos and richardson posed a fundamental algorithmic problem for such social network processes: if we can try to convince a subset of individuals to adopt a new product or innovation, and the goal is to trigger a large cascade of further adoptions, which set of individuals should we {target?we} consider this problem in several of the most widely studied models in social network analysis. the optimization problem of selecting the most influential nodes is {np}-hard here, and we provide the first provable approximation guarantees for efficient algorithms. using an analysis framework based on submodular functions, we show that a natural greedy strategy obtains a solution that is provably within 63\% of optimal for several classes of models; our framework suggests a general approach for reasoning about the performance guarantees of algorithms for these types of influence problems in social {networks.we} also provide computational experiments on large collaboration networks, showing that in addition to their provable guarantees, our approximation algorithms significantly out-perform node-selection heuristics based on the well-studied notions of degree centrality and distance centrality from the field of social networks."
801422,inproceedings,,proceedings of the 15th international conference on world wide web,www,acm,9,,,2006,,2006-08-14 22:57:24,"new york, ny, usa",exploring social annotations for the semantic web,"in order to obtain a machine understandable semantics for web resources, research on the semantic web tries to annotate web resources with concepts and relations from explicitly defined formal ontologies. this kind of formal annotation is usually done manually or semi-automatically. in this paper, we explore a complement approach that focuses on the ""social annotations of the web"" which are annotations manually made by normal web users without a pre-defined formal ontology. compared to the formal annotations, although social annotations are coarse-grained, informal and vague, they are also more accessible to more people and better reflect the web resources' meaning from the users' point of views during their actual usage of the web resources. using a social bookmark service as an example, we show how emergent semantics [2] can be statistically derived from the social annotations. furthermore, we apply the derived emergent semantics to discover and search shared web bookmarks. the initial evaluation on our implementation shows that our method can effectively discover semantically related web bookmarks that current social bookmark service can not discover easily."
363166,article,interactions,,,acm,9,7,6,2000,,2005-10-24 00:39:19,"new york, ny, usa",social navigation: techniques for building more usable systems,note: {ocr} errors may be found in this reference list extracted from the full text article.  {acm} has opted to expose the complete list rather than only correct and linked references.
572874,article,nature genetics,,,nature publishing group,10,34,2,2003,may,2006-04-02 03:35:56,"computer science department, stanford university, stanford, california, 94305, usa. eran@cs.stanford.edu",module networks: identifying regulatory modules and their condition-specific regulators from gene expression data,"much of a cell's activity is organized as a network of interacting modules: sets of genes coregulated to respond to different conditions. we present a probabilistic method for identifying regulatory modules from gene expression data. our procedure identifies modules of coregulated genes, their regulators and the conditions under which regulation occurs, generating testable hypotheses in the form 'regulator x regulates module y under conditions w'. we applied the method to a saccharomyces cerevisiae expression data set, showing its ability to identify functionally coherent modules and their correct regulators. we present microarray experiments supporting three novel predictions, suggesting regulatory roles for previously uncharacterized proteins."
302050,article,"science (new york, n.y.)",,,american association for the advancement of science,4,297,5586,2002,aug,2005-08-24 03:24:55,,hierarchical organization of modularity in metabolic networks.,"spatially or chemically isolated functional modules composed of several cellular components and carrying discrete functions are considered fundamental building blocks of cellular organization, but their presence in highly integrated biochemical networks lacks quantitative support. here, we show that the metabolic networks of 43 distinct organisms are organized into many small, highly connected topologic modules that combine in a hierarchical manner into larger, less cohesive units, with their number and degree of clustering following a power law. within escherichia coli, the uncovered hierarchical modularity closely overlaps with known metabolic functions. the identified network architecture may be generic to system-level cellular organization."
438129,article,nature,,,nature publishing group,1,438,7070,2005,dec,2005-12-17 01:31:29,,internet encyclopaedias go head to head,"jimmy wales' wikipedia comes close to britannica in terms of the accuracy of its science entries, a nature investigation finds. {update}: see details of how the data were collected for this article in the supplementary information. {update} 2 (28 march 2006). the results reported in this news story and their interpretation have been disputed by encyclopaedia britannica. nature responded to these objections . one of the extraordinary stories of the internet age is that of wikipedia, a free online encyclopaedia that anyone can edit. this radical and rapidly growing publication, which includes close to 4 million entries, is now a much-used resource."
778023,article,science,,,american association for the advancement of science,3,313,5786,2006,jul,2006-07-28 16:18:56,,reducing the dimensionality of data with neural networks,"high-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. gradient descent can be used for fine-tuning the weights in such ""autoencoder"" networks, but this works well only if the initial weights are close to a good solution. we describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
2620752,article,genome research,,,cold spring harbor laboratory press,8,18,4,2008,apr,2008-04-01 19:32:16,,protein networks in disease.,"during a decade of proof-of-principle analysis in model organisms, protein networks have been used to further the study of molecular evolution, to gain insight into the robustness of cells to perturbation, and for assignment of new protein functions. following these analyses, and with the recent rise of protein interaction measurements in mammals, protein networks are increasingly serving as tools to unravel the molecular basis of disease. we review promising applications of protein networks to disease in four major areas: identifying new disease genes; the study of their network properties; identifying disease-related subnetworks; and network-based disease classification. applications in infectious disease, personalized medicine, and pharmacology are also forthcoming as the available protein network information improves in quality and coverage."
346599,article,networker,,,acm,7,9,3,2005,sep,2005-10-10 04:30:49,"new york, ny, usa",the power of collective intelligence,"though the overall health of the tech sector may have looked bleak a few years back---at least in the eyes of financial analysts---a blend of old and new ideas, evolving technologies, and changing cultural values have recently given the online world new vigor. with content derived primarily by community contribution, popular and influential services like flickr and wikipedia represent the emergence of ""collective intelligence"" as the new driving force behind the evolution of the internet."
105949,book,,,,chapman and hall/crc,,,,2003,jul,2005-02-27 14:40:33,,"bayesian data analysis, second edition (chapman \& {hall/crc} texts in statistical science)","{incorporating new and updated information, this second edition of the bestselling text in bayesian data analysis continues to emphasize practice over theory, describing how to conceptualize, perform, and critique statistical analyses from a bayesian perspective. its world-class authors provide guidance on all aspects of bayesian data analysis and include examples of real statistical analyses, based on their own research, that demonstrate how to solve complicated problems. changes in the new edition include: \&\#183;stronger focus on mcmc\&\#183;revision of the computational advice in part iii\&\#183;new chapters on nonlinear models and decision analysis\&\#183;several additional applied examples from the authors' recent research\&\#183;additional chapters on current models for bayesian data analysis such as nonlinear models, generalized linear mixed models, and more\&\#183;reorganization of chapters 6 and 7 on model checking and data collectionbayesian computation is currently at a stage where there are many reasonable ways to compute any given posterior distribution. however, the best approach is not always clear ahead of time. reflecting this, the new edition offers a more pluralistic presentation, giving advice on performing computations from many perspectives while making clear the importance of being aware that there are different ways to implement any given iterative simulation computation. the new approach, additional examples, and updated information make bayesian data analysis an excellent introductory text and a reference that working scientists will use throughout their professional life.}"
171426,article,"knowledge and data engineering, ieee transactions on",,,,15,17,6,2005,,2005-04-26 13:50:21,,toward the next generation of recommender systems: a survey of the {state-of-the-art} and possible extensions,"this paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. this paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. these extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multcriteria ratings, and a provision of more flexible and less intrusive types of recommendations."
2283763,article,proceedings of the national academy of sciences,,,national academy of sciences,5,105,4,2008,jan,2008-01-24 08:30:49,,maps of random walks on complex networks reveal community structure,"to comprehend the multipartite organization of large-scale biological and social systems, we introduce an information theoretic approach that reveals community structure in weighted and directed networks. we use the probability flow of random walks on a network as a proxy for information flows in the real system and decompose the network into modules by compressing a description of the probability flow. the result is a map that both simplifies and highlights the regularities in the structure and their relationships. we illustrate the method by making a map of scientific communication as captured in the citation patterns of >6,000 journals. we discover a multicentric organization with fields that vary dramatically in size and degree of integration into the network of science. along the backbone of the network—including physics, chemistry, molecular biology, and medicine—information flows bidirectionally, but the map reveals a directional pattern of citation from the applied fields to the basic sciences."
6791223,article,genomics,,,,12,95,6,2010,jun,2010-03-10 11:26:23,,assembly algorithms for next-generation sequencing data,"the emergence of next-generation sequencing platforms led to resurgence of research in whole-genome shotgun assembly algorithms and software. {dna} sequencing data from the roche 454, {illumina/solexa}, and {abi} {solid} platforms typically present shorter read lengths, higher coverage, and different error profiles compared with sanger sequencing data. since 2005, several assembly software packages have been created or revised specifically for de novo assembly of next-generation sequencing data. this review summarizes and compares the published descriptions of packages named {ssake}, {sharcgs}, {vcake}, newbler, celera assembler, euler, velvet, {abyss}, {allpaths}, and {soapdenovo}. more generally, it compares the two standard methods known as the de bruijn graph approach and the overlap/layout/consensus approach to assembly."
6497618,article,bioinformatics,,,oxford university press,10,26,4,2010,feb,2010-01-07 10:57:33,,bioinformatics challenges for genome-wide association studies,"motivation: the sequencing of the human genome has made it possible to identify an informative set of >1 million single nucleotide polymorphisms ({snps}) across the genome that can be used to carry out genome-wide association studies ({gwass}). the availability of massive amounts of {gwas} data has necessitated the development of new biostatistical methods for quality control, imputation and analysis issues including multiple testing. this work has been successful and has enabled the discovery of new associations that have been replicated in multiple studies. however, it is now recognized that most {snps} discovered via {gwas} have small effects on disease susceptibility and thus may not be suitable for improving health care through genetic testing. one likely explanation for the mixed results of {gwas} is that the current biostatistical analysis paradigm is by design agnostic or unbiased in that it ignores all prior knowledge about disease pathobiology. further, the linear modeling framework that is employed in {gwas} often considers only one {snp} at a time thus ignoring their genomic and environmental context. there is now a shift away from the biostatistical approach toward a more holistic approach that recognizes the complexity of the genotype–phenotype relationship that is characterized by significant heterogeneity and gene–gene and gene–environment interaction. we argue here that bioinformatics has an important role to play in addressing the complexity of the underlying genetic basis of common human diseases. the goal of this review is to identify and discuss those {gwas} challenges that will require computational methods."
1453145,article,j. inf. sci.,journal of information science,,"sage publications, inc.",6,34,1,2008,feb,2007-07-13 01:16:09,"thousand oaks, ca, usa",the folksonomy tag cloud: when is it useful?,"the weighted list, known popularly as a 'tag cloud', has appeared on many popular folksonomy-based web-sites. flickr, delicious, technorati and many others have all featured a tag cloud at some point in their history. however, it is unclear whether the tag cloud is actually useful as an aid to finding information. we conducted an experiment, giving participants the option of using a tag cloud or a traditional search interface to answer various questions. we found that where the information-seeking task required specific information, participants preferred the search interface. conversely, where the information-seeking task was more general, participants preferred the tag cloud. while the tag cloud is not without value, it is not sufficient as the sole means of navigation for a folksonomy-based dataset. 10.1177/0165551506078083"
557229,article,biopolymers,,,"wiley subscription services, inc., a wiley company",60,22,12,1983,dec,2006-03-20 18:16:12,"biophysics department, max planck institute of medical research, 6900 heidelberg, federal republic of germany",dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features.,"for a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. we have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern-recognition process of hydrogen-bonded and geometrical features extracted from x-ray coordinates. cooperative secondary structure is recognized as repeats of the elementary hydrogen-bonding patterns  ” turn” and  ” bridge.” repeating turns are  ” helices,” repeating bridges are  ” ladders,” connected ladders are  ” sheets.” geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. local chain  ” chirality” is the torsional handedness of four consecutive cα positions and is positive for right-handed helices and negative for ideal twisted β-sheets. curved pieces are defined as  ” bends.” solvent  ” exposure” is given as the number of water molecules in possible contact with a residue. the end result is a compilation of the primary structure, including {ss} bonds, secondary structure, and solvent exposure of 62 different globular proteins. the presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. the dictionary is also available in computer-readable form for protein structure prediction work."
1369386,article,nature,,,nature publishing group,17,447,7145,2007,jun,2007-06-07 06:47:43,,"genome-wide association study of 14,000 cases of seven common diseases and 3,000 shared controls.","there is increasing evidence that genome-wide association ({gwa}) studies represent a powerful approach to the identification of genes involved in common human diseases. we describe a joint {gwa} study (using the affymetrix {genechip} {500k} mapping array set) undertaken in the british population, which has examined approximately 2,000 individuals for each of 7 major diseases and a shared set of approximately 3,000 controls. case-control comparisons identified 24 independent association signals at p < 5 x 10(-7): 1 in bipolar disorder, 1 in coronary artery disease, 9 in crohn's disease, 3 in rheumatoid arthritis, 7 in type 1 diabetes and 3 in type 2 diabetes. on the basis of prior findings and replication studies thus-far completed, almost all of these signals reflect genuine susceptibility effects. we observed association at many previously identified loci, and found compelling evidence that some loci confer risk for more than one of the diseases studied. across all diseases, we identified a large number of further signals (including 58 loci with single-point p values between 10(-5) and 5 x 10(-7)) likely to yield additional susceptibility loci. the importance of appropriately large samples was confirmed by the modest effect sizes observed at most loci identified. this study thus represents a thorough validation of the {gwa} approach. it has also demonstrated that careful use of a shared control group represents a safe and effective approach to {gwa} analyses of multiple disease phenotypes; has generated a genome-wide genotype database for future studies of common diseases in the british population; and shown that, provided individuals with {non-european} ancestry are excluded, the extent of population stratification in the british population is generally modest. our findings offer new avenues for exploring the pathophysiology of these important disorders. we anticipate that our data, results and software, which will be widely available to other investigators, will provide a powerful resource for human genetics research."
4222049,article,"intelligent systems, ieee","intelligent systems, ieee",,ieee,4,24,2,2009,mar,2009-03-26 12:22:08,"los alamitos, ca, usa",the unreasonable effectiveness of data,"at brown university, there is excitement of having access to the brown corpus, containing one million english words. since then, we have seen several notable corpora that are about 100 times larger, and in 2006, google released a trillion-word corpus with frequency counts for all sequences up to five words long. in some ways this corpus is a step backwards from the brown corpus: it's taken from unfiltered web pages and thus contains incomplete sentences, spelling errors, grammatical errors, and all sorts of other errors. it's not annotated with carefully hand-corrected part-of-speech tags. but the fact that it's a million times larger than the brown corpus outweighs these drawbacks. a trillion-word corpus - along with other web-derived corpora of millions, billions, or trillions of links, videos, images, tables, and user interactions - captures even very rare aspects of human behavior. so, this corpus could serve as the basis of a complete model for certain tasks - if only we knew how to extract the model from the data."
363614,article,science,,,american association for the advancement of science,4,303,5663,2004,mar,2005-10-24 14:40:13,"departments of molecular cell biology, physics of complex systems, and computer science, weizmann institute of science, rehovot 76100, israel.",superfamilies of evolved and designed networks,"complex biological, technological, and sociological networks can be of very different sizes and connectivities, making it difficult to compare their structures. here we present an approach to systematically study similarity in the local structure of networks, based on the significance profile ({sp}) of small subgraphs in the network compared to randomized networks. we find several superfamilies of previously unrelated networks with very similar {sps}. one superfamily, including transcription networks of microorganisms, represents  ” rate-limited” information-processing networks strongly constrained by the response time of their components. a distinct superfamily includes protein signaling, developmental genetic networks, and neuronal wiring. additional superfamilies include power grids, protein-structure networks and geometric networks, world wide web links and social networks, and word-adjacency networks from different languages."
272363,article,briefings in bioinformatics,,,oxford university press,14,6,1,2005,mar,2005-08-03 23:18:37,"department of medical informatics and clinical epidemiology, school of medicine, oregon health \& science university, 3181 s.w. sam jackson park road, portland, or 97239-309, usa. cohenaa@ohsu.edu",a survey of current work in biomedical text mining,"the volume of published biomedical research, and therefore the underlying biomedical knowledge base, is expanding at an increasing rate. among the tools that can aid researchers in coping with this information overload are text mining and knowledge extraction. significant progress has been made in applying text mining to named entity recognition, text classification, terminology extraction, relationship extraction and hypothesis generation. several research groups are constructing integrated flexible text-mining systems intended for multiple uses. the major challenge of biomedical text mining over the next 5–10 years is to make these systems useful to biomedical researchers. this will require enhanced access to full text, better understanding of the feature space of biomedical literature, better methods for measuring the usefulness of systems to users, and continued cooperation with the biomedical research community to ensure that their needs are addressed."
205973,book,,,,harvard business school press,,,,2002,feb,2005-05-20 10:45:48,,the social life of information,
851137,article,the journal of physiology,,,the physiological society,44,117,4,1952,aug,2006-09-20 11:57:06,,a quantitative description of membrane current and its application to conduction and excitation in nerve.,
466068,article,nature,,,nature publishing group,5,431,7004,2004,sep,2006-01-16 14:51:12,,transcriptional regulatory code of a eukaryotic genome,"{dna}-binding transcriptional regulators interpret the genome's regulatory code by binding to specific sequences to induce or repress gene expression1. comparative genomics has recently been used to identify potential cis-regulatory sequences within the yeast genome on the basis of phylogenetic conservation2, 3, 4, 5, 6, but this information alone does not reveal if or when transcriptional regulators occupy these binding sites. we have constructed an initial map of yeast's transcriptional regulatory code by identifying the sequence elements that are bound by regulators under various conditions and that are conserved among saccharomyces species. the organization of regulatory elements in promoters and the environment-dependent use of these elements by regulators are discussed. we find that environment-specific use of regulatory elements predicts mechanistic models for the function of a large population of yeast's transcriptional regulators."
3483363,article,nature,nature,,nature publishing group,6,456,7218,2008,nov,2008-11-05 21:28:59,,accurate whole human genome sequencing using reversible terminator chemistry,"{dna} sequence information underpins genetic research, enabling discoveries of important biological or medical benefit. sequencing projects have traditionally used long (400–800 base pair) reads, but the existence of reference sequences for the human and many other genomes makes it possible to develop new, fast approaches to re-sequencing, whereby shorter reads are compared to a reference to identify intraspecies genetic variation. here we report an approach that generates several billion bases of accurate nucleotide sequence per experiment at low cost. single molecules of {dna} are attached to a flat surface, amplified in situ and used as templates for synthetic sequencing with fluorescent reversible terminator deoxyribonucleotides. images of the surface are analysed to generate high-quality sequence. we demonstrate application of this approach to human genome sequencing on flow-sorted x chromosomes and then scale the approach to determine the genome sequence of a male yoruba from ibadan, nigeria. we build an accurate consensus sequence from >30 average depth of paired 35-base reads. we characterize four million single-nucleotide polymorphisms and four hundred thousand structural variants, many of which were previously unknown. our approach is effective for accurate, rapid and economical whole-genome re-sequencing and many other biomedical applications."
167555,article,j. mach. learn. res.,,,jmlr.org,25,3,,2003,mar,2005-04-22 18:17:10,"cambridge, ma, usa",an introduction to variable and feature selection,"variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. these areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. the objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. the contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods."
658201,article,commun. acm,,,acm,5,49,4,2006,apr,2006-07-08 21:10:21,"new york, ny, usa",exploratory search: from finding to understanding,research tools critical for exploratory search success involve the creation of new interfaces that move the process beyond predictable fact retrieval.
239528,article,"biostatistics (oxford, england)",,,oxford university press,15,4,2,2003,apr,2005-06-28 16:56:27,"department of biostatistics, johns hopkins university, baltimore, md 21205, usa. rafa@jhu.edu","exploration, normalization, and summaries of high density oligonucleotide array probe level data.","in this paper we report exploratory analyses of high-density oligonucleotide array data from the affymetrix {genechip} system with the objective of improving upon currently used measures of gene expression. our analyses make use of three data sets: a small experimental study consisting of five {mgu74a} mouse {genechip} arrays, part of the data from an extensive spike-in study conducted by gene logic and wyeth's genetics institute involving 95 {hg}-{u95a} human {genechip} arrays; and part of a dilution study conducted by gene logic involving 75 {hg}-{u95a} {genechip} arrays. we display some familiar features of the perfect match and mismatch probe ({pm} and {mm}) values of these data, and examine the variance-mean relationship with probe-level data from probes believed to be defective, and so delivering noise only. we explain why we need to normalize the arrays to one another using probe level intensities. we then examine the behavior of the {pm} and {mm} using spike-in data and assess three commonly used summary measures: affymetrix's (i) average difference ({avdiff}) and (ii) {mas} 5.0 signal, and (iii) the li and wong multiplicative model-based expression index ({mbei}). the exploratory data analyses of the probe level data motivate a new summary measure that is a robust multi-array average ({rma}) of background-adjusted, normalized, and log-transformed {pm} values. we evaluate the four expression summary measures using the dilution study data, assessing their behavior in terms of bias, variance and (for {mbei} and {rma}) model fit. finally, we evaluate the algorithms in terms of their ability to detect known levels of differential expression using the spike-in data. we conclude that there is no obvious downside to using {rma} and attaching a standard error ({se}) to this quantity using a linear model which removes probe-specific affinities."
211804,article,nucleic acids research,,,oxford university press,5,32,5,2004,mar,2005-05-26 10:24:04,bob@drive5.com,{muscle}: multiple sequence alignment with high accuracy and high throughput,"we describe {muscle}, a new computer program for creating multiple alignments of protein sequences. elements of the algorithm include fast distance estimation using kmer counting, progressive alignment using a new profile function we call the log‐expectation score, and refinement using tree‐dependent restricted partitioning. the speed and accuracy of {muscle} are compared with {t‐coffee}, {mafft} and {clustalw} on four test sets of reference alignments: {balibase}, {sabmark}, {smart} and a new benchmark, {prefab}. {muscle} achieves the highest, or joint highest, rank in accuracy on each of these sets. without refinement, {muscle} achieves average accuracy statistically indistinguishable from {t‐coffee} and {mafft}, and is the fastest of the tested methods for large numbers of sequences, aligning 5000 sequences of average length 350 in 7 min on a current desktop computer. the {muscle} program, source code and {prefab} test data are freely available at http://www.drive5. com/muscle."
4280,article,plos biol,,,public library of science,,2,12,2004,dec,2004-12-19 17:14:50,"laboratory of populations, rockefeller and columbia universities, new york, new york, usa. cohen@rockefeller.edu","mathematics is biology's next microscope, only better; biology is mathematics' next physics, only better",joel cohen offers a historical and prospective analysis of the relationship between mathematics and biology.
149386,book,,,,harvard business review press,,,,2000,mar,2005-04-05 02:41:12,,the social life of information,"{how many times has your pc crashed today? while gordon moore's now famous law projecting the doubling of computer power every 18 months has more than borne itself out, it's too bad that a similar trajectory projecting the reliability and usefulness of all that power didn't come to pass, as well. advances in information technology are most often measured in the cool numbers of megahertz, throughput, and bandwidth--but, for many us, the experience of these advances may be better measured in hours of frustration.<p>  the gap between the hype of the information age and its reality is often wide and deep, and it's into this gap that john seely brown and paul duguid plunge. not that these guys are luddites--far from it. brown, the chief scientist at xerox and the director of its palo alto research center (parc), and duguid, a historian and social theorist who also works with parc, measure how information technology interacts and meshes with the social fabric. they write, ""technology design often takes aim at the surface of life. there it undoubtedly scores lots of worthwhile hits. but such successes can make designers blind to the difficulty of more serious challenges--primarily the resourcefulness that helps embed certain ways of doing things deep in our lives.""<p>  the authors cast their gaze on the many trends and ideas proffered by infoenthusiasts over the years, such as software agents, ""still a long way from the predicted insertion into the woof and warp of ordinary life""; the electronic cottage that alvin toffler wrote about 20 years ago and has yet to be fully realized; and the rise of knowledge management and the challenges it faces trying to manage how people actually work and learn in the workplace. their aim is not to pass judgment but to help remedy the tunnel vision that prevents technologists from seeing larger the social context that their ideas must ultimately inhabit. <i>the social life of information</i> is a thoughtful and challenging read that belongs on the bookshelf of anyone trying to invent or make sense of the new world of information. <i>--harry c. edwards</i>} {<b>to see the future we can build with information technology, we must look beyond mere information to the social context that creates and gives meaning to it.</b><p>for years pundits have predicted that information technology will obliterate the need for almost everything-from travel to supermarkets to business organizations to social life itself. individual users, however, tend to be more skeptical.  beaten down by info-glut and exasperated by computer systems fraught with software crashes, viruses, and unintelligible error messages, they find it hard to get a fix on the true potential of the digital revolution.<p>john seely brown and paul duguid help us to see through frenzied visions of the future to the real forces for change in society.  they argue that the gap between digerati hype and end-user gloom is largely due to the ""tunnel vision"" that information-driven technologies breed.  we've become so focused on where we think we ought to be-a place where technology empowers individuals and obliterates social organizations-that we often fail to see where we're really going and what's helping us get there.  we need, they argue, to look beyond our obsession with information and individuals to include the critical social networks of which these are always a part.<p>drawing from rich learning experiences at xerox parc, from examples such as ibm, chiat/day advertising, and california's ""virtual university,"" and from historical, social, and cultural research, the authors sharply challenge the futurists' sweeping predictions. they explain how many of the tools, jobs, and organizations seemingly targeted for future extinction in fact provide useful social resources that people will fight to keep. rather than aiming technological bullets at these ""relics,"" we should instead look for ways that the new world of bits can learn from and complement them. <p>arguing elegantly for the important role that human sociability plays, even-perhaps especially-in the world of bits, <b>the social life of information</b> gives us an optimistic look beyond the simplicities of information and individuals.  it shows how a better understanding of the contribution that communities, organizations, and institutions make to learning, working and innovating can lead to the richest possible use of technology in our work and everyday lives.} {drawing from recent research and practical examples across a range of organizations, the social life of information dispels many of the futurists' sweeping predictions that information technology will obliterate the need for everything from travel to supermarkets to business organizations to social life itself. the authors examine the potential and limitations of technology with regard to intelligent software agents, the automated home office, business reorganization for innovation, knowledge management and work practices, the paperless society, and the digital university. arguing eloquently for the important role human sociability plays in the world of bits, brown and duguid give us an optimistic look beyond the simplicities of information and individuals. they show how a better understanding of the contribution that communities, organizations, and institutions make to learning, knowledge, and judgment can lead to the richest possible use of technology in our work and everyday lives.  }"
1288940,inproceedings,,proceedings of the 16th international conference on world wide web,www,acm,9,,,2007,,2007-05-10 23:37:47,"new york, ny, usa",optimizing web search using social annotations,"this paper explores the use of social annotations to improve websearch. nowadays, many services, e.g. del.icio.us, have been developed for web users to organize and share their favorite webpages on line by using social annotations. we observe that the social annotations can benefit web search in two aspects: 1) the annotations are usually good summaries of corresponding webpages; 2) the count of annotations indicates the popularity of webpages. two novel algorithms are proposed to incorporate the above information into page ranking: 1) {socialsimrank} ({ssr})calculates the similarity between social annotations and webqueries; 2) {socialpagerank} ({spr}) captures the popularity of webpages. preliminary experimental results show that {ssr} can find the latent semantic association between queries and annotations, while {spr} successfully measures the quality (popularity) of a webpage from the web users' perspective. we further evaluate the proposed methods empirically with 50 manually constructed queries and 3000 auto-generated queries on a dataset crawledfrom delicious. experiments show that both {ssr} and {sprbenefit} web search significantly."
7706897,article,genome biology,,,biomed central ltd,,11,8,2010,aug,2010-08-25 16:05:23,,"galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences.","increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. galaxy pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis."
384502,article,commun. acm,,,acm,7,21,7,1978,jul,2005-11-09 11:01:14,"new york, ny, usa","time, clocks, and the ordering of events in a distributed system","the concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. a distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. the use of the total ordering is illustrated with a method for solving synchronization problems. the algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become."
1362387,article,"science (new york, n.y.)",,,american association for the advancement of science,5,316,5830,2007,jun,2007-06-04 12:09:26,,genome-wide mapping of in vivo {protein-dna} interactions.,"in vivo {protein-dna} interactions connect each transcription factor with its direct targets to form a gene network scaffold. to map these {protein-dna} interactions comprehensively across entire mammalian genomes, we developed a large-scale chromatin immunoprecipitation assay ({chipseq}) based on direct ultrahigh-throughput {dna} sequencing. this sequence census method was then used to map in vivo binding of the neuron-restrictive silencer factor ({nrsf}; also known as {rest}, for repressor element-1 silencing transcription factor) to 1946 locations in the human genome. the data display sharp resolution of binding position [+/-50 base pairs (bp)], which facilitated our finding motifs and allowed us to identify noncanonical {nrsf}-binding motifs. these {chipseq} data also have high sensitivity and specificity [{roc} (receiver operator characteristic) area >/= 0.96] and statistical confidence (p <10(-4)), properties that were important for inferring new candidate interactions. these include key transcription factors in the gene network that regulates pancreatic islet cell development."
7736929,misc,arxiv e-prints,,,,,,,2010,aug,2010-08-30 08:03:05,,data analysis recipes: fitting a model to data,
9134853,article,nature genetics,,,nature research,7,43,5,2011,apr,2011-04-11 09:41:41,,a framework for variation discovery and genotyping using next-generation {dna} sequencing data,"recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. the amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. we present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) {snp} discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. we here discuss the application of these tools, instantiated in the genome analysis toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass (∼4×) 1000 genomes project datasets."
686555,article,proceedings of the national academy of sciences,,,national academy of sciences,5,103,23,2006,jun,2006-06-06 12:41:09,,modularity and community structure in networks,"many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. the problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. one highly effective approach is the optimization of the quality function known as  ” modularity” over the possible divisions of a network. here i show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which i call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. i illustrate the method with applications to several published network data sets."
270495,article,bioinformatics,bioinformatics,,oxford university press,8,19,2,2003,jan,2005-07-31 22:53:00,"group in biostatistics, university of california, berkeley, ca 94720, usa. bolstad@stat.berkeley.edu",a comparison of normalization methods for high density oligonucleotide array data based on variance and bias,"motivation: when running experiments that involve multiple high density oligonucleotide arrays, it is important to remove sources of variation between arrays of non-biological origin. normalization is a process for reducing this variation. it is common to see non-linear relations between arrays and the standard normalization provided by affymetrix does not perform well in these situations."
849862,article,"automatic control, ieee transactions on",,,ieee,7,19,6,1974,dec,2006-09-19 17:26:06,,a new look at the statistical model identification,the history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. the classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion ({aic}) estimate ({maice}) which is designed for the purpose of statistical identification is introduced. when there are several competing models the {maice} is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of {aic} defined by {aic} = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). {maice} provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. the practical utility of {maice} in time series analysis is demonstrated with some numerical examples.
11191048,article,nature,,,nature research,17,489,7414,2012,sep,2012-09-05 20:21:09,,an integrated encyclopedia of {dna} elements in the human genome,"the human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. the encyclopedia of {dna} elements ({encode}) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. these data enabled us to assign biochemical functions for 80\% of the genome, in particular outside of the well-studied protein-coding regions. many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. the newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research."
1451915,article,"science (new york, n.y.)",,,american association for the advancement of science,9,220,4598,1983,may,2007-07-12 13:09:35,,optimization by simulated annealing.,there is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). a detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. this connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.
686543,article,bmc bioinformatics,,,biomed central ltd,,7,Suppl 1,2006,mar,2006-06-06 12:25:05,"department of biomedical informatics, columbia university, new york, ny 10032, usa. adam@dbmi.columbia.edu",{aracne}: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context,"elucidating gene regulatory networks is crucial for understanding normal cell physiology and complex pathologic phenotypes. existing computational methods for the genome-wide ""reverse engineering"" of such networks have been successful only for lower eukaryotes with simple genomes. here we present {aracne}, a novel algorithm, using microarray expression profiles, specifically designed to scale up to the complexity of regulatory networks in mammalian cells, yet general enough to address a wider range of network deconvolution problems. this method uses an information theoretic approach to eliminate the majority of indirect interactions inferred by co-expression methods."
7168344,article,science,,,american association for the advancement of science,2,328,5980,2010,may,2010-05-14 07:25:42,,"community structure in {time-dependent}, multiscale, and multiplex networks","network science is an interdisciplinary endeavor, with methods and applications drawn from across the natural, social, and information sciences. a prominent problem in network science is the algorithmic detection of tightly connected groups of nodes known as communities. we developed a generalized framework of network quality functions that allowed us to study the community structure of arbitrary multislice networks, which are combinations of individual networks coupled through links that connect each node in one network slice to itself in other slices. this framework allows studies of community structure in a general setting encompassing networks that evolve over time, have multiple types of links (multiplexity), and have multiple scales."
200340,book,,,,the mit press,,,,2004,aug,2005-05-14 22:46:10,,where the action is: the foundations of embodied interaction,
6569530,article,bioinformatics,,,oxford university press,6,26,5,2010,mar,2010-01-20 23:32:59,,fast and accurate long-read alignment with {burrows–wheeler} transform,"motivation: many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. most of them are very efficient for short reads but inefficient or not applicable for reads >200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate. however, some sequencing platforms already produce longer reads and others are expected to become available soon. for longer reads, hashing-based software such as {blat} and {ssaha2} remain the only choices. nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time."
94348,article,nucleic acids research,,,oxford university press,7,22,22,1994,nov,2005-02-14 12:22:28,"european molecular biology laboratory, heidelberg, germany.","{clustal} w: improving the sensitivity of progressive multiple sequence alignment through sequence weighting, position-specific gap penalties and weight matrix choice.","the sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. these modifications are incorporated into a new program, {clustal} w which is freely available."
318897,book,,,,cambridge university press,,,,1992,oct,2005-09-13 20:35:47,,"numerical recipes in c: the art of scientific computing, second edition",
2288308,article,science,,,,3,319,5862,2008,jan,2008-01-25 07:09:15,,alignment uncertainty and genomic analysis,"the statistical methods applied to the analysis of genomic data do not account for uncertainty in the sequence alignment. indeed, the alignment is treated as an observation, and all of the subsequent inferences depend on the alignment being correct. this may not have been too problematic for many phylogenetic studies, in which the gene is carefully chosen for, among other things, ease of alignment. however, in a comparative genomics study, the same statistical methods are applied repeatedly on thousands of genes, many of which will be difficult to align. using genomic data from seven yeast species, we show that uncertainty in the alignment can lead to several problems, including different alignment methods resulting in different conclusions."
131325,article,"science (new york, n.y.)",,,american association for the advancement of science,8,304,5667,2004,apr,2005-03-17 15:10:29,,environmental genome shotgun sequencing of the sargasso sea.,"we have applied ""whole-genome shotgun sequencing"" to microbial populations collected en masse on tangential flow and impact filters from seawater samples collected from the sargasso sea near bermuda. a total of 1.045 billion base pairs of nonredundant sequence was generated, annotated, and analyzed to elucidate the gene content, diversity, and relative abundance of the organisms within these environmental samples. these data are estimated to derive from at least 1800 genomic species based on sequence relatedness, including 148 previously unknown bacterial phylotypes. we have identified over 1.2 million previously unknown genes represented in these samples, including more than 782 new rhodopsin-like photoreceptors. variation in species present and stoichiometry suggests substantial oceanic microbial diversity."
77267,article,commun. acm,,,acm,2,47,12,2004,dec,2005-01-13 12:14:28,"new york, ny, usa",how blogging software reshapes the online community,"spurred by easy-to-use commercial software, blogging is less about creating links and references to sites and sources, and increasingly about bloggers' own comments and personal interests."
71749,proceedings,,proceedings of the 32nd acm symposium on theory of computing,,,,,,-1,,2005-01-02 16:35:14,,the {small-world} phenomenon: an algorithmic perspective,"long a matter of folklore, the \&quot;small-world phenomenon\&quot; -- the principle that we are all linked by short chains of acquaintances -- was inaugurated as an area of experimental study in the social sciences through the pioneering work of stanley milgram in the 1960's. this work was among the first to make the phenomenon quantitative, allowing people to speak of the \&quot;six degrees of separation\&quot; between any two people in the united states. since then, a number of network models have been proposed as..."
102131,article,acm comput. surv.,,,acm,36,36,4,2004,dec,2005-02-23 21:53:02,"new york, ny, usa",a survey of peer-to-peer content distribution technologies,"distributed computer architectures labeled ""peer-to-peer"" are designed for the sharing of computer resources (content, storage, {cpu} cycles) by direct exchange, rather than requiring the intermediation or support of a centralized server or authority. peer-to-peer architectures are characterized by their ability to adapt to failures and accommodate transient populations of nodes while maintaining acceptable connectivity and {performance.content} distribution is an important peer-to-peer application on the internet that has received considerable research attention. content distribution applications typically allow personal computers to function in a coordinated manner as a distributed storage medium by contributing, searching, and obtaining digital {content.in} this survey, we propose a framework for analyzing peer-to-peer content distribution technologies. our approach focuses on nonfunctional characteristics such as security, scalability, performance, fairness, and resource management potential, and examines the way in which these characteristics are reflected in---and affected by---the architectural design decisions adopted by current peer-to-peer {systems.we} study current peer-to-peer systems and infrastructure technologies in terms of their distributed object location and routing mechanisms, their approach to content replication, caching and migration, their support for encryption, access control, authentication and identity, anonymity, deniability, accountability and reputation, and their use of resource trading and management schemes."
333029,article,rev. mod. phys.,,,american physical society,50,74,1,2002,jan,2005-09-27 16:01:26,,statistical mechanics of complex networks,"complex networks describe a wide range of systems in nature and society. frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the internet, a network of routers and computers connected by physical links. while traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. this article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. after reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network\&\#39;s robustness against failures and attacks."
1603667,article,bioinformatics,,,oxford university press,10,23,19,2007,oct,2007-08-29 06:56:48,"department of plant systems biology, vib, b-9052 ghent, belgium and bioinformatics and evolutionary genomics group, department of molecular genetics, ghent university, b-9052 ghent, belgium.",a review of feature selection techniques in bioinformatics,"feature selection techniques have become an apparent need in many bioinformatics applications. in addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques."
877,article,,,,,,,,-1,,2004-11-21 20:59:19,,{referral web}: combining social networks and collaborative filtering,
2678830,article,nature,,,nature publishing group,5,452,7189,2008,apr,2008-04-16 20:45:23,,evolvability and hierarchy in rewired bacterial gene networks,
117642,book,,,,scribner,,,,2002,aug,2005-03-09 00:17:04,,"emergence: the connected lives of ants, brains, cities, and software",
4170553,article,science,,,american association for the advancement of science,3,324,5925,2009,apr,2009-03-16 11:30:53,,local {dna} topography correlates with functional noncoding regions of the human genome,"the three-dimensional molecular structure of {dna}, specifically the shape of the backbone and grooves of genomic {dna}, can be dramatically affected by nucleotide changes, which can cause differences in protein-binding affinity and phenotype. we developed an algorithm to measure constraint on the basis of similarity of {dna} topography among multiple species, using hydroxyl radical cleavage patterns to interrogate the solvent-accessible surface area of {dna}. this algorithm found that 12\% of bases in the human genome are evolutionarily constrained—double the number detected by nucleotide sequence–based algorithms. topography-informed constrained regions correlated with functional noncoding elements, including enhancers, better than did regions identified solely on the basis of nucleotide sequence. these results support the idea that the molecular shape of {dna} is under selection and can identify evolutionary history."
1121661,article,mach. learn.,,,kluwer academic publishers,27,45,1,2001,oct,2007-05-22 17:21:44,"hingham, ma, usa",random forests,"random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. the generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. the generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. using a random selection of features to split each node yields error rates that compare favorably to adaboost (y. freund \& r. schapire, machine learning: proceedings of the thirteenth international conference, \&ast;\&ast;\&ast;, 148–156), but are more robust with respect to noise. internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. internal estimates are also used to measure variable importance. these ideas are also applicable to regression."
1877660,book,,,,wiley-interscience,,,,2006,jul,2007-11-07 13:44:10,,elements of information theory 2nd edition (wiley series in telecommunications and signal processing),"the latest edition of this classic is updated with new problem sets and material<br> <br> the second edition of this fundamental textbook maintains the book's tradition of clear, thought-provoking instruction. readers are provided once again with an instructive mix of mathematics, physics, statistics, and information theory.<br> <br> all the essential topics in information theory are covered in detail, including entropy, data compression, channel capacity, rate distortion, network information theory, and hypothesis testing. the authors provide readers with a solid understanding of the underlying theory and applications. problem sets and a telegraphic summary at the end of each chapter further assist readers. the historical notes that follow each chapter recap the main points.<br> <br> the second edition features:<br> * chapters reorganized to improve teaching<br> * 200 new problems<br> * new material on source coding, portfolio theory, and feedback capacity<br> * updated references<br> <br> now current and enhanced, the second edition of elements of information theory remains the ideal textbook for upper-level undergraduate and graduate courses in electrical engineering, statistics, and telecommunications. <p> an instructor's manual presenting detailed solutions to all the problems in the book is available from the wiley editorial department."
1087189,article,proceedings of the national academy of sciences,,,national academy of sciences,5,104,1,2007,jan,2007-02-04 14:45:07,,resolution limit in community detection,"detecting community structure is fundamental for uncovering the links between structure and function in complex networks and for practical applications in many disciplines such as biology and sociology. a popular method now widely used relies on the optimization of a quantity called modularity, which is a quality index for a partition of a network into communities. we find that modularity optimization may fail to identify modules smaller than a scale which depends on the total size of the network and on the degree of interconnectedness of the modules, even in cases where modules are unambiguously defined. this finding is confirmed through several examples, both in artificial and in real social, biological, and technological networks, where we show that modularity optimization indeed does not resolve a large number of modules. a check of the modules obtained through modularity optimization is thus necessary, and we provide here key elements for the assessment of the reliability of this community detection method."
7515828,article,genome research,,,cold spring harbor laboratory press,6,20,9,2010,sep,2010-07-20 07:45:31,,the genome analysis toolkit: a {mapreduce} framework for analyzing next-generation {dna} sequencing data,"an international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms"
587762,book,,,,yale university press,,,,2006,may,2006-04-15 17:42:59,,the wealth of networks: how social production transforms markets and freedom,
8525342,article,plos comput biol,,,public library of science,,7,1,2011,jan,2011-01-07 18:07:53,,ten simple rules for getting ahead as a computational biologist in academia,
491,inproceedings,,proceedings of the 13th international conference on world wide web,www,acm,10,,,2004,,2004-11-15 16:58:37,"new york, ny, usa",information diffusion through blogspace,"we study the dynamics of information propagation in environments of low-overhead personal publishing, using a large collection of weblogs over time as our example domain. we characterize and model this collection at two levels. first, we present a macroscopic characterization of topic propagation through our corpus, formalizing the notion of long-running ""chatter"" topics consisting recursively of ""spike"" topics generated by outside world events, or more rarely, by resonances within the community. second, we present a microscopic characterization of propagation from individual to individual, drawing on the theory of infectious diseases to model the flow. we propose, validate, and employ an algorithm to induce the underlying propagation network from a sequence of posts, and report on the results."
307461,article,nature genetics,,,nature publishing group,4,31,1,2002,apr,2005-08-30 19:25:14,,network motifs in the transcriptional regulation network of escherichia coli,"little is known about the design principles1, 2, 3, 4, 5, 6, 7, 8, 9, 10 of transcriptional regulation networks that control gene expression in cells. recent advances in data collection and analysis2, 11, 12, however, are generating unprecedented amounts of information about gene regulation networks. to understand these complex wiring diagrams1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, we sought to break down such networks into basic building blocks2. we generalize the notion of motifs, widely used for sequence analysis, to the level of networks. we define 'network motifs' as patterns of interconnections that recur in many different parts of a network at frequencies much higher than those found in randomized networks. we applied new algorithms for systematically detecting network motifs to one of the best-characterized regulation networks, that of direct transcriptional interactions in escherichia coli 3, 6. we find that much of the network is composed of repeated appearances of three highly significant motifs. each network motif has a specific function in determining gene expression, such as generating temporal expression programs and governing the responses to fluctuating external signals. the motif structure also allows an easily interpretable view of the entire known transcriptional network of the organism. this approach may help define the basic computational elements of other biological networks."
6758502,article,nature,,,nature publishing group,8,464,7285,2010,mar,2010-03-03 21:23:53,,quantum computers,"over the past several decades, quantum information science has emerged to seek answers to the question: can we gain some advantage by storing, transmitting and processing information encoded in systems that exhibit unique quantum properties? today it is understood that the answer is yes, and many research groups around the world are working towards the highly ambitious technological goal of building a quantum computer, which would dramatically improve computational power for particular tasks. a number of physical systems, spanning much of modern physics, are being developed for quantum computation. however, it remains unclear which technology, if any, will ultimately prove successful. here we describe the latest developments for each of the leading approaches and explain the major challenges for the future."
2322651,article,j. chem. theory comput.,journal of chemical theory and computation,,american chemical society,12,4,3,2008,mar,2008-02-02 10:28:22,"stockholm center for biomembrane research, stockholm university, se-10691 stockholm, sweden","{gromacs} 4:  algorithms for highly efficient, {load-balanced}, and scalable molecular simulation","molecular simulation is an extremely useful, but computationally very expensive tool for studies of chemical and biomolecular systems. here, we present a new implementation of our molecular simulation toolkit {gromacs} which now both achieves extremely high performance on single processors from algorithmic optimizations and hand-coded routines and simultaneously scales very well on parallel machines. the code encompasses a minimal-communication domain decomposition algorithm, full dynamic load balancing, a state-of-the-art parallel constraint solver, and efficient virtual site algorithms that allow removal of hydrogen atom degrees of freedom to enable integration time steps up to 5 fs for atomistic simulations also in parallel. to improve the scaling properties of the common particle mesh ewald electrostatics algorithms, we have in addition used a {multiple-program}, {multiple-data} approach, with separate node domains responsible for direct and reciprocal space interactions. not only does this combination of algorithms enable extremely long simulations of large systems but also it provides that simulation performance on quite modest numbers of standard cluster nodes."
126678,book,,,,addison-wesley professional,,,,1995,aug,2005-03-14 15:49:32,,"the mythical {man-month}: essays on software engineering, anniversary edition (2nd edition)","these essays draw from brooks' experience as project manager for the {ibm} system/360 computer family and then for {os}/360, its massive software system. now, 20 years after the initial publication of his book, brooks has revisited his original ideas and added new thoughts and advice. -- from publisher description"
6043555,article,nature methods,,,nature publishing group,7,6,11s,2009,oct,2009-10-30 15:56:40,,computational methods for discovering structural variation with next-generation sequencing,"in the last several years, a number of studies have described large-scale structural variation in several genomes. traditionally, such methods have used whole-genome array comparative genome hybridization or single-nucleotide polymorphism arrays to detect large regions subject to copy-number variation. later techniques have been based on paired-end mapping of sanger sequencing data, providing better resolution and accuracy. with the advent of next-generation sequencing, a new generation of methods is being developed to tackle the challenges of short reads, while taking advantage of the high coverage the new sequencing technologies provide. in this survey, we describe these methods, including their strengths and their limitations, and future research directions."
197297,book,,,,simon \& schuster,,,,1997,sep,2005-05-11 21:48:04,,life on the screen: identity in the age of the internet,"{sherry turkle is rapidly becoming the sociologist of the internet, and that's beginning to seem like a good thing. while her first outing, <i>the second self: computers and the human spirit</i>, made groundless assertions and seemed to be carried along more by her affection for certain theories than by a careful look at our current situation, <i>life on the screen</i> is a balanced and nuanced look at some of the ways that cyberculture helps us comment upon real life (what the cybercrowd sometimes calls rl). instead of giving in to any one theory on construction of identity, turkle looks at the way various netizens have used the internet, and especially muds (multi-user dimensions), to learn more about the possibilities available in apprehending the world. one of the most interesting sections deals with gender, a topic prone to rash and partisan pronouncements. taking as her motto william james's maxim ""philosophy is the art of imagining alternatives,"" turkle shows how playing with gender in cyberspace can shape a person's real-life understanding of gender. especially telling are the examples of the man who finds it easier to be assertive when playing a woman, because he believes male assertiveness is now frowned upon while female assertiveness is considered hip, and the woman who has the opposite response, believing that it is easier to be aggressive when she plays a male, because as a woman she would be considered ""bitchy."" without taking sides, turkle points out how both have expanded their emotional range. other topics, such as artificial life, receive an equally calm and sage response, and the first-person accounts from many internet users provide compelling reading and good source material for readers to draw their own conclusions.  }"
1388250,article,nature,,,nature publishing group,17,447,7146,2007,jun,2007-06-13 21:14:50,,identification and analysis of functional elements in 1\% of the human genome by the {encode} pilot project,"we report the generation and analysis of functional data from multiple, diverse experiments performed on a targeted 1\% of the human genome as part of the pilot phase of the {encode} project. these data have been further integrated and augmented by a number of evolutionary and computational analyses. together, our results advance the collective knowledge about human genome function in several major areas. first, our studies provide convincing evidence that the genome is pervasively transcribed, such that the majority of its bases can be found in primary transcripts, including non-protein-coding transcripts, and those that extensively overlap one another. second, systematic examination of transcriptional regulation has yielded new understanding about transcription start sites, including their relationship to specific regulatory sequences and features of chromatin accessibility and histone modification. third, a more sophisticated view of chromatin structure has emerged, including its inter-relationship with {dna} replication and transcriptional regulation. finally, integration of these new sources of information, in particular with respect to mammalian evolution based on inter- and intra-species sequence comparisons, has yielded new mechanistic and evolutionary insights concerning the functional landscape of the human genome. together, these studies are defining a path for pursuit of a more comprehensive characterization of human genome function."
201583,book,,,,routledge,,,,1999,feb,2005-05-16 17:58:02,,communities in cyberspace,"editors smith and kollock have gathered contributors with a variety of viewpoints to examine both the ""legitimacy"" of community in cyberspace and to question how it operates. while the authors do conclude that communities in cyberspace are real communities, they explore the sometimes surprising ways in which cybercommunities differ from their geographically based counterparts.<p> there are four primary issues probed here: the question of online identity in an environment where individuals cannot be seen; the question of social order and control in what is, at least on the surface, a largely anarchic environment; the structure and dynamics of online communities; and the cybercommunity as a foundation for collective action.<p> there's much here to provoke long discussions both online and off, such as the argument that the screen doesn't eliminate the consideration of racial identity so much as it allows for the development of nonvisual criteria for people to judge (or misjudge) the races of others. this book was compiled to be used in the college classroom, although it's not jargon laden or difficult to read. it will appeal to anyone who is professionally or individually involved with virtual communities. <{i>--elizabeth} {lewis</i}>"
126676,book,,,,back bay books,,,,2002,jan,2005-03-14 15:48:45,,the tipping point: how little things can make a big difference,"{""why did crime in new york drop so suddenly in the mid-90s? how does an unknown novelist end up a bestselling author? why is teenage smoking out of control, when everyone knows smoking kills? what makes tv shows like sesame street so good at teaching kids how to read? why did paul revere succeed with his famous warning? in this brilliant and groundbreaking book, new yorker writer malcolm gladwell looks at why major changes in our society so often happen suddenly and unexpectedly. ideas, behavior, messages, and products, he argues, often spread like outbreaks of infectious disease. just as a single sick person can start an epidemic of the flu, so too can a few fare-beaters and graffiti artists fuel a subway crime wave, or a satisfied customer fill the empty tables of a new restaurant. these are social epidemics, and the moment when they take off, when they reach their critical mass, is the tipping point.   <p>in the tipping point, gladwell introduces us to the particular personality types who are natural pollinators of new ideas and trends, the people who create the phenomenon of word of mouth. he analyzes fashion trends, smoking, children's television, direct mail and the early days of the american revolution for clues about making ideas infectious, and visits a religious commune, a successful high-tech company, and one of the world's greatest salesmen to show how to start and sustain social epidemics. the tipping point is an intellectual adventure story written with an infectious enthusiasm for the power and joy of new ideas. most of all, it is a road map to change, with a profoundly hopeful message--that one imaginative person applying a well-placed lever can move the world.""}"
3381078,article,plos med,,,public library of science,,5,10,2008,oct,2008-10-07 05:53:54,,why current publication practices may distort science,john ioannidis and colleagues argue that the current system of publication in biomedical research provides a distorted view of the reality of scientific data.
2580227,inproceedings,,proceedings of the 9th webkdd and 1st sna-kdd 2007 workshop on web mining and social network analysis,webkdd/sna-kdd,acm,9,,,2007,,2008-03-24 10:27:15,"new york, ny, usa",why we twitter: understanding microblogging usage and communities,"microblogging is a new form of communication in which users can describe their current status in short posts distributed by instant messages, mobile phones, email or the web. twitter, a popular microblogging tool has seen a lot of growth since it launched in october, 2006. in this paper, we present our observations of the microblogging phenomena by studying the topological and geographical properties of twitter's social network. we find that people use microblogging to talk about their daily activities and to seek or share information. finally, we analyze the user intentions associated at a community level and show how users with similar intentions connect with each other."
159967,article,nucleic acids research,,,oxford university press,9,30,7,2002,apr,2005-04-13 17:58:32,"computational genomics group, the european bioinformatics institute, embl cambridge outstation, cambridge cb10 1sd, uk. anton@ebi.ac.uk",an efficient algorithm for large-scale detection of protein families.,"detection of protein families in large databases is one of the principal research objectives in structural and functional genomics. protein family classification can significantly contribute to the delineation of functional diversity of homologous proteins, the prediction of function based on domain architecture or the presence of sequence motifs as well as comparative genomics, providing valuable evolutionary insights. we present a novel approach called {tribe}-{mcl} for rapid and accurate clustering of protein sequences into families. the method relies on the markov cluster ({mcl}) algorithm for the assignment of proteins into families based on precomputed sequence similarity information. this novel approach does not suffer from the problems that normally hinder other protein sequence clustering algorithms, such as the presence of multi-domain proteins, promiscuous domains and fragmented proteins. the method has been rigorously tested and validated on a number of very large databases, including {swissprot}, {interpro}, {scop} and the draft human genome. our results indicate that the method is ideally suited to the rapid and accurate detection of protein families on a large scale. the method has been used to detect and categorise protein families within the draft human genome and the resulting families have been used to annotate a large proportion of human proteins."
252315,book,,,,the johns hopkins university press,,,,1996,oct,2005-07-12 19:58:52,,matrix computations,"<{p>revised} and updated, the third edition of golub and van loan's classic text in computer science provides essential information about the mathematical background and algorithmic skills required for the production of numerical software. this new edition includes thoroughly revised chapters on matrix multiplication problems and parallel matrix computations, expanded treatment of {cs} decomposition, an updated overview of floating point arithmetic, a more accurate rendition of the modified {gram-schmidt} process, and new material devoted to {gmres}, {qmr}, and other methods designed to handle the sparse unsymmetric linear system {problem.</p}>"
128,article,proceedings of the national academy of sciences,,,national academy of sciences,5,98,2,2001,jan,2004-11-08 17:14:49,"santa fe institute, 1399 hyde park road, santa fe, nm 87501, usa. mark@santafe.edu",the structure of scientific collaboration networks,"the structure of scientific collaboration networks is investigated. two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including {medline} (biomedical research), the los alamos {e-print} archive (physics), and {ncstrl} (computer science). i show that these collaboration networks form  ” small worlds,” in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. i further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied."
142938,techreport,,,,,,,,-1,,2005-03-30 14:30:28,"redmond, washington",a tutorial on learning with bayesian networks,"a bayesian network is a graphical model that encodes probabilistic relationships among variables of interest. when used in conjunction with statistical techniques, the graphical model has several advantages for data analysis. one, because the model encodes dependencies among all variables, it readily handles situations where some data entries are missing. two, a bayesian network can be used to learn causal relationships, and hence can be used to gain understanding about a problem domain and to..."
5841376,article,bmc bioinformatics,,,,,10,1,2009,,2009-09-25 21:58:18,,social tagging in the life sciences: characterizing a new metadata resource for bioinformatics.,"academic social tagging systems, such as connotea and {citeulike}, provide researchers with a means to organize personal collections of online references with keywords (tags) and to share these collections with others. one of the side-effects of the operation of these systems is the generation of large, publicly accessible metadata repositories describing the resources in the collections. in light of the well-known expansion of information in the life sciences and the need for metadata to enhance its value, these repositories present a potentially valuable new resource for application developers. here we characterize the current contents of two scientifically relevant metadata repositories created through social tagging. this investigation helps to establish how such socially constructed metadata might be used as it stands currently and to suggest ways that new social tagging systems might be designed that would yield better aggregate products. we assessed the metadata that users of {citeulike} and connotea associated with citations in {pubmed} with the following metrics: coverage of the document space, density of metadata (tags) per document, rates of inter-annotator agreement, and rates of agreement with {mesh} indexing. {citeulike} and connotea were very similar on all of the measurements. in comparison to {pubmed}, document coverage and per-document metadata density were much lower for the social tagging systems. inter-annotator agreement within the social tagging systems and the agreement between the aggregated social tagging metadata and {mesh} indexing was low though the latter could be increased through voting. the most promising uses of metadata from current academic social tagging repositories will be those that find ways to utilize the novel relationships between users, tags, and documents exposed through these systems. for more traditional kinds of indexing-based applications (such as keyword-based search) to benefit substantially from socially generated metadata in the life sciences, more documents need to be tagged and more tags are needed for each document. these issues may be addressed both by finding ways to attract more users to current systems and by creating new user interfaces that encourage more collectively useful individual tagging behaviour."
1154381,article,nat mater,,,nature publishing group,8,6,3,2007,mar,2007-03-11 21:07:03,,the rise of graphene,"graphene is a rapidly rising star on the horizon of materials science and condensed-matter physics. this strictly two-dimensional material exhibits exceptionally high crystal and electronic quality, and, despite its short history, has already revealed a cornucopia of new physics and potential applications, which are briefly discussed here. whereas one can be certain of the realness of applications only when commercial products appear, graphene no longer requires any further proof of its importance in terms of fundamental physics. owing to its unusual electronic spectrum, graphene has led to the emergence of a new paradigm of 'relativistic' condensed-matter physics, where quantum relativistic phenomena, some of which are unobservable in high-energy physics, can now be mimicked and tested in table-top experiments. more generally, graphene represents a conceptually new class of materials that are only one atom thick, and, on this basis, offers new inroads into low-dimensional physics that has never ceased to surprise and continues to provide a fertile ground for applications."
77265,article,commun. acm,,,acm,4,47,12,2004,dec,2005-01-13 11:15:53,"new york, ny, usa",structure and evolution of blogspace,"a critical look at more than one million bloggers and the individual entries of some 25,000 blogs reveals blogger demographics, friendships, and activity patterns over time."
1326856,inproceedings,,proceedings of the 16th international conference on world wide web,www,acm,9,,,2007,,2007-05-25 10:25:23,"new york, ny, usa",the complex dynamics of collaborative tagging,"the debate within the web community over the optimal means by which to organize information often pits formalized classifications against distributed collaborative tagging systems. a number of questions remain unanswered, however, regarding the nature of collaborative tagging systems including whether coherent categorization schemes can emerge from unsupervised tagging by users. this paper uses data from the social bookmarking site delicio. us to examine the dynamics of collaborative tagging systems. in particular, we examine whether the distribution of the frequency of use of tags for ""popular"" sites with a long history (many tags and many users) can be described by a power law distribution, often characteristic of what are considered complex systems. we produce a generative model of collaborative tagging in order to understand the basic dynamics behind tagging, including how a power law distribution of tags could arise. we empirically examine the tagging history of sites in order to determine how this distribution arises over time and to determine the patterns prior to a stable distribution. lastly, by focusing on the high-frequency tags of a site where the distribution of tags is a stabilized power law, we show how tag co-occurrence networks for a sample domain of tags can be used to analyze the meaning of particular tags given their relationship to other tags."
137147,electronic,,,,,,,,2004,nov,2005-03-23 09:43:35,,how to search a social network,
5687044,article,nature genetics,,,nature publishing group,6,41,10,2009,oct,2009-08-31 04:23:22,,personalized copy number and segmental duplication maps using next-generation sequencing.,"despite their importance in gene innovation and phenotypic variation, duplicated regions have remained largely intractable owing to difficulties in accurately resolving their structure, copy number and sequence content. we present an algorithm ({mrfast}) to comprehensively map next-generation sequence reads, which allows for the prediction of absolute copy-number variation of duplicated segments and genes. we examine three human genomes and experimentally validate genome-wide copy number differences. we estimate that, on average, 73-87 genes vary in copy number between any two individuals and find that these genic differences overwhelmingly correspond to segmental duplications (odds ratio = 135; p < 2.2 x 10(-16)). our method can distinguish between different copies of highly identical genes, providing a more accurate assessment of gene content and insight into functional constraint without the limitations of array-based technology."
272,article,nature,,,nature publishing group,4,431,7006,2004,sep,2004-11-12 20:08:57,"department of molecular biophysics and biochemistry, yale university, po box 208114, new haven, connecticut 06520-8114, usa. sandy@bioinfo.mbb.yale.edu",genomic analysis of regulatory network dynamics reveals large topological changes,"network analysis has been applied widely, providing a unifying language to describe disparate systems ranging from social interactions to power grids. it has recently been used in molecular biology, but so far the resulting networks have only been analysed statically1, 2, 3, 4, 5, 6, 7, 8. here we present the dynamics of a biological network on a genomic scale, by integrating transcriptional regulatory information9, 10, 11 and gene-expression data12, 13, 14, 15, 16 for multiple conditions in saccharomyces cerevisiae. we develop an approach for the statistical analysis of network dynamics, called {sandy}, combining well-known global topological measures, local motifs and newly derived statistics. we uncover large changes in underlying network architecture that are unexpected given current viewpoints and random simulations. in response to diverse stimuli, transcription factors alter their interactions to varying degrees, thereby rewiring the network. a few transcription factors serve as permanent hubs, but most act transiently only during certain conditions. by studying sub-network structures, we show that environmental responses facilitate fast signal propagation (for example, with short regulatory cascades), whereas the cell cycle and sporulation direct temporal progression through multiple stages (for example, with highly inter-connected transcription factors). indeed, to drive the latter processes forward, phase-specific transcription factors inter-regulate serially, and ubiquitously active transcription factors layer above them in a two-tiered hierarchy. we anticipate that many of the concepts presented here—particularly the large-scale topological changes and hub transience—will apply to other biological networks, including complex sub-systems in higher eukaryotes."
620778,article,the american journal of sociology,,,,32,94,3,1988,,2006-05-10 00:41:12,,social networks and collective action: a theory of the critical mass. {iii},"most analyses of collective action agree that overcoming the freerider problem requires organizing potential contributors, thus making their decisions interdependent. the potential for organizing depends on the social ties in the group, particularly on the overall density or frequency of ties, on the extent to which they are centralized in a few individuals, and on the costs of communicating and coordinating actions through these ties. mathematical analysis and computer simulations extend a formal microsocial theory of interdependent collective action to treat social networks and organization costs. as expected, the overall density of social ties in a group improves its prospects for collective action. more significant, because less expected, are the findings that show that the centralization of network ties always has a positive effect on collective action and that the negative effect of costs on collective action declines as the group's resource or interest heterogeneity increases. these nonobvious results are due to the powerful effects of selectivity, the organizer's ability to concentrate organizing efforts on those individuals whose potential contributions are the largest."
2102204,article,nucleic acids research,,,oxford university press,4,36,suppl 1,2008,jan,2007-12-13 06:10:35,,{kegg} for linking genomes to life and the environment,"{kegg} (http://www.genome.jp/kegg/) is a database of biological systems that integrates genomic, chemical and systemic functional information. {kegg} provides a reference knowledge base for linking genomes to life through the process of {pathway} mapping, which is to map, for example, a genomic or transcriptomic content of genes to {kegg} reference pathways to infer systemic behaviors of the cell or the organism. in addition, {kegg} provides a reference knowledge base for linking genomes to the environment, such as for the analysis of drug-target relationships, through the process of {brite} mapping. {kegg} {brite} is an ontology database representing functional hierarchies of various biological objects, including molecules, cells, organisms, diseases and drugs, as well as relationships among them. {kegg} {pathway} is now supplemented with a new global map of metabolic pathways, which is essentially a combined map of about 120 existing pathway maps. in addition, smaller pathway modules are defined and stored in {kegg} {module} that also contains other functional units and complexes. the {kegg} resource is being expanded to suit the needs for practical applications. {kegg} {drug} contains all approved drugs in the {us} and japan, and {kegg} {disease} is a new database linking disease genes, pathways, drugs and diagnostic markers."
687885,article,proceedings of the national academy of sciences,,,,5,103,23,2006,jun,2006-06-07 06:41:01,,modularity and community structure in networks,"many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. the problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. one highly effective approach is the optimization of the quality function known as  ” modularity” over the possible divisions of a network. here i show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which i call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. i illustrate the method with applications to several published network data sets."
168648,inproceedings,,proceedings of the nineteenth acm symposium on operating systems principles,sosp,acm,13,,,2003,,2005-04-24 04:22:23,"new york, ny, usa",xen and the art of virtualization,"numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. some require specialized hardware, or cannot support commodity operating systems. some target 100\% binary compatibility at the expense of performance. others sacrifice security or functionality for speed. few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of {service.this} paper presents xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. this is achieved by providing an idealized virtual machine abstraction to which operating systems such as linux, {bsd} and windows {xp}, can be ported with minimal {effort.our} design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. the virtualization approach taken by xen is extremely efficient: we allow operating systems such as linux and windows {xp} to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. we considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests."
114719,book,,,,cambridge university press,,,,2000,mar,2005-03-05 09:49:31,,an introduction to support vector machines and other kernel-based learning methods,"this is the first comprehensive introduction to support vector machines ({svms}), a new generation learning system based on recent advances in statistical learning theory. students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. the concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. pointers to relevant literature and web sites containing software make it an ideal starting point for further study."
595771,inproceedings,,proceedings of the twelfth international conference on information and knowledge management,cikm,acm,3,,,2003,,2006-04-23 03:24:40,"new york, ny, usa",the link prediction problem for social networks,"given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? we formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the ""proximity"" of nodes in a network. experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures."
2739858,article,nature,,,nature publishing group,8,453,7191,2008,may,2008-05-01 09:25:30,,mapping and sequencing of structural variation from eight human genomes,
1880603,article,nature,,,nature publishing group,15,450,7167,2007,nov,2007-11-07 19:26:09,,evolution of genes and genomes on the drosophila phylogeny,"comparative analysis of multiple genomes in a phylogenetic framework dramatically improves the precision and sensitivity of evolutionary inference, producing more robust results than single-genome analyses can provide. the genomes of 12 drosophila species, ten of which are presented here for the first time (sechellia, simulans, yakuba, erecta, ananassae, persimilis, willistoni, mojavensis, virilis and grimshawi), illustrate how rates and patterns of sequence divergence across taxa can illuminate evolutionary processes on a genomic scale. these genome sequences augment the formidable genetic tools that have made drosophila melanogaster a pre-eminent model for animal genetics, and will further catalyse fundamental research on mechanisms of development, cell biology, genetics, disease, neurobiology, behaviour, physiology and evolution. despite remarkable similarities among these drosophila species, we identified many putatively non-neutral changes in protein-coding genes, non-coding {rna} genes, and cis-regulatory regions. these may prove to underlie differences in the ecology and behaviour of these diverse species."
5445743,article,nature,,,macmillan publishers limited. all rights reserved,4,461,7261,2009,sep,2009-08-16 21:28:43,,targeted capture and massively parallel sequencing of 12 human exomes.,"genome-wide association studies suggest that common genetic variants explain only a modest fraction of heritable risk for common diseases, raising the question of whether rare variants account for a significant fraction of unexplained heritability. although {dna} sequencing costs have fallen markedly, they remain far from what is necessary for rare and novel variants to be routinely identified at a genome-wide scale in large cohorts. we have therefore sought to develop second-generation methods for targeted sequencing of all protein-coding regions ('exomes'), to reduce costs while enriching for discovery of highly penetrant variants. here we report on the targeted capture and massively parallel sequencing of the exomes of 12 humans. these include eight {hapmap} individuals representing three populations, and four unrelated individuals with a rare dominantly inherited disorder, {freeman-sheldon} syndrome ({fss}). we demonstrate the sensitive and specific identification of rare and common variants in over 300 megabases of coding sequence. using {fss} as a proof-of-concept, we show that candidate genes for mendelian disorders can be identified by exome sequencing of a small number of unrelated, affected individuals. this strategy may be extendable to diseases with more complex genetics through larger sample sizes and appropriate weighting of non-synonymous variants by predicted functional impact."
1777140,article,molecular systems biology,,,nature publishing group,,3,1,2007,oct,2007-10-17 01:53:38,,network-based classification of breast cancer metastasis.,"mapping the pathways that give rise to metastasis is one of the key challenges of breast cancer research. recently, several large-scale studies have shed light on this problem through analysis of gene expression profiles to identify markers correlated with metastasis. here, we apply a protein-network-based approach that identifies markers not as individual genes but as subnetworks extracted from protein interaction databases. the resulting subnetworks provide novel hypotheses for pathways involved in tumor progression. although genes with known breast cancer mutations are typically not detected through analysis of differential expression, they play a central role in the protein network by interconnecting many differentially expressed genes. we find that the subnetwork markers are more reproducible than individual marker genes selected without network information, and that they achieve higher accuracy in the classification of metastatic versus non-metastatic tumors."
5251453,article,bmj,,,british medical journal publishing group,,339,jul20\_3,2009,jul,2009-07-24 16:03:56,,how citation distortions create unfounded authority: analysis of a citation network,"{abstractobjective} to understand belief in a specific scientific claim by studying the pattern of citations among papers stating {it.design} a complete citation network was constructed from all {pubmed} indexed english literature papers addressing the belief that β amyloid, a protein accumulated in the brain in alzheimer's disease, is produced by and injures skeletal muscle of patients with inclusion body myositis. social network theory and graph theory were used to analyse this {network.main} outcome measures citation bias, amplification, and invention, and their effects on determining {authority.results} the network contained 242 papers and 675 citations addressing the belief, with 220 553 citation paths supporting it. unfounded authority was established by citation bias against papers that refuted or weakened the belief; amplification, the marked expansion of the belief system by papers presenting no data addressing it; and forms of invention such as the conversion of hypothesis into fact through citation alone. extension of this network into text within grants funded by the national institutes of health and obtained through the freedom of information act showed the same phenomena present and sometimes used to justify requests for {funding.conclusion} citation is both an impartial scholarly method and a powerful form of social communication. through distortions in its social use that include bias, amplification, and invention, citation can be used to generate information cascades resulting in unfounded authority of claims. construction and analysis of a claim specific citation network may clarify the nature of a published belief system and expose distorted methods of social citation."
1332540,article,plos comput biol,,,public library of science,,3,5,2007,may,2007-05-25 16:27:31,,ten simple rules for a good poster presentation,
8958158,article,cell,,,elsevier,28,144,5,2011,mar,2011-03-11 00:56:33,,hallmarks of cancer: the next generation.,"main text {introductionwe} have proposed that six hallmarks of cancer together constitute an organizing principle that provides a logical framework for understanding the remarkable diversity of neoplastic diseases (hanahan and weinberg, 2000). implicit in our discussion was the notion that as normal cells evolve progressively to a neoplastic state, they acquire a succession of these hallmark capabilities, and that the multistep process of human tumor pathogenesis could be rationalized by the need of incipient cancer cells to acquire the traits that enable them to become tumorigenic and ultimately malignant."
267339,article,international journal of human-computer studies,,,,11,55,3,2001,sep,2005-07-28 16:47:39,,interactive machine learning: letting users build classifiers,"according to standard procedure, building a classifier using machine learning is a fully automated process that follows the preparation of training data by a domain expert. in contrast, interactive machine learning engages users in actually generating the classifier themselves. this offers a natural way of integrating background knowledge into the modelling stage-as long as interactive tools can be designed that support efficient and effective communication. this paper shows that appropriate techniques can empower users to create models that compete with classifiers built by state-of-the-art learning algorithms. it demonstrates that users-even users who are not domain experts-can often construct good classifiers, without any help from a learning algorithm, using a simple two-dimensional visual interface. experiments on real data demonstrate that, not surprisingly, success hinges on the domain: if a few attributes can support good predictions, users generate accurate classifiers, whereas domains with many high-order attribute interactions favour standard machine learning techniques. we also present an artificial example where domain knowledge allows an ''expert user'' to create a much more accurate model than automatic learning algorithms. these results indicate that our system has the potential to produce highly accurate classifiers in the hands of a domain expert who has a strong interest in the domain and therefore some insights into how to partition the data. moreover, small expert-defined models offer the additional advantage that they will generally be more intelligible than those generated by automatic techniques."
6067134,inproceedings,,acm recsys,,,,,,2009,oct,2009-11-04 09:52:05,new york,augmenting collaborative recommender by fusing explicit social relationships,
8877925,inproceedings,,proceedings of the fourth acm conference on recommender systems,recsys,acm,,,,2010,,2011-02-23 13:23:22,"new york, ny, usa",tutorial on evaluating recommender systems,"in this tutorial we discuss the evaluation of recommender systems. we discuss the main reason for evaluating recommender systems, i.e., the selection task. we overview some general guidelines for conducting evaluation tests. we then discuss the evaluation of the system accuracy given specific system tasks. we also overview many properties of recommender systems, and explain how these properties can be evaluated."